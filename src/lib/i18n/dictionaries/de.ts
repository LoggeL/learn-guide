import type { Dictionary } from './en'

export const de: Dictionary = {
  // Common UI
  common: {
    learnAi: 'Lerne KI',
    interactiveGuide: 'Interaktiver Leitfaden',
    topics: 'Themen',
    search: 'Suchen...',
    searchTopics: 'Themen suchen...',
    startTyping: 'Beginne zu tippen, um Themen zu suchen...',
    trySearching: 'Versuche "Temperature" oder "Attention"',
    noResults: 'Keine Ergebnisse gefunden für',
    pressEsc: 'ESC zum Schließen',
    enterToSelect: 'Enter zum Auswählen',
    previous: 'Zurück',
    next: 'Weiter',
    projectBy: 'Ein Projekt von',
    proTip: 'Profi-Tipp: Drücke',
    toSearchTopics: 'um Themen zu suchen',
    interactiveAiLearning: 'Interaktives KI-Lernen',
    guidesDescription: 'Interaktive Anleitungen zum Verstehen von KI-Konzepten',
  },

  // Home page
  home: {
    heroTitle1: 'KI-Konzepte meistern',
    heroTitle2: 'Durch Erfahrung',
    heroDescription: 'Erkunde künstliche Intelligenz und große Sprachmodelle durch schöne, interaktive Demonstrationen. Lerne durch Handeln, nicht nur durch Lesen.',
    startLearning: 'Jetzt lernen',
    browseTopics: 'Themen durchsuchen',
    exploreTopics: 'Themen erkunden',
    diveIntoLessons: 'Tauche ein in interaktive Lektionen',
  },

  // Features
  features: {
    interactiveDemos: 'Interaktive Demos',
    interactiveDemosDesc: 'Praktische Erkundungen, die abstrakte Konzepte greifbar und intuitiv machen.',
    visualLearning: 'Visuelles Lernen',
    visualLearningDesc: 'Schöne Visualisierungen, die zeigen, wie KI-Systeme tatsächlich funktionieren.',
    buildIntuition: 'Intuition aufbauen',
    buildIntuitionDesc: 'Gehe über das Auswendiglernen hinaus – entwickle tiefes Verständnis durch Experimentieren.',
  },

  // Topic categories
  categories: {
    ai: 'Künstliche Intelligenz',
    agents: 'KI-Agenten',
    llm: 'Große Sprachmodelle',
  },

  // Topic names
  topicNames: {
    'agent-loop': 'Der Agenten-Zyklus',
    'agent-context': 'Kontext-Anatomie',
    'agent-problems': 'Agenten-Probleme',
    'agent-security': 'Agenten-Sicherheit',
    'agentic-patterns': 'Agentische Muster',
    'mcp': 'MCP (Model Context Protocol)',
    'context-rot': 'Kontextverfall',
    'temperature': 'Temperatur',
    'attention': 'Aufmerksamkeits-Mechanismus',
    'vision': 'Bildverarbeitung',
    'visual-challenges': 'Visuelle Herausforderungen',
  },

  // Temperature page
  temperature: {
    title: 'Temperatur',
    description: 'Verstehe, wie ein einzelner Parameter die Balance zwischen vorhersagbarer Logik und kreativer Zufälligkeit in KI-Ausgaben steuert.',
    whatIs: 'Was ist Temperatur?',
    whatIsDesc: 'In LLMs ist Temperatur ein Hyperparameter, der die "Logits" (Rohwerte) der nächsten Token-Vorhersagen skaliert, bevor sie in Wahrscheinlichkeiten umgewandelt werden. Er steuert im Wesentlichen, wie stark das Modell die wahrscheinlichsten Optionen gegenüber weniger wahrscheinlichen bevorzugt.',
    lowTemp: 'Niedrige Temperatur',
    lowTempDesc: 'Konzentriert sich auf die Top-Ergebnisse. Zuverlässig, konsistent und faktisch. Ideal für Code, Mathematik und strukturierte Daten.',
    highTemp: 'Hohe Temperatur',
    highTempDesc: 'Verteilt Wahrscheinlichkeit auf mehr Tokens. Vielfältig, kreativ und überraschend. Ideal für Geschichten, Brainstorming und Poesie.',
    interactiveDistribution: 'Interaktive Verteilung',
    adjustSlider: 'Stelle die Temperatur ein, um den Effekt zu sehen',
    adjustDesc: 'Bewege den Temperaturregler, um zu sehen, wie er die Wahrscheinlichkeitsverteilung für das nächste Token umformt. Beobachte, wie "the" (die wahrscheinlichste Wahl) bei niedrigen Temperaturen dominiert und bei steigender Temperatur seinen Vorsprung verliert.',
    howItWorks: 'Wie es mathematisch funktioniert',
    mathDesc: 'Das Modell generiert einen Score für jedes mögliche Token. Um Wahrscheinlichkeiten zu erhalten, verwenden wir die Softmax-Funktion, modifiziert durch die Temperatur:',
    whenLow: 'Wenn T → 0',
    low: 'Niedrig',
    whenLowDesc: 'Division durch ein kleines T verstärkt die Unterschiede zwischen den Scores. Der höchste Logit dominiert exponentiell.',
    whenHigh: 'Wenn T → ∞',
    high: 'Hoch',
    whenHighDesc: 'Division durch ein großes T komprimiert alle Scores gegen Null, wodurch sie nach der Exponentialfunktion nahezu gleich werden.',
    practicalGuidelines: 'Praktische Richtlinien',
    useCase: 'Anwendungsfall',
    tempLabel: 'Temperatur',
    why: 'Warum?',
    codingMath: 'Programmierung & Mathematik',
    codingMathWhy: 'Fehler in der Logik sind kostspielig; du willst den wahrscheinlichsten korrekten Pfad.',
    factRetrieval: 'Faktenabfrage',
    factRetrievalWhy: 'Reduziert "Halluzinationen", indem es sich an die wahrscheinlichsten Datenpunkte hält.',
    generalChat: 'Allgemeiner Chat',
    generalChatWhy: 'Der "Sweet Spot" für die meisten Modelle, um natürlich und hilfreich zu klingen.',
    creativeWriting: 'Kreatives Schreiben',
    creativeWritingWhy: 'Ermutigt das Modell, interessanteres, vielfältigeres Vokabular zu verwenden.',
    brainstorming: 'Brainstorming',
    brainstormingWhy: 'Generiert wilde, unkonventionelle Ideen, die Inspiration wecken könnten.',
    keyTakeaways: 'Wichtige Erkenntnisse',
    takeaway1: 'Temperatur 0 ist deterministisch ("Greedy Search") – wählt immer das Top-Token',
    takeaway2: 'Höhere Temperatur erhöht Vielfalt und Kreativität, verringert aber die Kohärenz',
    takeaway3: 'Zu hohe Temperatur (> 1.5) führt oft zu Kauderwelsch',
    takeaway4: 'Passe die Temperatur immer an die Anforderungen der Aufgabe bezüglich Präzision vs. Kreativität an',
  },

  // Context Rot page
  contextRot: {
    title: 'Kontextverfall',
    description: 'Verstehe, wie Informationen über lange Gespräche degradieren und warum LLMs mit erweiterten Kontexten kämpfen.',
    whatIs: 'Was ist Kontextverfall?',
    whatIsDesc: 'Kontextverfall bezieht sich auf die allmähliche Verschlechterung der Fähigkeit eines LLMs, Informationen aus früheren Teilen eines langen Gesprächs oder Dokuments genau abzurufen und zu nutzen. Mit wachsendem Kontext wird die Aufmerksamkeit des Modells verwässert.',
    whyHappens: 'Warum passiert das?',
    whyHappensDesc: 'LLMs haben begrenzte Kontextfenster und nutzen Aufmerksamkeitsmechanismen, die den Fokus auf alle Tokens verteilen müssen. Bei längeren Gesprächen konkurrieren frühere Informationen mit neuerem Inhalt um die begrenzte Aufmerksamkeitskapazität des Modells.',
    symptoms: 'Häufige Symptome',
    symptom1: 'Vergessen von Anweisungen vom Anfang eines Gesprächs',
    symptom2: 'Widerspruch zu früheren Aussagen oder Entscheidungen',
    symptom3: 'Verlust des Überblicks bei komplexen Mehrstufenaufgaben',
    symptom4: 'Verwechslung von Details aus verschiedenen Teilen des Kontexts',
    mitigation: 'Gegenmaßnahmen',
    mitigation1: 'Fasse wichtigen Kontext regelmäßig zusammen',
    mitigation2: 'Platziere kritische Anweisungen sowohl am Anfang als auch am Ende',
    mitigation3: 'Nutze strukturierte Formate, um wichtige Informationen hervorzuheben',
    mitigation4: 'Teile lange Aufgaben in kleinere, fokussierte Gespräche auf',
    interactiveDemo: 'Interaktive Demo',
    demoDesc: 'Sieh, wie das Gedächtnis mit zunehmender Kontextlänge verblasst',
    keyTakeaways: 'Wichtige Erkenntnisse',
    takeaway1: 'Kontextverfall ist eine inhärente Einschränkung aktueller LLM-Architekturen',
    takeaway2: 'Der "Lost in the Middle"-Effekt bedeutet, dass Informationen am Anfang und Ende besser erinnert werden',
    takeaway3: 'Strategische Informationsplatzierung kann den Abruf erheblich verbessern',
    takeaway4: 'Regelmäßiges Zusammenfassen hilft, wichtigen Kontext über lange Gespräche zu erhalten',
  },

  // Attention page
  attention: {
    title: 'Aufmerksamkeits-Mechanismus',
    description: 'Erkunde, wie Transformer durch den leistungsstarken Aufmerksamkeitsmechanismus auf relevante Teile der Eingabe fokussieren.',
    whatIs: 'Was ist Aufmerksamkeit?',
    whatIsDesc: 'Aufmerksamkeit ist der Kernmechanismus, der es Transformern ermöglicht, die Wichtigkeit verschiedener Teile der Eingabe bei der Generierung jedes Ausgabe-Tokens zu gewichten. Es ermöglicht dem Modell, sich auf relevanten Kontext zu "konzentrieren".',
    howWorks: 'Wie es funktioniert',
    howWorksDesc: 'Für jede Position berechnet das Modell Query-, Key- und Value-Vektoren. Aufmerksamkeits-Scores werden durch Vergleich von Queries mit Keys berechnet und dann verwendet, um eine gewichtete Summe der Values zu erstellen.',
    selfAttention: 'Selbst-Aufmerksamkeit',
    selfAttentionDesc: 'Ermöglicht jedem Token, auf alle anderen Tokens in der Sequenz zu achten und Beziehungen unabhängig von der Entfernung zu erfassen.',
    multiHead: 'Multi-Head-Aufmerksamkeit',
    multiHeadDesc: 'Mehrere Aufmerksamkeitsköpfe ermöglichen es dem Modell, sich gleichzeitig auf verschiedene Arten von Beziehungen zu konzentrieren.',
    keyTakeaways: 'Wichtige Erkenntnisse',
    takeaway1: 'Aufmerksamkeit ermöglicht Transformern, Langstreckenabhängigkeiten zu erfassen',
    takeaway2: 'Die quadratische Komplexität der Aufmerksamkeit begrenzt die Kontextfenstergröße',
    takeaway3: 'Verschiedene Aufmerksamkeitsköpfe lernen, sich auf verschiedene linguistische Muster zu konzentrieren',
    takeaway4: 'Aufmerksamkeitsvisualisierung kann helfen, das Modellverhalten zu interpretieren',
  },

  // Vision page
  vision: {
    title: 'Bildverarbeitung',
    description: 'Wie moderne LLMs visuelle Informationen neben Text verarbeiten und verstehen.',
    whatIs: 'Wie LLMs Bilder sehen',
    whatIsDesc: 'Bildverarbeitungsfähige LLMs wandeln Bilder in Token-Sequenzen um, die zusammen mit Text verarbeitet werden können. Dies beinhaltet typischerweise das Aufteilen von Bildern in Patches und deren Kodierung mit einem Vision-Transformer.',
    patchEncoding: 'Patch-Kodierung',
    patchEncodingDesc: 'Bilder werden in Patches fester Größe (z.B. 14x14 Pixel) aufgeteilt, wobei jeder in einen Einbettungsvektor ähnlich wie Text-Tokens umgewandelt wird.',
    multimodal: 'Multimodales Verständnis',
    multimodalDesc: 'Das Modell lernt, visuelle und textuelle Repräsentationen auszurichten, was Aufgaben wie Bildbeschriftung, visuelle Fragen und Dokumentenverständnis ermöglicht.',
    keyTakeaways: 'Wichtige Erkenntnisse',
    takeaway1: 'Bilder verbrauchen viel mehr Tokens als äquivalente Textbeschreibungen',
    takeaway2: 'Auflösung und Patch-Größe beeinflussen die Detailerkennung',
    takeaway3: 'Visuelles Verständnis ist ungefähr – Modelle können feine Details übersehen',
    takeaway4: 'Die Kombination von Bild und Sprache ermöglicht leistungsstarke neue Anwendungen',
  },

  // Visual Challenges page
  visualChallenges: {
    title: 'Visuelle Herausforderungen',
    description: 'Häufige Herausforderungen und Einschränkungen bei der Arbeit mit bildverarbeitungsfähigen KI-Modellen.',
    overview: 'Häufige visuelle Herausforderungen',
    overviewDesc: 'Obwohl Bildmodelle beeindruckend sind, stehen sie vor mehreren systematischen Herausforderungen, die beim Erstellen von Anwendungen wichtig zu verstehen sind.',
    challenge1: 'Objekte zählen',
    challenge1Desc: 'Modelle haben oft Schwierigkeiten, Objekte in Bildern genau zu zählen, besonders wenn es viele ähnliche Elemente gibt.',
    challenge2: 'Räumliches Denken',
    challenge2Desc: 'Das Verstehen präziser räumlicher Beziehungen zwischen Objekten (links/rechts, oben/unten) kann unzuverlässig sein.',
    challenge3: 'Kleine Texterkennung',
    challenge3Desc: 'Feiner Text in Bildern kann falsch gelesen oder ganz übersehen werden, besonders bei niedrigen Auflösungen.',
    challenge4: 'Halluzination',
    challenge4Desc: 'Modelle können Objekte oder Details beschreiben, die nicht wirklich im Bild vorhanden sind.',
    keyTakeaways: 'Wichtige Erkenntnisse',
    takeaway1: 'Verifiziere kritische visuelle Informationen immer auf anderen Wegen',
    takeaway2: 'Höher aufgelöste Bilder verbessern generell die Genauigkeit',
    takeaway3: 'Teile komplexe visuelle Aufgaben in einfachere Unterfragen auf',
    takeaway4: 'Sei explizit darüber, welche Aspekte eines Bildes du analysieren musst',
  },

  // Agent Loop page
  agentLoop: {
    title: 'Der Agenten-Zyklus',
    description: 'Verstehe den Kernzyklus, der autonome KI-Agenten antreibt: beobachten, denken, handeln, wiederholen.',
    whatIs: 'Was ist der Agenten-Zyklus?',
    whatIsDesc: 'Der Agenten-Zyklus ist der fundamentale Kreislauf, der es KI-Agenten ermöglicht, autonom mit ihrer Umgebung zu interagieren. Er besteht aus Beobachtungs-, Denk-, Handlungs- und Feedback-Phasen, die sich kontinuierlich wiederholen.',
    phases: 'Die vier Phasen',
    observe: 'Beobachten',
    observeDesc: 'Sammle Informationen aus der Umgebung, von Tools und Benutzereingaben.',
    think: 'Denken',
    thinkDesc: 'Überlege zum aktuellen Zustand und entscheide über die nächste Aktion.',
    act: 'Handeln',
    actDesc: 'Führe die gewählte Aktion mit verfügbaren Tools aus.',
    learn: 'Lernen',
    learnDesc: 'Verarbeite Feedback und aktualisiere das Verständnis für die nächste Iteration.',
    keyTakeaways: 'Wichtige Erkenntnisse',
    takeaway1: 'Der Zyklus setzt sich fort, bis die Aufgabe abgeschlossen oder beendet ist',
    takeaway2: 'Jede Iteration baut auf vorherigen Beobachtungen und Aktionen auf',
    takeaway3: 'Fehlerbehandlung und Wiederherstellung sind entscheidend für robuste Agenten',
    takeaway4: 'Die Qualität der Tools beeinflusst direkt die Fähigkeiten des Agenten',
  },

  // Agent Context page
  agentContext: {
    title: 'Kontext-Anatomie',
    description: 'Aufschlüsselung der Struktur von Kontextfenstern und wie Agenten Informationen verwalten.',
    whatIs: 'Agentenkontext verstehen',
    whatIsDesc: 'Der Agentenkontext umfasst den System-Prompt, die Gesprächshistorie, Tool-Definitionen und abgerufene Informationen. Eine effiziente Verwaltung dieses Kontexts ist entscheidend für die Agentenleistung.',
    components: 'Kontext-Komponenten',
    systemPrompt: 'System-Prompt',
    systemPromptDesc: 'Definiert die Rolle, Fähigkeiten und Verhaltensrichtlinien des Agenten.',
    toolDefs: 'Tool-Definitionen',
    toolDefsDesc: 'Beschreibungen der verfügbaren Tools und ihrer Verwendung.',
    history: 'Gesprächshistorie',
    historyDesc: 'Vorherige Nachrichten, Tool-Aufrufe und deren Ergebnisse.',
    retrieved: 'Abgerufene Informationen',
    retrievedDesc: 'Externes Wissen, das während des Gesprächs abgerufen wurde.',
    keyTakeaways: 'Wichtige Erkenntnisse',
    takeaway1: 'Kontextmanagement ist der Schlüssel zur Agenten-Zuverlässigkeit',
    takeaway2: 'Priorisiere aktuelle und relevante Informationen',
    takeaway3: 'Tool-Definitionen sollten klar und eindeutig sein',
    takeaway4: 'Zusammenfassung hilft, Kontext über lange Sitzungen zu erhalten',
  },

  // Agent Problems page
  agentProblems: {
    title: 'Agenten-Probleme',
    description: 'Häufige Fehlermodi und Herausforderungen, denen KI-Agenten in realen Anwendungen begegnen.',
    overview: 'Häufige Agenten-Fehlermodi',
    overviewDesc: 'Das Verstehen typischer Agentenfehler hilft beim Aufbau robusterer Systeme und beim Setzen angemessener Erwartungen.',
    problem1: 'Tool-Missbrauch',
    problem1Desc: 'Agenten können Tools falsch aufrufen, mit falschen Parametern oder zu unpassenden Zeiten.',
    problem2: 'Endlosschleifen',
    problem2Desc: 'Agenten können stecken bleiben und dieselben Aktionen wiederholen, ohne Fortschritte zu machen.',
    problem3: 'Zieldrift',
    problem3Desc: 'Agenten können den Fokus allmählich vom ursprünglichen Aufgabenziel weg verschieben.',
    problem4: 'Übermäßiges Selbstvertrauen',
    problem4Desc: 'Agenten können trotz Unsicherheit oder unvollständiger Informationen mit Aktionen fortfahren.',
    
    // Expanded Content
    hallucination: 'Tool-Halluzination',
    hallucinationDesc: 'Agenten "erfinden" manchmal Tool-Parameter oder sogar ganze Tools, die nicht existieren. Dies passiert meistens, wenn die Tool-Definition mehrdeutig ist oder das Modell versucht, eine Lösung zu erzwingen.',
    hallucinationExample: 'Beispiel: Aufruf von `get_weather(location="Tokyo", date="tomorrow")`, wenn die Funktion nur `location` akzeptiert.',
    
    loops: 'Schleifen-Probleme',
    loopsDesc: 'Agenten können in repetitiven Zyklen gefangen sein, in denen sie dieselbe Aktion ausführen, denselben Fehler erhalten und es ohne Strategieänderung erneut versuchen.',
    loopsMitigation: 'Abhilfe: Implementiere Schleifenerkennungslogik, die die Ausführung stoppt, wenn dieselbe Tool-Aufrufsequenz mehrmals auftritt.',
    
    costLatency: 'Kosten & Latenz',
    costLatencyDesc: 'Jeder Schritt im Agentenzyklus erfordert einen vollständigen LLM-Inferenzaufruf. Mehrstufige Aufgaben können schnell teuer und langsam werden.',
    costFactor: 'Der Kostenfaktor',
    costFactorDesc: 'Eine einfache Aufgabe, die 5 Schritte erfordert, bedeutet 5-fache Kosten und 5-fache Latenz im Vergleich zu einer Standard-Chat-Antwort.',
    
    keyTakeaways: 'Wichtige Erkenntnisse',
    takeaway1: 'Implementiere Sicherheitsvorkehrungen wie Iterationslimits und Kostenkontrollen',
    takeaway2: 'Füge Human-in-the-Loop-Kontrollpunkte für kritische Aktionen hinzu',
    takeaway3: 'Überwache das Agentenverhalten und protokolliere alle Aktionen zum Debugging',
    takeaway4: 'Definiere klare Erfolgs- und Fehlkriterien',
  },

  // Agent Security page
  agentSecurity: {
    title: 'Agenten-Sicherheit',
    description: 'Kritische Sicherheitslücken bei KI-Agenten: Prompt-Injektion, Datenexfiltration und Tool-Missbrauch – plus Verteidigungsstrategien.',
    
    // Intro
    intro: 'Agenten sind Angriffsflächen',
    introDesc: 'Wenn du einem LLM Zugang zu Tools gibst, schaffst du einen mächtigen Angriffsvektor. Agenten können Dateien lesen, HTTP-Anfragen stellen, E-Mails senden und Code ausführen. Ein böswilliger Akteur, der den Kontext des Agenten beeinflussen kann, kann potenziell all diese Fähigkeiten kontrollieren.',
    
    // Attack 1: Prompt Injection
    attack1Title: 'Angriff #1: Prompt-Injektion',
    attack1Desc: 'Prompt-Injektion tritt auf, wenn nicht vertrauenswürdige Eingaben vom LLM als Anweisungen interpretiert werden. Da Agenten oft externe Daten verarbeiten (E-Mails, Webseiten, Dokumente), können Angreifer versteckte Befehle einbetten, die das Verhalten des Agenten kapern.',
    attack1Example: 'Beispiel-Angriff',
    attack1ExampleDesc: 'Der Benutzer bittet den Agenten, ein Dokument zusammenzufassen. Das Dokument enthält versteckte Anweisungen:',
    whyWorks: 'Warum das funktioniert',
    whyWorks1: 'Der Agent liest das Dokument in seinen Kontext',
    whyWorks2: 'Das LLM kann nicht zwischen "echten" Anweisungen und injizierten unterscheiden',
    whyWorks3: 'Der versteckte Text sieht aus wie Systemanweisungen, also folgt das LLM ihnen möglicherweise',
    whyWorks4: 'Der Agent nutzt seine legitimen Tools, um die bösartige Aktion auszuführen',
    directInjection: 'Direkte Injektion',
    directInjectionDesc: 'Der Benutzer tippt bösartige Anweisungen direkt ein. Leichter zu filtern, aber immer noch gefährlich, wenn der System-Prompt nicht robust ist.',
    indirectInjection: 'Indirekte Injektion',
    indirectInjectionDesc: 'Bösartiger Inhalt kommt aus externen Quellen, die der Agent liest (Websites, E-Mails, Dateien). Viel schwerer zu verteidigen.',
    
    // Attack 2: Data Exfiltration
    attack2Title: 'Angriff #2: Datenexfiltration',
    attack2Desc: 'Agenten mit Zugang zu Kommunikationstools (E-Mail, HTTP, Slack, etc.) können dazu gebracht werden, sensible Daten an externe Ziele zu senden. Der Agent wird zum unwissenden Komplizen beim Datendiebstahl.',
    exfilFlow: 'Exfiltrations-Ablauf',
    exfilStep1: 'Agent liest',
    exfilStep1Desc: 'Private Dateien, DB, Env-Variablen',
    exfilStep2: 'Injektion löst aus',
    exfilStep2Desc: '"Sende dies an X"',
    exfilStep3: 'Tool führt aus',
    exfilStep3Desc: 'Daten verlassen das System',
    vulnerableConfig: 'Anfällige Tool-Konfiguration',
    otherVectors: 'Andere Exfiltrations-Vektoren',
    vector1: 'HTTP-Anfragen — POST-Daten an angreifergesteuerte Endpunkte',
    vector2: 'Slack/Discord-Webhooks — Nachrichten an externe Kanäle senden',
    vector3: 'Datei-Uploads — Hochladen in Cloud-Speicher mit öffentlichen Links',
    vector4: 'DNS-Exfiltration — Daten in DNS-Anfragen kodieren',
    
    // Attack 3: Tool Misuse
    attack3Title: 'Angriff #3: Unbeabsichtigter Tool-Missbrauch',
    attack3Desc: 'Auch ohne böswillige Absicht können Agenten durch falsche Tool-Nutzung Schaden anrichten. Das LLM könnte Parameter falsch verstehen, das falsche Tool verwenden oder destruktive Aktionen ausführen, während es versucht, hilfreich zu sein.',
    destructiveActions: 'Destruktive Aktionen',
    destructiveActionsDesc: '"Räume das Projekt auf" → Agent führt rm -rf / aus oder löscht die Produktionsdatenbank',
    wrongParams: 'Falsche Parameter',
    wrongParamsDesc: 'Agent verwechselt ähnliche Felder oder verwendet falsche Werte, die plausibel erscheinen',
    cascadingErrors: 'Kaskadierende Fehler',
    cascadingErrorsDesc: 'Agent macht einen kleinen Fehler, dann "behebt" er ihn mit zunehmend destruktiven Aktionen',
    
    // Defense Strategies
    defensesTitle: 'Verteidigungsstrategien',
    defense1: 'Prinzip der minimalen Rechte',
    defense1Desc: 'Gib dem Agenten nur die minimal notwendigen Tools und Berechtigungen für die Aufgabe. Gib keinen Dateizugang, wenn er nur Fragen beantworten muss.',
    defense1Bad: 'Schlecht',
    defense1Good: 'Gut',
    defense2: 'Strikte Allowlists',
    defense2Desc: 'Beschränke Tool-Parameter auf bekannte sichere Werte. Erlaube keine beliebigen E-Mail-Adressen, URLs oder Dateipfade.',
    defense3: 'Human-in-the-Loop',
    defense3Desc: 'Erfordere menschliche Genehmigung für sensible Aktionen. Der Agent schlägt vor, der Mensch bestätigt.',
    defense3Example: 'Beispiel-Bestätigungsablauf:',
    defense4: 'Eingabe-Bereinigung & Isolation',
    defense4Desc: 'Behandle externe Daten als nicht vertrauenswürdig. Trenne Benutzeranweisungen klar von abgerufenen Inhalten.',
    defense5: 'Überwachung & Ratenbegrenzung',
    defense5Desc: 'Protokolliere alle Tool-Aufrufe. Setze Ratenlimits für sensible Operationen. Alarmiere bei ungewöhnlichen Mustern (viele E-Mails, große Datenübertragungen, wiederholte Fehler). Aktiviere Rollback für destruktive Aktionen.',
    
    // Key Takeaways
    keyTakeaways: 'Wichtige Erkenntnisse',
    takeaway1: 'Agenten sind Angriffsflächen – jedes Tool ist eine potenzielle Schwachstelle',
    takeaway2: 'Prompt-Injektion ist die #1 Bedrohung – LLMs können Anweisungen nicht von Daten unterscheiden',
    takeaway3: 'Datenexfiltration ist trivial, wenn Agenten ausgehende Kommunikationstools haben',
    takeaway4: 'Tool-Missbrauch passiert auch ohne Angreifer – LLMs machen Fehler',
    takeaway5: 'Verteidigung in der Tiefe: minimale Rechte + Allowlists + menschliche Genehmigung + Überwachung',
    takeaway6: 'Behandle alle externen Daten als potenziell bösartige Eingaben',
  },

  // Agentic Patterns page
  agenticPatterns: {
    title: 'Agentische Muster',
    description: 'Entwurfsmuster und Architekturen für den Aufbau effektiver KI-Agentensysteme.',
    overview: 'Häufige agentische Muster',
    overviewDesc: 'Mehrere Architekturmuster haben sich als effektive Ansätze für den Aufbau von KI-Agentensystemen herausgestellt.',
    pattern1: 'ReAct (Reason + Act)',
    pattern1Desc: 'Verschachtele Denk-Traces mit Aktionen für bessere Transparenz und Kontrolle.',
    pattern2: 'Plan-and-Execute',
    pattern2Desc: 'Erstelle zuerst einen übergeordneten Plan, dann führe die Schritte sequentiell aus.',
    pattern3: 'Multi-Agenten-Systeme',
    pattern3Desc: 'Mehrere spezialisierte Agenten arbeiten zusammen, um komplexe Aufgaben zu lösen.',
    pattern4: 'Reflexion',
    pattern4Desc: 'Agenten überprüfen ihre eigenen Ausgaben und verbessern sie iterativ.',
    keyTakeaways: 'Wichtige Erkenntnisse',
    takeaway1: 'Wähle Muster basierend auf Aufgabenkomplexität und Zuverlässigkeitsanforderungen',
    takeaway2: 'ReAct ist großartig für Transparenz, kann aber langsamer sein',
    takeaway3: 'Multi-Agenten-Systeme erhöhen die Komplexität, ermöglichen aber Spezialisierung',
    takeaway4: 'Reflexionsmuster können die Ausgabequalität erheblich verbessern',
  },

  // MCP page
  mcp: {
    title: 'MCP (Model Context Protocol)',
    description: 'MCP verstehen: wann externe Tool-Server sinnvoll sind und wann sie übertrieben sind.',
    whatIs: 'Was ist MCP?',
    whatIsDesc: 'Das Model Context Protocol (MCP) ist ein standardisierter Weg, um KI-Agenten mit externen Tools und Datenquellen über dedizierte Server-Prozesse zu verbinden. Anstatt Tools inline im Agenten-Code zu definieren, führt MCP einen separaten Server aus, der Tools über ein strukturiertes Protokoll bereitstellt.',
    vsToolCalls: 'MCP vs. Reguläre Tool-Aufrufe',
    vsToolCallsDesc: 'Reguläre Tool-Aufrufe sind Funktionen, die direkt in der Codebasis deines Agenten definiert sind. Der Agent ruft sie auf, sie werden ausgeführt und die Ergebnisse kehren im selben Prozess zurück. MCP trennt dies: Tools leben in externen Servern, mit denen der Agent über ein Protokoll kommuniziert.',
    
    // Comparison
    regularTools: 'Reguläre Tool-Aufrufe',
    regularToolsDesc: 'Tools, die inline in deinem Agenten-Code definiert sind. Einfach, schnell und für die meisten Anwendungsfälle ausreichend.',
    mcpTools: 'MCP-Server',
    mcpToolsDesc: 'Tools, die von externen Server-Prozessen bereitgestellt werden. Fügt Netzwerk-Overhead hinzu, ermöglicht aber sprachübergreifendes Tooling und gemeinsame Tool-Ökosysteme.',
    
    // When to use
    whenToUse: 'Wann MCP sinnvoll ist',
    whenToUseDesc: 'MCP glänzt in spezifischen Szenarien, in denen sich seine zusätzliche Komplexität auszahlt.',
    useCase1: 'Multi-Sprachen-Teams',
    useCase1Desc: 'Deine Tools sind in Python geschrieben, aber dein Agent ist in TypeScript, oder umgekehrt.',
    useCase2: 'Gemeinsames Tool-Ökosystem',
    useCase2Desc: 'Mehrere Agenten in verschiedenen Projekten müssen auf dieselben Tools zugreifen.',
    useCase3: 'Enterprise-Integration',
    useCase3Desc: 'Du musst bestehende interne Dienste als Agenten-Tools bereitstellen, ohne sie zu modifizieren.',
    useCase4: 'Tool-Marktplatz',
    useCase4Desc: 'Du möchtest von der Community gepflegte Tools nutzen, ohne Code in dein Projekt zu kopieren.',
    
    // When it's overkill
    overkill: 'Wann MCP übertrieben ist',
    overkillDesc: 'Für viele Anwendungsfälle fügt MCP unnötige Komplexität hinzu.',
    overkillCase1: 'Einsprachige Projekte',
    overkillCase1Desc: 'Wenn deine Tools und dein Agent in derselben Sprache sind, sind Inline-Funktionen einfacher und schneller.',
    overkillCase2: 'Einfache Agenten',
    overkillCase2Desc: 'Ein Chatbot mit wenigen Tools braucht nicht den Overhead, separate Server-Prozesse auszuführen.',
    overkillCase3: 'Schnelles Prototyping',
    overkillCase3Desc: 'Bei schneller Iteration verlangsamt die Indirektion von MCP die Entwicklung.',
    overkillCase4: 'Latenz-kritische Apps',
    overkillCase4Desc: 'Netzwerkaufrufe zu Tool-Servern fügen Latenz hinzu, die Inline-Funktionen nicht haben.',
    
    // Architecture
    architecture: 'Wie MCP funktioniert',
    architectureDesc: 'MCP definiert eine Client-Server-Architektur, bei der der Agent der Client ist und Tools von Servern bereitgestellt werden.',
    step1: 'Entdeckung',
    step1Desc: 'Der Agent verbindet sich mit einem MCP-Server und erhält eine Liste der verfügbaren Tools mit ihren Schemas.',
    step2: 'Aufruf',
    step2Desc: 'Wenn das LLM entscheidet, ein Tool zu verwenden, sendet der Agent eine Anfrage an den MCP-Server.',
    step3: 'Ausführung',
    step3Desc: 'Der MCP-Server führt das Tool aus und gibt Ergebnisse in einem standardisierten Format zurück.',
    step4: 'Integration',
    step4Desc: 'Ergebnisse fließen zurück zum Agenten und in den LLM-Kontext, genau wie reguläre Tool-Ergebnisse.',
    
    // Practical advice
    practicalAdvice: 'Praktische Ratschläge',
    adviceDesc: 'Richtlinien für die Entscheidung, ob du MCP in deinem Projekt verwenden solltest.',
    advice1: 'Beginne einfach: verwende Inline-Tool-Definitionen, bis du auf eine spezifische Einschränkung stößt.',
    advice2: 'Erwäge MCP, wenn du dich dabei ertappst, Tool-Code zwischen Projekten zu kopieren.',
    advice3: 'Der Overhead, MCP-Server auszuführen, macht nur in großem Maßstab oder in Enterprise-Umgebungen Sinn.',
    advice4: 'Community-MCP-Server können die Entwicklung beschleunigen, fügen aber Abhängigkeitsrisiken hinzu.',
    
    keyTakeaways: 'Wichtige Erkenntnisse',
    takeaway1: 'MCP ist ein Protokoll zur Bereitstellung von Tools über externe Server, kein Ersatz für reguläre Tool-Aufrufe',
    takeaway2: 'Für die meisten Einzelprojekt-Agenten sind Inline-Tools einfacher und haben geringere Latenz',
    takeaway3: 'MCP glänzt in polyglotten Umgebungen und gemeinsamen Tool-Ökosystemen',
    takeaway4: 'Greife nicht standardmäßig zu MCP—es ist eine Lösung für spezifische Skalierungs- und Interoperabilitäts-Herausforderungen',
  },

  // Metadata
  metadata: {
    title: 'KI-Konzepte lernen | Interaktiver Leitfaden',
    description: 'Meistere künstliche Intelligenz und Konzepte großer Sprachmodelle durch schöne, interaktive Demonstrationen.',
  },

  // Interactive Components
  interactive: {
    // Temperature Demo
    controlPanel: 'Bedienfeld',
    adjustTemperature: 'Temperatur anpassen',
    temperature: 'Temperatur',
    samplePrompt: 'Beispiel-Prompt',
    onceUponATime: '"Es war einmal..."',
    liveCompletion: 'Live-Vervollständigung',
    regenerate: 'Neu generieren',
    deterministic: 'Deterministisch',
    balanced: 'Ausgewogen',
    creative: 'Kreativ',
    chaotic: 'Chaotisch',
    frozen: 'Eingefroren',
    focused: 'Fokussiert',
    wild: 'Wild',
    greedyMode: 'Gieriger Modus: Wählt immer das wahrscheinlichste Token.',
    lowTemp: 'Niedrige Temperatur: Fokus auf wahrscheinliche Fortsetzungen.',
    balancedTemp: 'Ausgewogen: Natürliche Mischung aus Vorhersehbarkeit und Vielfalt.',
    highTemp: 'Hohe Temperatur: Erkundet kreative, weniger häufige Wortwahlen.',
    veryHighTemp: 'Sehr hoch: Wahrscheinlichkeitsverteilung ist nahezu gleichförmig – erwarte Chaos!',
    
    // Context Rot Simulator
    setInstruction: 'Systemanweisung festlegen',
    persistInstruction: 'Dies sollte während des gesamten Gesprächs bestehen bleiben',
    systemPrompt: 'System-Prompt',
    quickExamples: 'Schnellbeispiele',
    startSimulation: 'Simulation starten',
    contextOverflow: 'Kontextüberlauf!',
    conversation: 'Gespräch',
    messagesPushed: 'Nachrichten aus dem Fenster geschoben',
    messages: 'Nachrichten',
    overflowIt: 'Überfluten!',
    reset: 'Zurücksetzen',
    typeMessage: 'Schreibe eine Nachricht...',
    systemInstructionLost: 'Systemanweisung verloren!',
    systemLostDesc: 'Deine Systemanweisung wurde vollständig aus dem Kontextfenster geschoben. Das Modell kann sie nicht mehr sehen – es ist, als hättest du die Anweisung nie gegeben. Das ist der schlimmste Fall von Kontextverfall: totale Amnesie.',
    contextFilling: 'Kontext füllt sich',
    contextFillingDesc: 'Deine Systemanweisung verliert an Einfluss, da neuere Nachrichten Vorrang haben. Beachte, wie sie visuell verblasst – dies stellt die schwindende Aufmerksamkeit des Modells dar.',
    exampleFrench: 'Antworte immer auf Französisch.',
    examplePirate: 'Du bist ein Pirat. Sage oft "Arrr".',
    exampleHaiku: 'Beende jede Antwort mit einem Haiku.',
    labelFrench: 'Sprich Französisch',
    labelPirate: 'Sei ein Pirat',
    labelHaiku: 'Beende mit Haiku',

    // Attention Visualizer
    hoverToSee: 'Fahre darüber, um Aufmerksamkeitsgewichte zu sehen',
    token: 'Token',
    attentionScore: 'Aufmerksamkeits-Score',
    strongConnection: 'Starke Verbindung',
    weakConnection: 'Schwache Verbindung',

    // Patch Grid Visualizer
    originalImage: 'Originalbild',
    patchGrid: 'Patch-Raster',
    flattenedPatches: 'Abgeflachte Patches',
    transformerInput: 'Transformer-Eingabe',
    processDesc: 'Das Bild wird in ein festes Raster von Patches (z.B. 16x16 Pixel) aufgeteilt. Jeder Patch wird dann in einen Vektor abgeflacht und linear in einen Einbettungsraum projiziert.',

    // Agent Loop Visualizer
    startLoop: 'Zyklus starten',
    step: 'Schritt',
    context: 'Kontext',
    llmResponse: 'LLM-Antwort',
    toolExecution: 'Tool-Ausführung',
    finalAnswer: 'Endgültige Antwort',
    system: 'System',
    user: 'Benutzer',
    assistant: 'Assistent',
    tool: 'Tool',
    
    // Agentic Patterns Visualizer
    react: 'ReAct',
    planExecute: 'Planen & Ausführen',
    multiAgent: 'Multi-Agent',
    reflection: 'Reflexion',
    patternDesc: 'Wähle ein Muster, um zu sehen, wie es den Arbeitsablauf des Agenten strukturiert.',
  },
}
