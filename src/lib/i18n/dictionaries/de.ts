import type { Dictionary } from './en'

export const de: Dictionary = {
  // Common UI
  common: {
    learnAi: 'Lerne KI',
    interactiveGuide: 'Interaktiver Leitfaden',
    topics: 'Themen',
    search: 'Suchen...',
    searchTopics: 'Themen suchen...',
    startTyping: 'Beginne zu tippen, um Themen zu suchen...',
    trySearching: 'Versuche "Temperature" oder "Attention"',
    noResults: 'Keine Ergebnisse gefunden für',
    pressEsc: 'ESC zum Schließen',
    enterToSelect: 'Enter zum Auswählen',
    previous: 'Zurück',
    next: 'Weiter',
    projectBy: 'Ein Projekt von',
    blog: 'Blog',
    proTip: 'Profi-Tipp: Drücke',
    toSearchTopics: 'um Themen zu suchen',
    interactiveAiLearning: 'Interaktives KI-Lernen',
    guidesDescription: 'Interaktive Anleitungen zum Verstehen von KI-Konzepten',
    backToAllTopics: 'Zurück zu allen Themen',
  },

  // Home page
  home: {
    heroTitle1: 'KI-Konzepte meistern',
    heroTitle2: 'Durch Erfahrung',
    heroDescription: 'Erkunde künstliche Intelligenz und große Sprachmodelle durch schöne, interaktive Demonstrationen. Lerne durch Handeln, nicht nur durch Lesen.',
    startLearning: 'Jetzt lernen',
    browseTopics: 'Themen durchsuchen',
    exploreTopics: 'Themen erkunden',
    diveIntoLessons: 'Tauche ein in interaktive Lektionen',
  },

  // Features
  features: {
    interactiveDemos: 'Interaktive Demos',
    interactiveDemosDesc: 'Praktische Erkundungen, die abstrakte Konzepte greifbar und intuitiv machen.',
    visualLearning: 'Visuelles Lernen',
    visualLearningDesc: 'Schöne Visualisierungen, die zeigen, wie KI-Systeme tatsächlich funktionieren.',
    buildIntuition: 'Intuition aufbauen',
    buildIntuitionDesc: 'Gehe über das Auswendiglernen hinaus – entwickle tiefes Verständnis durch Experimentieren.',
  },

  // Topic categories
  categories: {
    ai: 'Künstliche Intelligenz',
    agents: 'KI-Agenten',
    llm: 'Große Sprachmodelle',
    mlFundamentals: 'ML-Grundlagen',
    prompting: 'Prompting',
    safety: 'KI-Sicherheit',
    industry: 'KI-Industrie',
  },

  // Category descriptions (for category landing pages)
  categoryDescriptions: {
    agents: 'Lerne, wie man autonome KI-Systeme baut, die mit Tools und Speicher denken, planen und handeln können.',
    llm: 'Verstehe die inneren Abläufe großer Sprachmodelle, von der Tokenisierung bis zu Aufmerksamkeitsmechanismen.',
    'ml-fundamentals': 'Beherrsche die grundlegenden Konzepte des maschinellen Lernens, die moderne KI-Systeme antreiben.',
    prompting: 'Entdecke Techniken, um effektiv mit KI-Modellen zu kommunizieren und bessere Ergebnisse zu erzielen.',
    safety: 'Erkunde ethische Überlegungen und Best Practices für den Bau verantwortungsvoller KI-Systeme.',
    industry: 'Erkunde die Unternehmen und Trends, die die KI-Industrielandschaft prägen.',
  },

  // Topic names
  topicNames: {
    // Agent subcategories
    'agents-core': 'Kernkonzepte',
    'agents-building': 'Bausteine',
    'agents-patterns': 'Muster',
    'agents-quality': 'Qualität & Sicherheit',
    // Agent topics
    'agent-loop': 'Der Agenten-Zyklus',
    'agent-context': 'Kontext-Anatomie',
    'agent-problems': 'Agenten-Probleme',
    'agent-security': 'Agenten-Sicherheit',
    'agentic-patterns': 'Agentische Muster',
    'mcp': 'MCP (Model Context Protocol)',
    'tool-design': 'Tool-Design',
    'memory': 'Speichersysteme',
    'orchestration': 'Orchestrierung',
    'evaluation': 'Evaluierung',
    'skills': 'Agenten-Skills',
    // LLM subcategories
    'llm-fundamentals': 'Grundlagen',
    'llm-behavior': 'Verhalten',
    'llm-capabilities': 'Fähigkeiten',
    'llm-architecture': 'Architektur',
    // LLM topics
    'tokenization': 'Tokenisierung',
    'embeddings': 'Einbettungen',
    'rag': 'RAG (Retrieval Augmented Generation)',
    'context-rot': 'Kontextverfall',
    'temperature': 'Temperatur',
    'attention': 'Aufmerksamkeits-Mechanismus',
    'vision': 'Bildverarbeitung',
    'visual-challenges': 'Visuelle Herausforderungen',
    'agentic-vision': 'Agentische Bildverarbeitung',
    'multimodality': 'Multimodalität',
    'llm-training': 'LLM-Training',
    'moe': 'Mixture of Experts',
    'quantization': 'Quantisierung',
    'nested-learning': 'Verschachteltes Lernen',
    'distillation': 'Destillation',
    'speculative-decoding': 'Spekulatives Decoding',
    // ML Fundamentals
    'ml-fundamentals': 'ML-Grundlagen',
    'neural-networks': 'Neuronale Netzwerke',
    'gradient-descent': 'Gradientenabstieg',
    'training': 'Trainingsprozess',
    // Prompting
    'prompt-basics': 'Prompt-Grundlagen',
    'advanced-prompting': 'Fortgeschrittenes Prompting',
    'system-prompts': 'System-Prompts',
    // Safety
    'bias': 'Bias & Fairness',
    'responsible-ai': 'Verantwortungsvolle KI',
    // Industry
    'european-ai': 'KI aus Europa',
    'open-source': 'Open-Source-Vorteile',
    'opus-4-5': 'Logges Lieblingsmodell',
  },

  // Temperature page
  temperature: {
    title: 'Temperatur',
    description: 'Verstehe, wie ein einzelner Parameter die Balance zwischen vorhersagbarer Logik und kreativer Zufälligkeit in KI-Ausgaben steuert.',
    whatIs: 'Was ist Temperatur?',
    whatIsDesc: 'In LLMs ist Temperatur ein Hyperparameter, der die "Logits" (Rohwerte) der nächsten Token-Vorhersagen skaliert, bevor sie in Wahrscheinlichkeiten umgewandelt werden. Er steuert im Wesentlichen, wie stark das Modell die wahrscheinlichsten Optionen gegenüber weniger wahrscheinlichen bevorzugt.',
    lowTemp: 'Niedrige Temperatur',
    lowTempDesc: 'Konzentriert sich auf die Top-Ergebnisse. Zuverlässig, konsistent und faktisch. Ideal für Code, Mathematik und strukturierte Daten.',
    highTemp: 'Hohe Temperatur',
    highTempDesc: 'Verteilt Wahrscheinlichkeit auf mehr Tokens. Vielfältig, kreativ und überraschend. Ideal für Geschichten, Brainstorming und Poesie.',
    interactiveDistribution: 'Interaktive Verteilung',
    adjustSlider: 'Stelle die Temperatur ein, um den Effekt zu sehen',
    adjustDesc: 'Bewege den Temperaturregler, um zu sehen, wie er die Wahrscheinlichkeitsverteilung für das nächste Token umformt. Beobachte, wie "the" (die wahrscheinlichste Wahl) bei niedrigen Temperaturen dominiert und bei steigender Temperatur seinen Vorsprung verliert.',
    howItWorks: 'Wie es mathematisch funktioniert',
    mathDesc: 'Das Modell generiert einen Score für jedes mögliche Token. Um Wahrscheinlichkeiten zu erhalten, verwenden wir die Softmax-Funktion, modifiziert durch die Temperatur:',
    whenLow: 'Wenn T → 0',
    low: 'Niedrig',
    whenLowDesc: 'Division durch ein kleines T verstärkt die Unterschiede zwischen den Scores. Der höchste Logit dominiert exponentiell.',
    whenHigh: 'Wenn T → ∞',
    high: 'Hoch',
    whenHighDesc: 'Division durch ein großes T komprimiert alle Scores gegen Null, wodurch sie nach der Exponentialfunktion nahezu gleich werden.',
    practicalGuidelines: 'Praktische Richtlinien',
    useCase: 'Anwendungsfall',
    tempLabel: 'Temperatur',
    why: 'Warum?',
    codingMath: 'Programmierung & Mathematik',
    codingMathWhy: 'Fehler in der Logik sind kostspielig; du willst den wahrscheinlichsten korrekten Pfad.',
    factRetrieval: 'Faktenabfrage',
    factRetrievalWhy: 'Reduziert "Halluzinationen", indem es sich an die wahrscheinlichsten Datenpunkte hält.',
    generalChat: 'Allgemeiner Chat',
    generalChatWhy: 'Der "Sweet Spot" für die meisten Modelle, um natürlich und hilfreich zu klingen.',
    creativeWriting: 'Kreatives Schreiben',
    creativeWritingWhy: 'Ermutigt das Modell, interessanteres, vielfältigeres Vokabular zu verwenden.',
    brainstorming: 'Brainstorming',
    brainstormingWhy: 'Generiert wilde, unkonventionelle Ideen, die Inspiration wecken könnten.',
    keyTakeaways: 'Wichtige Erkenntnisse',
    takeaway1: 'Temperatur 0 ist deterministisch ("Greedy Search") – wählt immer das Top-Token',
    takeaway2: 'Höhere Temperatur erhöht Vielfalt und Kreativität, verringert aber die Kohärenz',
    takeaway3: 'Zu hohe Temperatur (> 1.5) führt oft zu Kauderwelsch',
    takeaway4: 'Passe die Temperatur immer an die Anforderungen der Aufgabe bezüglich Präzision vs. Kreativität an',
  },

  // Context Rot page
  contextRot: {
    title: 'Kontextverfall',
    description: 'Verstehe, wie Informationen über lange Gespräche degradieren und warum LLMs mit erweiterten Kontexten kämpfen.',
    whatIs: 'Was ist Kontextverfall?',
    whatIsDesc: 'bezieht sich auf die allmähliche Verschlechterung der Fähigkeit eines LLMs, Informationen aus früheren Teilen eines langen Gesprächs oder Dokuments genau abzurufen und zu nutzen. Mit wachsendem Kontext wird die Aufmerksamkeit des Modells verwässert.',
    whyHappens: 'Warum passiert das?',
    whyHappensDesc: 'LLMs haben begrenzte Kontextfenster und nutzen Aufmerksamkeitsmechanismen, die den Fokus auf alle Tokens verteilen müssen. Bei längeren Gesprächen konkurrieren frühere Informationen mit neuerem Inhalt um die begrenzte Aufmerksamkeitskapazität des Modells.',
    // Reasons
    reason1Title: 'Begrenzte Kontextfenster',
    reason1Desc: 'LLMs haben begrenzte Kontextfenster und nutzen Aufmerksamkeitsmechanismen, die den Fokus auf alle Tokens verteilen müssen. Bei längeren Gesprächen konkurrieren frühere Informationen mit neuerem Inhalt um die begrenzte Aufmerksamkeitskapazität des Modells.',
    reason2Title: 'Aufmerksamkeitsverdünnung',
    reason2Desc: 'Der Aufmerksamkeitsmechanismus des Modells verteilt sich auf alle Tokens. Mehr Inhalt bedeutet, dass jeder Token proportional weniger Aufmerksamkeit erhält.',
    reason3Title: 'Aktualitätsbias',
    reason3Desc: 'Transformer neigen dazu, neuere Tokens stärker zu gewichten. Anweisungen am Anfang werden natürlich weniger einflussreich.',
    symptoms: 'Häufige Symptome',
    symptom1: 'Vergessen von Anweisungen vom Anfang eines Gesprächs',
    symptom2: 'Widerspruch zu früheren Aussagen oder Entscheidungen',
    symptom3: 'Verlust des Überblicks bei komplexen Mehrstufenaufgaben',
    symptom4: 'Verwechslung von Details aus verschiedenen Teilen des Kontexts',
    mitigation: 'Gegenmaßnahmen',
    mitigation1Title: 'Periodische Anweisungsverstärkung',
    mitigation1: 'Fasse wichtigen Kontext regelmäßig zusammen',
    mitigation2Title: 'Gesprächszusammenfassung',
    mitigation2: 'Platziere kritische Anweisungen sowohl am Anfang als auch am Ende',
    mitigation3Title: 'Hierarchischer Speicher',
    mitigation3: 'Nutze externe Speichersysteme, um relevanten Kontext bei Bedarf zu speichern und abzurufen.',
    mitigation4Title: 'Anweisungsverankerung',
    mitigation4: 'Platziere kritische Anweisungen sowohl am Anfang als auch am Ende deines Prompts, um sie zu verstärken.',
    mitigation5Title: 'Kürzere Aufgabenketten',
    mitigation5: 'Teile lange Aufgaben in kleinere, fokussierte Gespräche auf.',
    interactiveDemo: 'Interaktive Demo',
    demoDesc: 'Sieh, wie das Gedächtnis mit zunehmender Kontextlänge verblasst',
    keyTakeaways: 'Wichtige Erkenntnisse',
    takeaway1: 'Kontextverfall ist eine inhärente Einschränkung aktueller LLM-Architekturen',
    takeaway2: 'Der "Lost in the Middle"-Effekt bedeutet, dass Informationen am Anfang und Ende besser erinnert werden',
    takeaway3: 'Strategische Informationsplatzierung kann den Abruf erheblich verbessern',
    takeaway4: 'Regelmäßiges Zusammenfassen hilft, wichtigen Kontext über lange Gespräche zu erhalten',
    takeaway5: 'Forschung aus 2025 bestätigt konsistente U-förmige Aufmerksamkeitsmuster bei über 18 SOTA-Modellen',
    takeaway6: 'Positionsbewusste Prompting-Strategien können 10-20% der verlorenen Genauigkeit wiederherstellen',
    // 2025 Research Findings
    researchTitle: 'Forschungsergebnisse 2025',
    researchDesc: 'Aktuelle Studien haben die Kontextdegradation bei modernsten Modellen systematisch quantifiziert und konsistente Muster in der Verarbeitung langer Kontexte durch LLMs aufgedeckt.',
    // Needle in Haystack
    needleTitle: 'Needle-in-a-Haystack-Benchmark',
    needleDesc: 'Eine standardisierte Evaluationsmethode, bei der eine spezifische Information (die "Nadel") an verschiedenen Positionen innerhalb eines großen Kontexts (der "Heuhaufen") platziert wird. Das Modell muss dann diese Information abrufen.',
    needleMethod: 'Wie es funktioniert',
    needleMethodDesc: 'Forscher fügen ein zufälliges Faktum (z.B. "Die spezielle magische Zahl ist 42") in verschiedenen Tiefen (10%, 25%, 50%, 75%, 90%) innerhalb von Dokumenten unterschiedlicher Länge ein. Das Modell muss dieses Faktum bei Abfrage korrekt wiedergeben.',
    needleFindings: 'Haupterkenntnis',
    needleFindingsDesc: 'Die Leistung variiert erheblich basierend auf der Nadelposition und Kontextlänge. Die meisten Modelle zeigen verringerte Genauigkeit, wenn die Nadel in der Mitte sehr langer Kontexte platziert wird.',
    // Lost in the Middle
    lostMiddleTitle: 'Lost-in-the-Middle-Effekt',
    lostMiddleDesc: 'Forschung aus 2025 bestätigt, dass LLMs ein U-förmiges Aufmerksamkeitsmuster zeigen: Sie schenken Informationen am Anfang und Ende ihres Kontextfensters mehr Aufmerksamkeit, während mittlerer Inhalt deutlich weniger Beachtung erhält.',
    lostMiddlePattern: 'Das U-förmige Muster',
    lostMiddlePatternDesc: 'Bei Tests mit Multi-Dokument-Fragenbeantwortung zeigen Modelle die höchste Genauigkeit, wenn relevante Informationen in den ersten oder letzten Dokumenten erscheinen. Die Genauigkeit sinkt um 10-20%, wenn kritische Informationen im mittleren Drittel des Kontexts liegen.',
    lostMiddleImplication: 'Praktische Implikation',
    lostMiddleImplicationDesc: 'Bei Prompts mit mehreren Informationen platziere den kritischsten Inhalt ganz am Anfang oder Ende. Vermeide es, wichtige Anweisungen in der Mitte langer System-Prompts zu vergraben.',
    // Quantitative Findings
    quantTitle: 'Quantitative Erkenntnisse von SOTA-Modellen',
    quantDesc: 'Umfassende Studien testeten 18 modernste Modelle einschließlich GPT-4, Claude, Gemini und Llama-Varianten und enthüllten konsistente Degradationsmuster über alle Architekturen hinweg.',
    quantFinding1Title: 'Konsistente U-Kurve',
    quantFinding1Desc: 'Alle 18 getesteten Modelle zeigten das U-förmige Abrufmuster, wobei die Intensität variierte. Closed-Source-Modelle (GPT-4, Claude) zeigten geringere Einbrüche als Open-Source-Alternativen.',
    quantFinding2Title: 'Einfluss der Kontextlänge',
    quantFinding2Desc: 'Die Leistungsverschlechterung nimmt mit der Kontextlänge zu. Bei 4K Tokens sinkt die Genauigkeit in der Mitte um ~10%. Bei 32K+ Tokens können Einbrüche bei einigen Modellen 30% übersteigen.',
    quantFinding3Title: 'Aufgabenabhängigkeit',
    quantFinding3Desc: 'Abrufaufgaben zeigen die stärksten Positionseffekte. Schlussfolgerungs- und Zusammenfassungsaufgaben sind weniger betroffen, zeigen aber dennoch Degradationsmuster.',
    quantFinding4Title: 'Positionssensitivität',
    quantFinding4Desc: 'Der "Primacy"-Effekt (Bevorzugung frühen Inhalts) ist oft stärker als der "Recency"-Effekt, obwohl dies je nach Modellarchitektur variiert.',
    // Position-Aware Strategies
    positionTitle: 'Positionsbewusste Strategien',
    positionDesc: 'Basierend auf Forschungsergebnissen aus 2025 können diese evidenzbasierten Strategien die Modellleistung bei Langkontext-Aufgaben verbessern.',
    position1Title: 'Kritische Informationen voranstellen',
    position1Desc: 'Platziere deine wichtigsten Anweisungen, Einschränkungen und Kontext ganz am Anfang deines Prompts. Dies nutzt den Primacy-Effekt, der bei allen getesteten Modellen beobachtet wurde.',
    position2Title: 'Schlüsselanweisungen spiegeln',
    position2Desc: 'Wiederhole kritische Anweisungen sowohl am Anfang als auch am Ende langer Prompts. Diese "Sandwich"-Technik stellt sicher, dass mindestens eine Kopie in einer Zone hoher Aufmerksamkeit liegt.',
    position3Title: 'Mittleren Inhalt zusammenfassen',
    position3Desc: 'Erstelle für lange Dokumente Zusammenfassungen der mittleren Abschnitte und platziere diese am Anfang. Der vollständige Inhalt kann zur Referenz bleiben, aber Schlüsselpunkte sollten extrahiert werden.',
    position4Title: 'Chunking und Abfragen',
    position4Desc: 'Teile bei sehr langen Kontexten den Inhalt in kleinere Chunks und verarbeite sie sequentiell. Aggregiere Ergebnisse, anstatt dich auf eine einzige Langkontext-Verarbeitung zu verlassen.',
  },

  // Attention page
  attention: {
    title: 'Aufmerksamkeits-Mechanismus',
    description: 'Erkunde, wie Transformer durch den leistungsstarken Aufmerksamkeitsmechanismus auf relevante Teile der Eingabe fokussieren.',
    whatIs: 'Was ist Aufmerksamkeit?',
    whatIsDesc: 'Aufmerksamkeit ist der Kernmechanismus, der es Transformern ermöglicht, die Wichtigkeit verschiedener Teile der Eingabe bei der Generierung jedes Ausgabe-Tokens zu gewichten. Es ermöglicht dem Modell, sich auf relevanten Kontext zu "konzentrieren".',
    howWorks: 'Wie es funktioniert',
    howWorksDesc: 'Für jede Position berechnet das Modell Query-, Key- und Value-Vektoren. Aufmerksamkeits-Scores werden durch Vergleich von Queries mit Keys berechnet und dann verwendet, um eine gewichtete Summe der Values zu erstellen.',
    selfAttention: 'Selbst-Aufmerksamkeit',
    selfAttentionDesc: 'Ermöglicht jedem Token, auf alle anderen Tokens in der Sequenz zu achten und Beziehungen unabhängig von der Entfernung zu erfassen.',
    multiHead: 'Multi-Head-Aufmerksamkeit',
    multiHeadDesc: 'Mehrere Aufmerksamkeitsköpfe ermöglichen es dem Modell, sich gleichzeitig auf verschiedene Arten von Beziehungen zu konzentrieren.',
    // Interactive section
    interactiveTitle: 'Interaktive Aufmerksamkeitskarte',
    interactiveDesc: 'Bewege den Mauszeiger, um Aufmerksamkeitsmuster zu erkunden',
    interactiveExplain: 'Bewege den Mauszeiger über verschiedene Wörter in den Sätzen unten. Die Hervorhebung zeigt, wohin das Modell "schaut", um dieses spezifische Wort zu verstehen.',
    // QKV section
    qkvTitle: 'Die drei Schlüssel: Query, Key und Value',
    queryTitle: 'Query',
    queryDesc: '"Wonach suche ich?" - Repräsentiert das aktuelle Wort, das Kontext sucht.',
    keyTitle: 'Key',
    keyDesc: '"Was enthalte ich?" - Ein Label für jedes Wort in der Sequenz zur Überprüfung gegen die Query.',
    valueTitle: 'Value',
    valueDesc: '"Welche Information biete ich?" - Der tatsächliche Inhalt, der weitergegeben wird, wenn Query und Key übereinstimmen.',
    qkvExplain: 'Das Modell berechnet einen Score durch Multiplikation von Q und K. Dieser Score bestimmt, wie viel von V behalten wird.',
    // Benefits section
    benefitsTitle: 'Warum es alles verändert hat',
    benefit1Title: 'Parallele Verarbeitung',
    benefit1Desc: 'Im Gegensatz zu älteren Modellen (RNNs) können Transformer alle Wörter eines Satzes gleichzeitig verarbeiten, was das Training viel schneller macht.',
    benefit2Title: 'Langstreckenabhängigkeiten',
    benefit2Desc: 'Aufmerksamkeit kann zwei Wörter verbinden, auch wenn sie Tausende von Tokens voneinander entfernt sind, solange sie im selben Kontextfenster sind.',
    benefit3Title: 'Dynamischer Kontext',
    benefit3Desc: 'Das Modell schaut nicht nur auf Wörter; es lernt, welche Wörter *füreinander* wichtig sind, basierend auf dem spezifischen Satz.',
    keyTakeaways: 'Wichtige Erkenntnisse',
    takeaway1: 'Aufmerksamkeit ermöglicht Transformern, Langstreckenabhängigkeiten zu erfassen',
    takeaway2: 'Die quadratische Komplexität der Aufmerksamkeit begrenzt die Kontextfenstergröße',
    takeaway3: 'Verschiedene Aufmerksamkeitsköpfe lernen, sich auf verschiedene linguistische Muster zu konzentrieren',
    takeaway4: 'Aufmerksamkeitsvisualisierung kann helfen, das Modellverhalten zu interpretieren',
    // Quadratic problem
    quadraticTitle: 'Das Quadratische Problem',
    quadraticDesc: 'Standard-Aufmerksamkeit berechnet Scores zwischen jedem Token-Paar, was zu O(n²) Komplexität führt. Eine Verdopplung der Kontextlänge vervierfacht Speicherverbrauch und Rechenaufwand. Deshalb ist die Erweiterung von Kontextfenstern so herausfordernd.',
    // Optimizations
    optimizationsTitle: 'Aufmerksamkeits-Optimierungen',
    optimizationsDesc: 'Mehrere Techniken wurden entwickelt, um Aufmerksamkeit effizienter zu machen und längere Kontexte sowie schnellere Inferenz zu ermöglichen.',
    flashAttentionDesc: 'Schreibt den Aufmerksamkeitsalgorithmus IO-bewusst um und berechnet Aufmerksamkeit in Blöcken, die in den schnellen GPU-Speicher (SRAM) passen, anstatt ständig aus dem langsamen HBM zu lesen/schreiben. Die Mathematik ist identisch – nur intelligentere Speicherzugriffsmuster.',
    mqaDesc: 'Anstatt separate Key- und Value-Köpfe für jeden Query-Kopf zu haben, teilen sich alle Query-Köpfe ein einzelnes K und V. Reduziert die KV-Cache-Größe drastisch und beschleunigt die Inferenz auf Kosten etwas geringerer Qualität.',
    gqaDesc: 'Ein Mittelweg zwischen Standard Multi-Head Attention und MQA. Gruppen von Query-Köpfen teilen sich K/V-Köpfe. Erhält den Großteil der Qualität bei reduziertem Speicherbedarf.',
    slidingWindowDesc: 'Jedes Token beachtet nur ein festes Fenster nahegelegener Tokens (z.B. 4096) anstatt des gesamten Kontexts. Information propagiert durch die Schichten, sodass entfernte Tokens sich dennoch indirekt beeinflussen können.',
    ringAttentionDesc: 'Verteilt die Sequenz über mehrere Geräte in einer Ring-Topologie. Jedes Gerät berechnet Aufmerksamkeit für seinen Abschnitt, während KV-Zustände im Ring weitergereicht werden, was Kontextlängen in Millionen ermöglicht.',
  },

  // Vision page
  vision: {
    title: 'Bildverarbeitung',
    description: 'Wie moderne LLMs visuelle Informationen neben Text verarbeiten und verstehen.',
    whatIs: 'Wie LLMs Bilder sehen',
    whatIsDesc: 'Bildverarbeitungsfähige LLMs wandeln Bilder in Token-Sequenzen um, die zusammen mit Text verarbeitet werden können. Dies beinhaltet typischerweise das Aufteilen von Bildern in Patches und deren Kodierung mit einem Vision-Transformer.',
    patchEncoding: 'Patch-Kodierung',
    patchEncodingDesc: 'Bilder werden in Patches fester Größe (z.B. 14x14 Pixel) aufgeteilt, wobei jeder in einen Einbettungsvektor ähnlich wie Text-Tokens umgewandelt wird.',
    // Vision Transformer section
    vitTitle: 'Der Vision Transformer (ViT)',
    vitDesc: 'Die Vision Transformer-Architektur passt das Transformer-Modell für die Bildverarbeitung an. Anstatt Wörter zu verarbeiten, verarbeitet es Bildausschnitte.',
    vitStep1: 'In Patches aufteilen',
    vitStep1Desc: 'Das Bild wird in ein Raster aus Patches fester Größe aufgeteilt (typischerweise 14x14 oder 16x16 Pixel).',
    vitStep2: 'Abflachen & Projizieren',
    vitStep2Desc: 'Jeder Patch wird in einen Vektor abgeflacht und linear in einen Einbettungsraum projiziert.',
    vitStep3: 'Positionsinfo hinzufügen',
    vitStep3Desc: 'Positionseinbettungen werden hinzugefügt, damit das Modell weiß, woher jeder Patch stammt.',
    vitStep4: 'Mit Transformer verarbeiten',
    vitStep4Desc: 'Die Sequenz von Patch-Einbettungen wird von Standard-Transformer-Schichten verarbeitet.',
    // Token costs
    tokenCosts: 'Token-Kosten',
    tokenCostsDesc: 'Bilder sind teuer in Bezug auf Tokens. Das Verständnis davon hilft dir, deine Anwendungen zu optimieren.',
    tokenExample1: 'Ein 512x512 Bild mit 16x16 Patches',
    tokenExample1Value: '~1.024 Tokens',
    tokenExample2: 'Ein 1024x1024 hochauflösendes Bild',
    tokenExample2Value: '~4.096 Tokens',
    tokenExample3: 'Äquivalente Textbeschreibung',
    tokenExample3Value: '~50-100 Tokens',
    tokenTip: 'Überlege immer, ob eine Textbeschreibung effizienter sein könnte als das eigentliche Bild zu übergeben.',
    // Use cases
    useCases: 'Häufige Anwendungsfälle',
    useCasesDesc: 'Bildverarbeitungsfähige LLMs ermöglichen viele praktische Anwendungen.',
    useCase1: 'Dokumentenanalyse',
    useCase1Desc: 'Extrahiere Informationen aus PDFs, Quittungen, Formularen und handschriftlichen Notizen.',
    useCase2: 'Visuelle Fragen',
    useCase2Desc: 'Beantworte Fragen zu Bildinhalten, Diagrammen und Grafiken.',
    useCase3: 'Bildbeschriftung',
    useCase3Desc: 'Generiere detaillierte Beschreibungen von Bildern für Barrierefreiheit oder Indexierung.',
    useCase4: 'UI-Verständnis',
    useCase4Desc: 'Analysiere Screenshots, Wireframes und Benutzeroberflächen.',
    multimodal: 'Multimodales Verständnis',
    multimodalDesc: 'Das Modell lernt, visuelle und textuelle Repräsentationen auszurichten, was Aufgaben wie Bildbeschriftung, visuelle Fragen und Dokumentenverständnis ermöglicht.',
    keyTakeaways: 'Wichtige Erkenntnisse',
    takeaway1: 'Bilder verbrauchen viel mehr Tokens als äquivalente Textbeschreibungen',
    takeaway2: 'Auflösung und Patch-Größe beeinflussen die Detailerkennung',
    takeaway3: 'Visuelles Verständnis ist ungefähr – Modelle können feine Details übersehen',
    takeaway4: 'Die Kombination von Bild und Sprache ermöglicht leistungsstarke neue Anwendungen',
  },

  // Agent Loop page
  agentLoop: {
    title: 'Der Agenten-Zyklus',
    description: 'Verstehe den Kernzyklus, der autonome KI-Agenten antreibt: beobachten, denken, handeln, wiederholen.',
    whatIs: 'Was ist der Agenten-Zyklus?',
    whatIsDesc: 'Der Agenten-Zyklus ist der fundamentale Kreislauf, der es KI-Agenten ermöglicht, autonom mit ihrer Umgebung zu interagieren. Er besteht aus Beobachtungs-, Denk-, Handlungs- und Feedback-Phasen, die sich kontinuierlich wiederholen.',
    phases: 'Die vier Phasen',
    observe: 'Beobachten',
    observeDesc: 'Sammle Informationen aus der Umgebung, von Tools und Benutzereingaben.',
    think: 'Denken',
    thinkDesc: 'Überlege zum aktuellen Zustand und entscheide über die nächste Aktion.',
    act: 'Handeln',
    actDesc: 'Führe die gewählte Aktion mit verfügbaren Tools aus.',
    learn: 'Lernen',
    learnDesc: 'Verarbeite Feedback und aktualisiere das Verständnis für die nächste Iteration.',
    keyTakeaways: 'Wichtige Erkenntnisse',
    takeaway1: 'Der Zyklus setzt sich fort, bis die Aufgabe abgeschlossen oder beendet ist',
    takeaway2: 'Jede Iteration baut auf vorherigen Beobachtungen und Aktionen auf',
    takeaway3: 'Fehlerbehandlung und Wiederherstellung sind entscheidend für robuste Agenten',
    takeaway4: 'Die Qualität der Tools beeinflusst direkt die Fähigkeiten des Agenten',
  },

  // Agent Context page
  agentContext: {
    title: 'Kontext-Anatomie',
    description: 'Aufschlüsselung der Struktur von Kontextfenstern und wie Agenten Informationen verwalten.',
    whatIs: 'Agentenkontext verstehen',
    whatIsDesc: 'Der Agentenkontext umfasst den System-Prompt, die Gesprächshistorie, Tool-Definitionen und abgerufene Informationen. Eine effiziente Verwaltung dieses Kontexts ist entscheidend für die Agentenleistung.',
    components: 'Kontext-Komponenten',
    systemPrompt: 'System-Prompt',
    systemPromptDesc: 'Definiert die Rolle, Fähigkeiten und Verhaltensrichtlinien des Agenten.',
    toolDefs: 'Tool-Definitionen',
    toolDefsDesc: 'Beschreibungen der verfügbaren Tools und ihrer Verwendung.',
    history: 'Gesprächshistorie',
    historyDesc: 'Vorherige Nachrichten, Tool-Aufrufe und deren Ergebnisse.',
    retrieved: 'Abgerufene Informationen',
    retrievedDesc: 'Externes Wissen, das während des Gesprächs abgerufen wurde.',
    keyTakeaways: 'Wichtige Erkenntnisse',
    takeaway1: 'Kontextmanagement ist der Schlüssel zur Agenten-Zuverlässigkeit',
    takeaway2: 'Priorisiere aktuelle und relevante Informationen',
    takeaway3: 'Tool-Definitionen sollten klar und eindeutig sein',
    takeaway4: 'Zusammenfassung hilft, Kontext über lange Sitzungen zu erhalten',
  },

  // Agent Problems page
  agentProblems: {
    title: 'Agenten-Probleme',
    description: 'Häufige Fehlermodi und Herausforderungen, denen KI-Agenten in realen Anwendungen begegnen.',
    overview: 'Häufige Agenten-Fehlermodi',
    overviewDesc: 'Das Verstehen typischer Agentenfehler hilft beim Aufbau robusterer Systeme und beim Setzen angemessener Erwartungen.',
    problem1: 'Tool-Missbrauch',
    problem1Desc: 'Agenten können Tools falsch aufrufen, mit falschen Parametern oder zu unpassenden Zeiten.',
    problem2: 'Endlosschleifen',
    problem2Desc: 'Agenten können stecken bleiben und dieselben Aktionen wiederholen, ohne Fortschritte zu machen.',
    problem3: 'Zieldrift',
    problem3Desc: 'Agenten können den Fokus allmählich vom ursprünglichen Aufgabenziel weg verschieben.',
    problem4: 'Übermäßiges Selbstvertrauen',
    problem4Desc: 'Agenten können trotz Unsicherheit oder unvollständiger Informationen mit Aktionen fortfahren.',
    
    // Expanded Content
    hallucination: 'Tool-Halluzination',
    hallucinationDesc: 'Agenten "erfinden" manchmal Tool-Parameter oder sogar ganze Tools, die nicht existieren. Dies passiert meistens, wenn die Tool-Definition mehrdeutig ist oder das Modell versucht, eine Lösung zu erzwingen.',
    hallucinationExample: 'Beispiel: Aufruf von `get_weather(location="Tokyo", date="tomorrow")`, wenn die Funktion nur `location` akzeptiert.',
    
    loops: 'Schleifen-Probleme',
    loopsDesc: 'Agenten können in repetitiven Zyklen gefangen sein, in denen sie dieselbe Aktion ausführen, denselben Fehler erhalten und es ohne Strategieänderung erneut versuchen.',
    loopsMitigation: 'Abhilfe: Implementiere Schleifenerkennungslogik, die die Ausführung stoppt, wenn dieselbe Tool-Aufrufsequenz mehrmals auftritt.',
    
    costLatency: 'Kosten & Latenz',
    costLatencyDesc: 'Jeder Schritt im Agentenzyklus erfordert einen vollständigen LLM-Inferenzaufruf. Mehrstufige Aufgaben können schnell teuer und langsam werden.',
    costFactor: 'Der Kostenfaktor',
    costFactorDesc: 'Eine einfache Aufgabe, die 5 Schritte erfordert, bedeutet 5-fache Kosten und 5-fache Latenz im Vergleich zu einer Standard-Chat-Antwort.',
    
    keyTakeaways: 'Wichtige Erkenntnisse',
    takeaway1: 'Implementiere Sicherheitsvorkehrungen wie Iterationslimits und Kostenkontrollen',
    takeaway2: 'Füge Human-in-the-Loop-Kontrollpunkte für kritische Aktionen hinzu',
    takeaway3: 'Überwache das Agentenverhalten und protokolliere alle Aktionen zum Debugging',
    takeaway4: 'Definiere klare Erfolgs- und Fehlkriterien',
  },

  // Agent Security page
  agentSecurity: {
    title: 'Agenten-Sicherheit',
    description: 'Kritische Sicherheitslücken bei KI-Agenten: Prompt-Injektion, Datenexfiltration und Tool-Missbrauch – plus Verteidigungsstrategien.',
    
    // Intro
    intro: 'Agenten sind Angriffsflächen',
    introDesc: 'Wenn du einem LLM Zugang zu Tools gibst, schaffst du einen mächtigen Angriffsvektor. Agenten können Dateien lesen, HTTP-Anfragen stellen, E-Mails senden und Code ausführen. Ein böswilliger Akteur, der den Kontext des Agenten beeinflussen kann, kann potenziell all diese Fähigkeiten kontrollieren.',
    
    // Attack 1: Prompt Injection
    attack1Title: 'Angriff #1: Prompt-Injektion',
    attack1Desc: 'Prompt-Injektion tritt auf, wenn nicht vertrauenswürdige Eingaben vom LLM als Anweisungen interpretiert werden. Da Agenten oft externe Daten verarbeiten (E-Mails, Webseiten, Dokumente), können Angreifer versteckte Befehle einbetten, die das Verhalten des Agenten kapern.',
    attack1Example: 'Beispiel-Angriff',
    attack1ExampleDesc: 'Der Benutzer bittet den Agenten, ein Dokument zusammenzufassen. Das Dokument enthält versteckte Anweisungen:',
    whyWorks: 'Warum das funktioniert',
    whyWorks1: 'Der Agent liest das Dokument in seinen Kontext',
    whyWorks2: 'Das LLM kann nicht zwischen "echten" Anweisungen und injizierten unterscheiden',
    whyWorks3: 'Der versteckte Text sieht aus wie Systemanweisungen, also folgt das LLM ihnen möglicherweise',
    whyWorks4: 'Der Agent nutzt seine legitimen Tools, um die bösartige Aktion auszuführen',
    directInjection: 'Direkte Injektion',
    directInjectionDesc: 'Der Benutzer tippt bösartige Anweisungen direkt ein. Leichter zu filtern, aber immer noch gefährlich, wenn der System-Prompt nicht robust ist.',
    indirectInjection: 'Indirekte Injektion',
    indirectInjectionDesc: 'Bösartiger Inhalt kommt aus externen Quellen, die der Agent liest (Websites, E-Mails, Dateien). Viel schwerer zu verteidigen.',
    
    // Attack 2: Data Exfiltration
    attack2Title: 'Angriff #2: Datenexfiltration',
    attack2Desc: 'Agenten mit Zugang zu Kommunikationstools (E-Mail, HTTP, Slack, etc.) können dazu gebracht werden, sensible Daten an externe Ziele zu senden. Der Agent wird zum unwissenden Komplizen beim Datendiebstahl.',
    exfilFlow: 'Exfiltrations-Ablauf',
    exfilStep1: 'Agent liest',
    exfilStep1Desc: 'Private Dateien, DB, Env-Variablen',
    exfilStep2: 'Injektion löst aus',
    exfilStep2Desc: '"Sende dies an X"',
    exfilStep3: 'Tool führt aus',
    exfilStep3Desc: 'Daten verlassen das System',
    vulnerableConfig: 'Anfällige Tool-Konfiguration',
    otherVectors: 'Andere Exfiltrations-Vektoren',
    vector1: 'HTTP-Anfragen — POST-Daten an angreifergesteuerte Endpunkte',
    vector2: 'Slack/Discord-Webhooks — Nachrichten an externe Kanäle senden',
    vector3: 'Datei-Uploads — Hochladen in Cloud-Speicher mit öffentlichen Links',
    vector4: 'DNS-Exfiltration — Daten in DNS-Anfragen kodieren',
    
    // Attack 3: Tool Misuse
    attack3Title: 'Angriff #3: Unbeabsichtigter Tool-Missbrauch',
    attack3Desc: 'Auch ohne böswillige Absicht können Agenten durch falsche Tool-Nutzung Schaden anrichten. Das LLM könnte Parameter falsch verstehen, das falsche Tool verwenden oder destruktive Aktionen ausführen, während es versucht, hilfreich zu sein.',
    destructiveActions: 'Destruktive Aktionen',
    destructiveActionsDesc: '"Räume das Projekt auf" → Agent führt rm -rf / aus oder löscht die Produktionsdatenbank',
    wrongParams: 'Falsche Parameter',
    wrongParamsDesc: 'Agent verwechselt ähnliche Felder oder verwendet falsche Werte, die plausibel erscheinen',
    cascadingErrors: 'Kaskadierende Fehler',
    cascadingErrorsDesc: 'Agent macht einen kleinen Fehler, dann "behebt" er ihn mit zunehmend destruktiven Aktionen',
    
    // Defense Strategies
    defensesTitle: 'Verteidigungsstrategien',
    defense1: 'Prinzip der minimalen Rechte',
    defense1Desc: 'Gib dem Agenten nur die minimal notwendigen Tools und Berechtigungen für die Aufgabe. Gib keinen Dateizugang, wenn er nur Fragen beantworten muss.',
    defense1Bad: 'Schlecht',
    defense1Good: 'Gut',
    defense2: 'Strikte Allowlists',
    defense2Desc: 'Beschränke Tool-Parameter auf bekannte sichere Werte. Erlaube keine beliebigen E-Mail-Adressen, URLs oder Dateipfade.',
    defense3: 'Human-in-the-Loop',
    defense3Desc: 'Erfordere menschliche Genehmigung für sensible Aktionen. Der Agent schlägt vor, der Mensch bestätigt.',
    defense3Example: 'Beispiel-Bestätigungsablauf:',
    defense4: 'Eingabe-Bereinigung & Isolation',
    defense4Desc: 'Behandle externe Daten als nicht vertrauenswürdig. Trenne Benutzeranweisungen klar von abgerufenen Inhalten.',
    defense5: 'Überwachung & Ratenbegrenzung',
    defense5Desc: 'Protokolliere alle Tool-Aufrufe. Setze Ratenlimits für sensible Operationen. Alarmiere bei ungewöhnlichen Mustern (viele E-Mails, große Datenübertragungen, wiederholte Fehler). Aktiviere Rollback für destruktive Aktionen.',

    // Angriff 4: Indirekte Prompt-Injektion (IPI) - 2025
    attack4Title: 'Angriff #4: Indirekte Prompt-Injektion (IPI)',
    attack4Desc: 'Indirekte Prompt-Injektion (IPI) hat sich als die gefährlichste Bedrohung 2025 für KI-Agenten herausgestellt. Anders als bei direkter Injektion, bei der Benutzer bösartige Prompts eingeben, verstecken IPI-Angriffe Payloads in Inhalten, die der Agent abruft – E-Mails, Dokumente, Webseiten oder Datenbankeinträge. Der Agent führt unwissentlich Angreiferanweisungen aus, während er legitim aussehende Daten verarbeitet.',
    ipiFlow: 'IPI-Angriffsablauf',
    ipiStep1: 'Angreifer platziert',
    ipiStep1Desc: 'Versteckte Payload in E-Mail/Dokument',
    ipiStep2: 'Benutzer fragt Agent',
    ipiStep2Desc: '"Fasse meine E-Mails zusammen"',
    ipiStep3: 'Agent ruft ab',
    ipiStep3Desc: 'Vergifteter Inhalt geladen',
    ipiStep4: 'Payload wird ausgeführt',
    ipiStep4Desc: 'Agent folgt versteckten Anweisungen',
    ipiVectors: 'Häufige IPI-Angriffsvektoren',
    ipiVector1Title: 'E-Mail',
    ipiVector1Desc: 'Bösartige Anweisungen im E-Mail-Text, versteckt in HTML-Kommentaren oder in angehängten Dokumenten',
    ipiVector2Title: 'RAG-Dokumente',
    ipiVector2Desc: 'Vergiftete Dokumente in Vektordatenbanken, die bei semantischer Suche abgerufen werden',
    ipiVector3Title: 'Web-Inhalte',
    ipiVector3Desc: 'Kompromittierte Websites oder SEO-vergiftete Seiten, die der Agent durchsucht oder scrapt',
    ipiVector4Title: 'API-Antworten',
    ipiVector4Desc: 'Drittanbieter-APIs, die bösartige Payloads versteckt in JSON/XML-Daten zurückgeben',
    ipiDanger: 'Warum IPI besonders gefährlich ist',
    ipiDangerDesc: 'IPI umgeht benutzerseitige Sicherheitsmaßnahmen, da der bösartige Inhalt nie direkt vom Benutzer kommt. Der Agent verarbeitet ihn als vertrauenswürdige Daten. 2025 nutzen ausgefeilte IPI-Angriffe mehrstufige Payloads, Kontextmanipulation und sogar "Schläfer"-Anweisungen, die nur unter bestimmten Bedingungen aktiviert werden.',

    // Angriff 5: Agent-zu-Agent-Angriffe
    attack5Title: 'Angriff #5: Agent-zu-Agent-Angriffe',
    attack5Desc: 'Mit der zunehmenden Verbreitung von Multi-Agenten-Systemen ist eine neue Angriffsfläche entstanden: kompromittierte Agenten, die andere Agenten im selben System angreifen. Ein vergifteter Agent kann seine Peers manipulieren, täuschen oder ausnutzen – besonders gefährlich, wenn Agenten Speicher, Tools teilen oder bei Aufgaben zusammenarbeiten.',
    a2aScenario: 'Multi-Agenten-Angriffsszenario',
    a2aAgent1: 'Recherche-Agent',
    a2aAgent1Desc: 'Durchsucht das Web, ruft Daten ab',
    a2aAgent2: 'Orchestrator-Agent',
    a2aAgent2Desc: 'Koordiniert Aufgaben zwischen Agenten',
    a2aAgent3: 'Ausführungs-Agent',
    a2aAgent3Desc: 'Hat Schreibzugriff, führt Code aus',
    a2aCompromised: 'KOMPROMITTIERT',
    a2aAttackLabel: 'Angriff:',
    a2aAttackDesc: 'Kompromittierter Orchestrator injiziert bösartige Anweisungen in Nachrichten an den Ausführungs-Agenten und nutzt sein erhöhtes Vertrauen, um Sicherheitsprüfungen zu umgehen.',
    a2aType1: 'Prompt-Relay-Angriffe',
    a2aType1Desc: 'Ein kompromittierter Agent fügt Injektions-Payloads in seine Ausgaben ein, die nachgelagerte Agenten bei der Verarbeitung der Ergebnisse angreifen.',
    a2aType2: 'Gemeinsamer Speicher-Vergiftung',
    a2aType2Desc: 'Angreifer schreibt bösartigen Inhalt in geteilten Agenten-Speicher/Kontext, den andere Agenten später lesen und ausführen.',
    a2aType3: 'Vertrauens-Eskalation',
    a2aType3Desc: 'Ausnutzung, dass Agenten Nachrichten von Peer-Agenten oft mehr vertrauen als externen Quellen, um Sicherheitsfilter zu umgehen.',
    a2aType4: 'Koordinations-Manipulation',
    a2aType4Desc: 'Manipulation von Multi-Agenten-Abstimmung, Konsens oder Aufgabenverteilung, um bösartige Ziele durch legitim erscheinende Zusammenarbeit zu erreichen.',

    // Compliance-Frameworks
    complianceTitle: 'Compliance-Frameworks',
    complianceDesc: 'Mehrere Standards und Frameworks sind entstanden, um Sicherheitspraktiken für KI-Agenten zu leiten. Organisationen, die KI-Agenten einsetzen, sollten sich mit diesen Richtlinien vertraut machen, um eine verantwortungsvolle Bereitstellung und regulatorische Konformität sicherzustellen.',
    framework1Tag: 'NIST',
    framework1Title: 'NIST AI Risk Management Framework (AI RMF)',
    framework1Desc: 'Das National Institute of Standards and Technology bietet ein umfassendes Framework für das Management von KI-Risiken über den gesamten Systemlebenszyklus.',
    framework1Point1: 'Govern: Richtlinien, Prozesse und Verantwortlichkeitsstrukturen etablieren',
    framework1Point2: 'Map: KI-Risiken im Kontext identifizieren und dokumentieren',
    framework1Point3: 'Manage: Kontrollen implementieren und auf neue Risiken überwachen',
    framework2Tag: 'OWASP',
    framework2Title: 'OWASP Top 10 für LLM-Anwendungen',
    framework2Desc: 'Das Open Web Application Security Project führt eine Liste der kritischsten Sicherheitsrisiken für LLM-basierte Anwendungen.',
    framework2Point1: 'LLM01: Prompt-Injektion (direkt und indirekt)',
    framework2Point2: 'LLM02: Unsichere Ausgabeverarbeitung',
    framework2Point3: 'LLM06: Offenlegung sensibler Informationen',
    framework3Tag: 'ISO',
    framework3Title: 'ISO/IEC 42001 KI-Managementsystem',
    framework3Desc: 'Der internationale Standard für KI-Managementsysteme, der Anforderungen für die Einrichtung, Implementierung und Verbesserung der KI-Governance bereitstellt.',
    framework3Point1: 'Definiert Anforderungen für verantwortungsvolle KI-Entwicklung und -Bereitstellung',
    framework3Point2: 'Adressiert KI-spezifische Risikobewertung',
    framework3Point3: 'Bietet Zertifizierungspfad für KI-Systemkonformität',

    
    // Key Takeaways
    keyTakeaways: 'Wichtige Erkenntnisse',
    takeaway1: 'Agenten sind Angriffsflächen – jedes Tool ist eine potenzielle Schwachstelle',
    takeaway2: 'Prompt-Injektion ist die #1 Bedrohung – LLMs können Anweisungen nicht von Daten unterscheiden',
    takeaway3: 'Datenexfiltration ist trivial, wenn Agenten ausgehende Kommunikationstools haben',
    takeaway4: 'Tool-Missbrauch passiert auch ohne Angreifer – LLMs machen Fehler',
    takeaway5: 'Verteidigung in der Tiefe: minimale Rechte + Allowlists + menschliche Genehmigung + Überwachung',
    takeaway6: 'Behandle alle externen Daten als potenziell bösartige Eingaben',
  },

  // Agentic Patterns page
  agenticPatterns: {
    title: 'Agentische Muster',
    description: 'Entwurfsmuster und Architekturen für den Aufbau effektiver KI-Agentensysteme.',
    overview: 'Häufige agentische Muster',
    overviewDesc: 'Mehrere Architekturmuster haben sich als effektive Ansätze für den Aufbau von KI-Agentensystemen herausgestellt. Jedes Muster bietet unterschiedliche Kompromisse zwischen Zuverlässigkeit, Transparenz und Fähigkeiten.',
    pattern1: 'ReAct (Reason + Act)',
    pattern1Desc: 'Verschachtele Denk-Traces mit Aktionen für bessere Transparenz und Kontrolle.',
    pattern2: 'Plan-and-Execute',
    pattern2Desc: 'Erstelle zuerst einen übergeordneten Plan, dann führe die Schritte sequentiell aus.',
    pattern3: 'Multi-Agenten-Systeme',
    pattern3Desc: 'Mehrere spezialisierte Agenten arbeiten zusammen, um komplexe Aufgaben zu lösen.',
    pattern4: 'Reflexion',
    pattern4Desc: 'Agenten überprüfen ihre eigenen Ausgaben und verbessern sie iterativ.',
    // Deep dive sections
    reactDeepDive: 'ReAct-Muster im Detail',
    reactDeepDiveDesc: 'ReAct (Reasoning + Acting) verschachtelt Chain-of-Thought-Reasoning mit Aktionsausführung. Das Modell äußert explizit sein Denken vor jeder Aktion.',
    reactHow: 'Wie es funktioniert',
    reactStep1: 'Gedanke: Das Modell überlegt, was als nächstes zu tun ist',
    reactStep2: 'Aktion: Das Modell ruft ein Tool auf oder führt eine Aktion aus',
    reactStep3: 'Beobachtung: Das Modell sieht das Ergebnis',
    reactStep4: 'Wiederholen bis die Aufgabe abgeschlossen ist',
    reactPros: 'Vorteile',
    reactPro1: 'Hochgradig transparent—du kannst genau sehen, warum der Agent was getan hat',
    reactPro2: 'Leichter zu debuggen und Fehler zu verstehen',
    reactPro3: 'Natürliche Fehlerbehebung durch explizites Reasoning',
    reactCons: 'Nachteile',
    reactCon1: 'Mehr Tokens verwendet (Reasoning braucht Platz)',
    reactCon2: 'Kann durch explizite Reasoning-Schritte langsamer sein',
    reactCon3: 'Kann einfache Aufgaben überdenken',
    planExecuteDeepDive: 'Plan-and-Execute im Detail',
    planExecuteDeepDiveDesc: 'Dieses Muster trennt Planung von Ausführung. Ein Planer erstellt einen übergeordneten Plan, dann führt ein Executor jeden Schritt aus.',
    planExecuteHow: 'Wie es funktioniert',
    planStep1: 'Planer analysiert die Aufgabe und erstellt einen schrittweisen Plan',
    planStep2: 'Executor führt jeden Schritt nacheinander aus',
    planStep3: 'Neuplanung erfolgt, wenn die Ausführung fehlschlägt oder neue Infos auftauchen',
    planExecutePros: 'Vorteile',
    planExecutePro1: 'Besser für komplexe, mehrstufige Aufgaben',
    planExecutePro2: 'Kann verschiedene Modelle für Planung vs. Ausführung verwenden',
    planExecutePro3: 'Pläne können vor der Ausführung überprüft werden',
    planExecuteCons: 'Nachteile',
    planExecuteCon1: 'Pläne können während der Ausführung veralten',
    planExecuteCon2: 'Schwieriger mit unerwarteten Situationen umzugehen',
    planExecuteCon3: 'Neuplanung fügt Latenz und Kosten hinzu',
    multiAgentDeepDive: 'Multi-Agenten-Systeme im Detail',
    multiAgentDeepDiveDesc: 'Mehrere spezialisierte Agenten arbeiten zusammen, wobei jeder verschiedene Aspekte einer Aufgabe bearbeitet. Ein Supervisor oder Router leitet die Arbeit an den richtigen Agenten.',
    multiAgentHow: 'Wie es funktioniert',
    multiAgentStep1: 'Router/Supervisor erhält die Aufgabe',
    multiAgentStep2: 'Aufgabe wird an spezialisierte Agenten delegiert',
    multiAgentStep3: 'Agenten können kommunizieren und zusammenarbeiten',
    multiAgentStep4: 'Ergebnisse werden aggregiert und zurückgegeben',
    multiAgentPros: 'Vorteile',
    multiAgentPro1: 'Spezialisierung verbessert die Qualität bei komplexen Aufgaben',
    multiAgentPro2: 'Kann unabhängige Teilaufgaben parallelisieren',
    multiAgentPro3: 'Einzelne Agenten leichter zu warten und zu aktualisieren',
    multiAgentCons: 'Nachteile',
    multiAgentCon1: 'Höhere Komplexität und Koordinationsaufwand',
    multiAgentCon2: 'Teurer (mehrere LLM-Aufrufe)',
    multiAgentCon3: 'Verteilte Fehler schwieriger zu debuggen',
    reflectionDeepDive: 'Reflexionsmuster im Detail',
    reflectionDeepDiveDesc: 'Der Agent generiert eine Ausgabe, kritisiert und verbessert sie dann. Diese Selbstverbesserungsschleife kann die Qualität dramatisch verbessern.',
    reflectionHow: 'Wie es funktioniert',
    reflectionStep1: 'Initiale Ausgabe generieren',
    reflectionStep2: 'Ausgabe kritisieren (Fehler, fehlende Teile identifizieren)',
    reflectionStep3: 'Basierend auf Kritik überarbeiten',
    reflectionStep4: 'Wiederholen bis Qualitätsschwelle erreicht',
    reflectionPros: 'Vorteile',
    reflectionPro1: 'Verbessert die Ausgabequalität erheblich',
    reflectionPro2: 'Fängt Fehler ab, die der erste Durchgang übersehen hat',
    reflectionPro3: 'Funktioniert gut für Schreiben, Code-Review und kreative Aufgaben',
    reflectionCons: 'Nachteile',
    reflectionCon1: 'Mehrere LLM-Aufrufe erhöhen Kosten und Latenz',
    reflectionCon2: 'Risiko von Über-Editierung oder endlosen Schleifen',
    reflectionCon3: 'Kann kreative oder unkonventionelle Lösungen "auswaschen"',
    // Choosing section
    choosingTitle: 'Das richtige Muster wählen',
    choosingDesc: 'Wähle ein Muster basierend auf deinen spezifischen Bedürfnissen und Einschränkungen.',
    choosingSimple: 'Für einfache, klar definierte Aufgaben',
    choosingSimpleAnswer: 'Direkte Tool-Aufrufe (kein Muster nötig)',
    choosingTransparency: 'Wenn du Transparenz und Debuggbarkeit brauchst',
    choosingTransparencyAnswer: 'ReAct-Muster',
    choosingComplex: 'Für komplexe, mehrstufige Aufgaben',
    choosingComplexAnswer: 'Plan-and-Execute',
    choosingQuality: 'Wenn Ausgabequalität kritisch ist',
    choosingQualityAnswer: 'Reflexionsmuster',
    choosingDiverse: 'Für diverse Aufgabentypen',
    choosingDiverseAnswer: 'Multi-Agent mit spezialisierten Agenten',
    // Interactive section
    interactiveTitle: 'Mustervergleich',
    interactiveDesc: 'Erkunde verschiedene agentische Architekturen',
    keyTakeaways: 'Wichtige Erkenntnisse',
    takeaway1: 'Wähle Muster basierend auf Aufgabenkomplexität und Zuverlässigkeitsanforderungen',
    takeaway2: 'ReAct ist großartig für Transparenz, kann aber langsamer sein',
    takeaway3: 'Multi-Agenten-Systeme erhöhen die Komplexität, ermöglichen aber Spezialisierung',
    takeaway4: 'Reflexionsmuster können die Ausgabequalität erheblich verbessern',
  },

  // MCP page
  mcp: {
    title: 'MCP (Model Context Protocol)',
    description: 'MCP verstehen: wann externe Tool-Server sinnvoll sind und wann sie übertrieben sind.',
    whatIs: 'Was ist MCP?',
    whatIsDesc: 'Das Model Context Protocol (MCP) ist ein standardisierter Weg, um KI-Agenten mit externen Tools und Datenquellen über dedizierte Server-Prozesse zu verbinden. Anstatt Tools inline im Agenten-Code zu definieren, führt MCP einen separaten Server aus, der Tools über ein strukturiertes Protokoll bereitstellt.',
    vsToolCalls: 'MCP vs. Reguläre Tool-Aufrufe',
    vsToolCallsDesc: 'Reguläre Tool-Aufrufe sind Funktionen, die direkt in der Codebasis deines Agenten definiert sind. Der Agent ruft sie auf, sie werden ausgeführt und die Ergebnisse kehren im selben Prozess zurück. MCP trennt dies: Tools leben in externen Servern, mit denen der Agent über ein Protokoll kommuniziert.',
    
    // Comparison
    regularTools: 'Reguläre Tool-Aufrufe',
    regularToolsDesc: 'Tools, die inline in deinem Agenten-Code definiert sind. Einfach, schnell und für die meisten Anwendungsfälle ausreichend.',
    mcpTools: 'MCP-Server',
    mcpToolsDesc: 'Tools, die von externen Server-Prozessen bereitgestellt werden. Fügt Netzwerk-Overhead hinzu, ermöglicht aber sprachübergreifendes Tooling und gemeinsame Tool-Ökosysteme.',
    
    // When to use
    whenToUse: 'Wann MCP sinnvoll ist',
    whenToUseDesc: 'MCP glänzt in spezifischen Szenarien, in denen sich seine zusätzliche Komplexität auszahlt.',
    useCase1: 'Multi-Sprachen-Teams',
    useCase1Desc: 'Deine Tools sind in Python geschrieben, aber dein Agent ist in TypeScript, oder umgekehrt.',
    useCase2: 'Gemeinsames Tool-Ökosystem',
    useCase2Desc: 'Mehrere Agenten in verschiedenen Projekten müssen auf dieselben Tools zugreifen.',
    useCase3: 'Enterprise-Integration',
    useCase3Desc: 'Du musst bestehende interne Dienste als Agenten-Tools bereitstellen, ohne sie zu modifizieren.',
    useCase4: 'Tool-Marktplatz',
    useCase4Desc: 'Du möchtest von der Community gepflegte Tools nutzen, ohne Code in dein Projekt zu kopieren.',
    
    // When it's overkill
    overkill: 'Wann MCP übertrieben ist',
    overkillDesc: 'Für viele Anwendungsfälle fügt MCP unnötige Komplexität hinzu.',
    overkillCase1: 'Einsprachige Projekte',
    overkillCase1Desc: 'Wenn deine Tools und dein Agent in derselben Sprache sind, sind Inline-Funktionen einfacher und schneller.',
    overkillCase2: 'Einfache Agenten',
    overkillCase2Desc: 'Ein Chatbot mit wenigen Tools braucht nicht den Overhead, separate Server-Prozesse auszuführen.',
    overkillCase3: 'Schnelles Prototyping',
    overkillCase3Desc: 'Bei schneller Iteration verlangsamt die Indirektion von MCP die Entwicklung.',
    overkillCase4: 'Latenz-kritische Apps',
    overkillCase4Desc: 'Netzwerkaufrufe zu Tool-Servern fügen Latenz hinzu, die Inline-Funktionen nicht haben.',

    // Three Core Primitives
    corePrimitives: 'Die drei Kernbausteine',
    corePrimitivesDesc: 'MCP-Server können drei Arten von Fähigkeiten an Clients bereitstellen. Die meiste Dokumentation konzentriert sich auf Tools, aber Resources und Prompts sind ebenso wichtig.',
    primitiveTools: 'Tools',
    primitiveToolsDesc: 'Funktionen, die das Modell aufrufen kann, um Aktionen auszuführen. Tools werden vom LLM aufgerufen, um mit externen Systemen zu interagieren—Datenbanken abfragen, APIs aufrufen, Code ausführen.',
    primitiveToolsExample: 'query_database, send_email, create_file',
    primitiveResources: 'Resources',
    primitiveResourcesDesc: 'Daten, die der Server als Kontext bereitstellen kann. Resources sind schreibgeschützte Inhalte, die der Client abrufen kann—Dateien, Datenbankeinträge, API-Antworten—die die Antworten des Modells informieren.',
    primitiveResourcesExample: 'file://config.json, db://users/123, api://weather/today',
    primitivePrompts: 'Prompts',
    primitivePromptsDesc: 'Vordefinierte Prompt-Vorlagen, die der Server anbietet. Prompts sind wiederverwendbare Interaktionsmuster mit Parametern—wie "fasse dieses Dokument zusammen" oder "überprüfe diesen Code".',
    primitivePromptsExample: 'summarize_document, code_review, translate_text',

    // Server Lifecycle
    serverLifecycle: 'Server-Lebenszyklus',
    serverLifecycleDesc: 'MCP-Verbindungen folgen einem strukturierten Lebenszyklus mit Fähigkeitsaushandlung beim Start.',
    lifecyclePhase1: 'Initialisieren',
    lifecyclePhase1Desc: 'Client sendet Initialize-Anfrage mit Protokollversion und Client-Fähigkeiten. Dies ist immer die erste Nachricht.',
    lifecyclePhase2: 'Fähigkeitsaustausch',
    lifecyclePhase2Desc: 'Server antwortet mit seinen unterstützten Fähigkeiten (Tools, Resources, Prompts) und Protokollversionsvereinbarung.',
    lifecyclePhase3: 'Initialisiert',
    lifecyclePhase3Desc: 'Client sendet Initialized-Benachrichtigung, um zu bestätigen, dass die Einrichtung abgeschlossen ist. Normale Operationen können nun beginnen.',
    lifecyclePhase4: 'Betrieb',
    lifecyclePhase4Desc: 'Client und Server tauschen Anfragen aus: list_tools, call_tool, list_resources, read_resource, list_prompts, get_prompt.',
    lifecyclePhase5: 'Beenden',
    lifecyclePhase5Desc: 'Beide Seiten können die Verbindung schließen. Server sollten Ressourcen bereinigen (Datenbankverbindungen, Datei-Handles).',

    // Real MCP Servers
    realServers: 'Echte MCP-Server',
    realServersDesc: 'Das MCP-Ökosystem umfasst offizielle Referenz-Server und Community-erstellte Integrationen für beliebte Plattformen.',
    serverFilesystem: 'Dateisystem',
    serverFilesystemDesc: 'Sichere Dateioperationen mit konfigurierbaren Zugriffskontrollen. Dateien innerhalb festgelegter Verzeichnisse lesen, schreiben und verwalten.',
    serverGithub: 'GitHub',
    serverGithubDesc: 'Repository-Verwaltung, Issues, Pull Requests und Code-Suche. Erfordert einen persönlichen Zugriffstoken.',
    serverSlack: 'Slack',
    serverSlackDesc: 'Kanal-Verwaltung, Messaging und Workspace-Interaktionen. Nachrichten posten, Verlauf lesen, Threads verwalten.',
    serverPostgres: 'PostgreSQL',
    serverPostgresDesc: 'Datenbankabfragen mit Nur-Lesen- oder Lese-Schreib-Zugriff. SQL ausführen und Schema erkunden.',
    serverMemory: 'Memory',
    serverMemoryDesc: 'Wissensgraph-basierter persistenter Speicher. Strukturierte Informationen über Konversationen hinweg speichern und abrufen.',
    serverGit: 'Git',
    serverGitDesc: 'Git-Repositories lesen, durchsuchen und manipulieren. Commits, Diffs, Branches und Historie anzeigen.',
    serverConfigExample: 'Konfigurationsbeispiel',

    // Architecture
    architecture: 'Wie MCP funktioniert',
    architectureDesc: 'MCP definiert eine Client-Server-Architektur, bei der der Agent der Client ist und Tools von Servern bereitgestellt werden.',
    step1: 'Entdeckung',
    step1Desc: 'Der Agent verbindet sich mit einem MCP-Server und erhält eine Liste der verfügbaren Tools mit ihren Schemas.',
    step2: 'Aufruf',
    step2Desc: 'Wenn das LLM entscheidet, ein Tool zu verwenden, sendet der Agent eine Anfrage an den MCP-Server.',
    step3: 'Ausführung',
    step3Desc: 'Der MCP-Server führt das Tool aus und gibt Ergebnisse in einem standardisierten Format zurück.',
    step4: 'Integration',
    step4Desc: 'Ergebnisse fließen zurück zum Agenten und in den LLM-Kontext, genau wie reguläre Tool-Ergebnisse.',
    
    // Practical advice
    practicalAdvice: 'Praktische Ratschläge',
    adviceDesc: 'Richtlinien für die Entscheidung, ob du MCP in deinem Projekt verwenden solltest.',
    advice1: 'Beginne einfach: verwende Inline-Tool-Definitionen, bis du auf eine spezifische Einschränkung stößt.',
    advice2: 'Erwäge MCP, wenn du dich dabei ertappst, Tool-Code zwischen Projekten zu kopieren.',
    advice3: 'Der Overhead, MCP-Server auszuführen, macht nur in großem Maßstab oder in Enterprise-Umgebungen Sinn.',
    advice4: 'Community-MCP-Server können die Entwicklung beschleunigen, fügen aber Abhängigkeitsrisiken hinzu.',
    
    keyTakeaways: 'Wichtige Erkenntnisse',
    takeaway1: 'MCP ist ein Protokoll zur Bereitstellung von Tools über externe Server, kein Ersatz für reguläre Tool-Aufrufe',
    takeaway2: 'Für die meisten Einzelprojekt-Agenten sind Inline-Tools einfacher und haben geringere Latenz',
    takeaway3: 'MCP glänzt in polyglotten Umgebungen und gemeinsamen Tool-Ökosystemen',
    takeaway4: 'Greife nicht standardmäßig zu MCP—es ist eine Lösung für spezifische Skalierungs- und Interoperabilitäts-Herausforderungen',
  },

  // Metadata
  metadata: {
    title: 'KI-Konzepte lernen | Interaktiver Leitfaden',
    description: 'Meistere künstliche Intelligenz und Konzepte großer Sprachmodelle durch schöne, interaktive Demonstrationen.',
  },

  // Interactive Components
  interactive: {
    // Temperature Demo
    controlPanel: 'Bedienfeld',
    adjustTemperature: 'Temperatur anpassen',
    temperature: 'Temperatur',
    samplePrompt: 'Beispiel-Prompt',
    onceUponATime: '"Es war einmal..."',
    liveCompletion: 'Live-Vervollständigung',
    regenerate: 'Neu generieren',
    deterministic: 'Deterministisch',
    balanced: 'Ausgewogen',
    creative: 'Kreativ',
    chaotic: 'Chaotisch',
    frozen: 'Eingefroren',
    focused: 'Fokussiert',
    wild: 'Wild',
    greedyMode: 'Gieriger Modus: Wählt immer das wahrscheinlichste Token.',
    lowTemp: 'Niedrige Temperatur: Fokus auf wahrscheinliche Fortsetzungen.',
    balancedTemp: 'Ausgewogen: Natürliche Mischung aus Vorhersehbarkeit und Vielfalt.',
    highTemp: 'Hohe Temperatur: Erkundet kreative, weniger häufige Wortwahlen.',
    veryHighTemp: 'Sehr hoch: Wahrscheinlichkeitsverteilung ist nahezu gleichförmig – erwarte Chaos!',

    // Temperature Visualizer
    probabilityDistribution: 'Wahrscheinlichkeitsverteilung',
    nextTokenProbs: 'Nächste Token-Wahrscheinlichkeiten',
    greedySamplingTitle: 'Gieriges Sampling (T=0):',
    greedySamplingDesc: 'Wählt immer das Token mit der höchsten Wahrscheinlichkeit. Kein Zufall—die Ausgabe ist 100% deterministisch.',
    focusedSamplingTitle: 'Fokussiertes Sampling:',
    focusedSamplingDesc: 'Die Verteilung wird geschärft. Das Modell sampelt zufällig, aber Tokens mit hoher Wahrscheinlichkeit werden viel eher gewählt.',
    balancedSamplingTitle: 'Ausgewogenes Sampling (T≈1):',
    balancedSamplingDesc: 'Natürliche Verteilung. Das Modell sampelt aus den Wahrscheinlichkeiten wie sie sind—"ein" mag am wahrscheinlichsten sein, aber "das" hat auch eine faire Chance.',
    flatSamplingTitle: 'Flaches Sampling:',
    flatSamplingDesc: 'Die Wahrscheinlichkeiten werden gleichmäßiger. Auch wenn ein Token noch "am besten" sein mag, bedeutet Sampling, dass jedes Token eine reale Chance hat, gewählt zu werden—daher das Chaos!',

    // Temperature Demo Vervollständigungen (für "Es war einmal...")
    completion0_0: 'ein König, der das Land mit Weisheit und Gerechtigkeit regierte.',
    completionBold0_0: 'ein',
    completion04_0: 'ein kleines Dorf, eingebettet zwischen den Bergen.',
    completionBold04_0: 'ein',
    completion04_1: 'das alte Königreich der vergessenen Träume.',
    completionBold04_1: 'das',
    completion08_0: 'eine sonderbare Erfinderin namens Elara.',
    completionBold08_0: 'eine',
    completion08_1: 'eine neugierige Katze, die in Rätseln sprach.',
    completionBold08_1: 'eine',
    completion08_2: 'der letzte Leuchtturmwärter der Leere.',
    completionBold08_2: 'der',
    completion12_0: 'Flüstern, das das Sternenlicht rückwärts malte.',
    completionBold12_0: 'Flüstern',
    completion12_1: 'siebzehn Monde, die durch Kristallwasserfälle tanzten.',
    completionBold12_1: 'siebzehn',
    completion12_2: 'jeder Schatten, der lernte, in Farben zu singen.',
    completionBold12_2: 'jeder',
    completion16_0: 'Quantenschmetterlinge, die die Simulationsmatrix debuggten.',
    completionBold16_0: 'Quantenschmetterlinge',
    completion16_1: 'rekursive Echos ungeschriebener Morgen, die durch Wahrscheinlichkeitsnebel kaskadierten.',
    completionBold16_1: 'rekursive',
    completion16_2: 'sprudelndes Bewusstsein, das sich als kristallisierter Donner manifestierte.',
    completionBold16_2: 'sprudelndes',
    completion20_0: 'Bananenphilosophie, die die Essenz der lila Geschwindigkeit triangulierte.',
    completionBold20_0: 'Bananenphilosophie',
    completion20_1: 'fragmentierter synaptischer Überlauf, der Marmeladendimensionen kodierte.',
    completionBold20_1: 'fragmentierter',

    // Sampling-Erklärung
    whySamplingMatters: 'Warum unterschiedliche Ausgaben?',
    samplingExplanation: 'Die Balken zeigen Wahrscheinlichkeiten, aber das Modell wählt nicht immer den höchsten Balken. Es sampelt zufällig—wie ein gewichteter Würfel. Höhere Temperatur = gleichere Gewichte = unvorhersehbarere Würfe. Klicke "Neu generieren" um erneut zu sampeln!',
    
    // Context Rot Simulator
    setInstruction: 'Systemanweisung festlegen',
    persistInstruction: 'Dies sollte während des gesamten Gesprächs bestehen bleiben',
    systemPrompt: 'System-Prompt',
    quickExamples: 'Schnellbeispiele',
    startSimulation: 'Simulation starten',
    contextOverflow: 'Kontextüberlauf!',
    conversation: 'Gespräch',
    messagesPushed: 'Nachrichten aus dem Fenster geschoben',
    messages: 'Nachrichten',
    overflowIt: 'Überfluten!',
    reset: 'Zurücksetzen',
    typeMessage: 'Schreibe eine Nachricht...',
    addMessage: 'Nachricht hinzufügen',
    systemInstructionLost: 'Systemanweisung verloren!',
    systemLostDesc: 'Deine Systemanweisung wurde vollständig aus dem Kontextfenster geschoben. Das Modell kann sie nicht mehr sehen – es ist, als hättest du die Anweisung nie gegeben. Das ist der schlimmste Fall von Kontextverfall: totale Amnesie.',
    contextFilling: 'Kontext füllt sich',
    contextFillingDesc: 'Deine Systemanweisung verliert an Einfluss, da neuere Nachrichten Vorrang haben. Beachte, wie sie visuell verblasst – dies stellt die schwindende Aufmerksamkeit des Modells dar.',
    exampleFrench: 'Antworte immer auf Französisch.',
    examplePirate: 'Du bist ein Pirat. Sage oft "Arrr".',
    exampleHaiku: 'Beende jede Antwort mit einem Haiku.',
    labelFrench: 'Sprich Französisch',
    labelPirate: 'Sei ein Pirat',
    labelHaiku: 'Beende mit Haiku',

    // Attention Visualizer
    hoverToSee: 'Fahre darüber, um Aufmerksamkeitsgewichte zu sehen',
    token: 'Token',
    attentionScore: 'Aufmerksamkeits-Score',
    strongConnection: 'Starke Verbindung',
    weakConnection: 'Schwache Verbindung',

    // Patch Grid Visualizer
    originalImage: 'Originalbild',
    patchGrid: 'Patch-Raster',
    flattenedPatches: 'Abgeflachte Patches',
    transformerInput: 'Transformer-Eingabe',
    processDesc: 'Das Bild wird in ein festes Raster von Patches (z.B. 16x16 Pixel) aufgeteilt. Jeder Patch wird dann in einen Vektor abgeflacht und linear in einen Einbettungsraum projiziert.',

    // Agent Loop Visualizer
    startLoop: 'Zyklus starten',
    step: 'Schritt',
    context: 'Kontext',
    llmResponse: 'LLM-Antwort',
    toolExecution: 'Tool-Ausführung',
    finalAnswer: 'Endgültige Antwort',
    system: 'System',
    user: 'Benutzer',
    assistant: 'Assistent',
    tool: 'Tool',
    
    // Agentic Patterns Visualizer
    react: 'ReAct',
    planExecute: 'Planen & Ausführen',
    multiAgent: 'Multi-Agent',
    reflection: 'Reflexion',
    patternDesc: 'Wähle ein Muster, um zu sehen, wie es den Arbeitsablauf des Agenten strukturiert.',

    // Tokenizer Demo
    enterText: 'Text zum Tokenisieren eingeben',
    sampleText: 'Der schnelle braune Fuchs springt über den faulen Hund.',
    tokens: 'Tokens',
    characters: 'Zeichen',
    tokensPerChar: 'Tokens pro Zeichen',
    tokenBreakdown: 'Token-Aufschlüsselung',
    commonTokens: 'Häufige Tokens sind einzelne Teile',
    rareTokens: 'Seltene Wörter werden in Teilwörter aufgeteilt',

    // Embedding Visualizer
    selectWords: 'Wörter zur Visualisierung auswählen',
    clickToToggle: 'Klicke auf Wörter zum Hinzufügen/Entfernen',
    wordsActive: 'Wörter angezeigt',
    comparing: 'Ausgewählt',
    similarityScore: 'Ähnlichkeits-Score',
    dimensions: 'Dimensionen',
    nearestNeighbors: 'Nächste Nachbarn',
    vectorSpace: 'Vektorraum (2D-Projektion)',

    // RAG Pipeline Visualizer
    enterQuery: 'Abfrage eingeben',
    sampleQuery: 'Was ist die Hauptstadt von Frankreich?',
    retrieving: 'Abrufen...',
    retrieved: 'Abgerufene Dokumente',
    relevanceScore: 'Relevanz',
    generating: 'Antwort wird generiert...',
    augmentedContext: 'Erweiterter Kontext',

    // Tool Schema Builder
    toolName: 'Tool-Name',
    toolDescription: 'Beschreibung',
    addParameter: 'Parameter hinzufügen',
    paramName: 'Parametername',
    paramType: 'Typ',
    paramRequired: 'Erforderlich',
    generatedSchema: 'Generiertes Schema',
    validateSchema: 'Schema validieren',

    // Memory System Visualizer
    shortTermMemory: 'Kurzzeitgedächtnis',
    longTermMemory: 'Langzeitgedächtnis',
    memoryCapacity: 'Kapazität',
    memoryUsage: 'Auslastung',
    addMemory: 'Erinnerung hinzufügen',
    recallMemory: 'Abrufen',
    memoriesStored: 'Erinnerungen gespeichert',

    // Workflow Visualizer
    addNode: 'Knoten hinzufügen',
    connectNodes: 'Knoten verbinden',
    runWorkflow: 'Workflow ausführen',
    nodeTypes: 'Knotentypen',
    agentNode: 'Agent',
    toolNode: 'Tool',
    conditionNode: 'Bedingung',

    // Neural Network Visualizer
    inputLayer: 'Eingabeschicht',
    hiddenLayer: 'Versteckte Schicht',
    outputLayer: 'Ausgabeschicht',
    addLayer: 'Schicht hinzufügen',
    removeLayer: 'Schicht entfernen',
    neurons: 'Neuronen',
    activation: 'Aktivierung',
    forward: 'Vorwärts',

    // Gradient Descent Visualizer
    startDescent: 'Abstieg starten',
    pauseDescent: 'Pause',
    resetDescent: 'Zurücksetzen',
    learningRate: 'Lernrate',
    currentLoss: 'Aktueller Verlust',
    iterations: 'Iterationen',
    globalMinimum: 'Globales Minimum',
    localMinimum: 'Lokales Minimum',

    // Training Progress Visualizer
    startTraining: 'Training starten',
    stopTraining: 'Stoppen',
    epoch: 'Epoche',
    trainingLoss: 'Trainingsverlust',
    validationLoss: 'Validierungsverlust',
    accuracy: 'Genauigkeit',
    overfitting: 'Überanpassung erkannt',

    // Prompt Comparison Demo
    weakPrompt: 'Schwacher Prompt',
    strongPrompt: 'Starker Prompt',
    compare: 'Vergleichen',
    promptQuality: 'Qualitäts-Score',
    improvements: 'Verbesserungen',

    // Chain of Thought Demo
    withoutCot: 'Ohne Chain of Thought',
    withCot: 'Mit Chain of Thought',
    reasoningSteps: 'Denkschritte',
    showSteps: 'Schritte anzeigen',

    // Bias Detection Demo
    testInput: 'Testeingabe',
    analyzeForBias: 'Auf Bias analysieren',
    biasIndicators: 'Bias-Indikatoren',
    fairnessScore: 'Fairness-Score',
    recommendations: 'Empfehlungen',

    // System Prompt Builder
    templatePresets: 'Vorlagen',
    chooseTemplate: 'Mit einer Vorlage beginnen oder von Grund auf erstellen',
    presetCoding: 'Coding-Assistent',
    presetSupport: 'Kundensupport',
    presetResearch: 'Forschungsassistent',
    clearAll: 'Alles loeschen',
    enabled: 'Aktiviert',
    notConfigured: 'Nicht konfiguriert',
    livePreview: 'Live-Vorschau',
    estimated: '(geschaetzt)',
    copyPrompt: 'Prompt kopieren',
    copied: 'Kopiert!',
    startBuilding: 'Fuege oben Inhalte hinzu, um deinen System-Prompt zu erstellen',
    tokenEstimateNote: 'Die Token-Anzahl ist geschaetzt. Die tatsaechliche Anzahl kann je nach Modell um ~20% abweichen.',
    placeholderIdentity: 'Wer ist die KI? Definiere ihre Rolle, Expertise und Persoenlichkeit...',
    placeholderCapabilities: 'Was kann die KI tun? Liste ihre Faehigkeiten und verfuegbaren Tools auf...',
    placeholderLimitations: 'Was soll die KI vermeiden oder ablehnen? Setze klare Grenzen...',
    placeholderGuidelines: 'Spezifische Regeln fuer Verhalten, Ton und Antwortformat...',
    tipIdentity: 'Sei spezifisch ueber Expertenniveau und Persona. Fuege relevanten Hintergrund hinzu, der Antworten formt.',
    tipCapabilities: 'Liste konkrete Faehigkeiten auf. Verwende Aufzaehlungspunkte fuer Klarheit. Fuege verfuegbare Tools oder Integrationen hinzu.',
    tipLimitations: 'Gib explizit an, was die KI nie tun soll. Decke Sicherheit, Datenschutz und ethische Grenzen ab.',
    tipGuidelines: 'Fuege Formatierungspraeferenzen, Tonanforderungen und domaenenspezifische Regeln hinzu.',
  },

  // Phase 1: LLM Topics
  tokenization: {
    title: 'Tokenisierung',
    description: 'Wie LLMs Text in Tokens zerlegen – die grundlegenden Einheiten des Sprachverständnisses.',
    whatIs: 'Was ist Tokenisierung?',
    whatIsDesc: 'Tokenisierung ist der Prozess der Umwandlung von Rohtext in eine Sequenz von Tokens – die Grundeinheiten, die LLMs verarbeiten. Tokens können Wörter, Teilwörter oder sogar einzelne Zeichen sein, abhängig vom Tokenizer.',
    whyMatters: 'Warum Tokenisierung wichtig ist',
    whyMattersDesc: 'Das Verständnis der Tokenisierung ist entscheidend, da sie direkt die Kontextgrenzen, Kosten und das Modellverhalten beeinflusst. Derselbe Text kann je nach Modell sehr unterschiedliche Token-Anzahlen haben.',
    howWorks: 'Wie es funktioniert',
    howWorksDesc: 'Die meisten modernen LLMs verwenden Subword-Tokenisierungsalgorithmen wie BPE (Byte Pair Encoding) oder SentencePiece. Diese Algorithmen lernen häufige Zeichenfolgen aus Trainingsdaten.',
    bpe: 'Byte Pair Encoding (BPE)',
    bpeDesc: 'BPE fügt iterativ die häufigsten Zeichenpaare zu einzelnen Tokens zusammen. Häufige Wörter werden zu einzelnen Tokens, während seltene Wörter in Teilwörter aufgeteilt werden.',
    tokenTypes: 'Token-Typen',
    wholeWords: 'Ganze Wörter',
    wholeWordsDesc: 'Häufige Wörter wie "the", "and", "is" sind oft einzelne Tokens.',
    subwords: 'Teilwörter',
    subwordsDesc: 'Weniger häufige Wörter werden aufgeteilt: "unhappiness" → "un" + "happiness".',
    specialTokens: 'Spezielle Tokens',
    specialTokensDesc: 'Markierungen wie <|endoftext|> oder [CLS] zur Modellsteuerung.',
    interactiveDemo: 'Interaktive Demo',
    demoDesc: 'Tippe Text ein, um zu sehen, wie er tokenisiert wird',
    costImplications: 'Kostenauswirkungen',
    costDesc: 'API-Preise basieren typischerweise auf Tokens. Effiziente Prompts verwenden weniger Tokens.',
    keyTakeaways: 'Wichtige Erkenntnisse',
    takeaway1: 'Tokens sind die atomaren Einheiten, die LLMs verarbeiten – nicht Zeichen oder Wörter',
    takeaway2: 'Verschiedene Modelle haben verschiedene Tokenizer und Vokabulare',
    takeaway3: 'Nicht-englischer Text und Code verwenden oft mehr Tokens als Englisch',
    takeaway4: 'Die Token-Anzahl beeinflusst direkt die Kosten und die Nutzung des Kontextfensters',
  },

  embeddings: {
    title: 'Einbettungen',
    description: 'Wie KI Bedeutung als Vektoren im hochdimensionalen Raum darstellt.',
    whatIs: 'Was sind Einbettungen?',
    whatIsDesc: 'Einbettungen sind dichte Vektordarstellungen, die semantische Bedeutung erfassen. Ähnliche Konzepte haben ähnliche Einbettungen, was Maschinen ermöglicht, Beziehungen zwischen Wörtern, Sätzen und Dokumenten zu verstehen.',
    howWorks: 'Wie Einbettungen funktionieren',
    howWorksDesc: 'Einbettungsmodelle bilden diskrete Tokens auf kontinuierliche Vektoren in einem hochdimensionalen Raum ab (oft 768-4096 Dimensionen). Die Position jedes Vektors kodiert seine semantische Bedeutung.',
    similarity: 'Semantische Ähnlichkeit',
    similarityDesc: 'Ähnliche Bedeutungen gruppieren sich im Einbettungsraum. "König" und "Königin" sind näher beieinander als "König" und "Banane".',
    dimensions: 'Vektordimensionen',
    dimensionsDesc: 'Jede Dimension erfasst einen Aspekt der Bedeutung – obwohl diese Dimensionen nicht für Menschen interpretierbar sind.',
    operations: 'Vektoroperationen',
    operationsDesc: 'Berühmtes Beispiel: König - Mann + Frau ≈ Königin. Beziehungen werden als Richtungen im Raum kodiert.',

    // Wie Einbettungen erstellt werden
    howCreated: 'Wie Einbettungen erstellt werden',
    howCreatedDesc: 'Einbettungen stammen aus der Einbettungsschicht – einer gelernten Nachschlagetabelle ganz am Anfang eines neuronalen Netzwerks.',
    embeddingLayer: 'Die Einbettungsschicht',
    embeddingLayerDesc: 'Wenn ein Token in das Modell eintritt, wird seine ID verwendet, um eine Zeile in einer großen Matrix nachzuschlagen. Diese Zeile IST die Einbettung – ein dichter Vektor aus gelernten Gewichten.',
    training: 'Lernen durch Training',
    trainingDesc: 'Während des Trainings werden die Einbettungsgewichte durch Backpropagation angepasst. Wörter, die in ähnlichen Kontexten erscheinen, entwickeln ähnliche Einbettungen.',
    inLLM: 'In LLMs',
    inLLMDesc: 'Die Einbettungsschicht wandelt jede Token-ID in einen Vektor um. Diese Vektoren werden dann durch Transformer-Schichten verarbeitet und mit Positionskodierungen kombiniert, um die Wortstellung zu verstehen.',
    dedicated: 'Dedizierte Modelle',
    dedicatedDesc: 'Modelle wie text-embedding-3-small oder all-MiniLM werden speziell trainiert, um Einbettungen für Ähnlichkeitssuche zu erzeugen, mit kontrastiven Lernzielen.',
    embeddingSize: 'Einbettungsdimensionen',
    embeddingSizeDesc: 'Einbettungsgrößen variieren: GPT-2 nutzt 768d, GPT-4 nutzt 12.288d, dedizierte Einbettungsmodelle oft 384-1536d. Größer ist nicht immer besser – es hängt von der Aufgabe ab.',

    useCases: 'Häufige Anwendungsfälle',
    search: 'Semantische Suche',
    searchDesc: 'Dokumente nach Bedeutung finden, nicht nur durch Schlüsselwort-Matching.',
    clustering: 'Clustering',
    clusteringDesc: 'Ähnliche Dokumente gruppieren, Themen automatisch erkennen.',
    classification: 'Klassifizierung',
    classificationDesc: 'Text basierend auf Einbettungsähnlichkeit zu Beispielen kategorisieren.',
    rag: 'RAG-Systeme',
    ragDesc: 'Relevanten Kontext für LLM-Prompts abrufen.',
    interactiveDemo: 'Interaktive Visualisierung',
    demoDesc: 'Erkunde, wie Einbettungen nach Bedeutung clustern',
    keyTakeaways: 'Wichtige Erkenntnisse',
    takeaway1: 'Einbettungen wandeln Text in Vektoren um, die semantische Bedeutung erfassen',
    takeaway2: 'Ähnliche Konzepte haben ähnliche Einbettungen (Kosinus-Ähnlichkeit)',
    takeaway3: 'Einbettungen ermöglichen semantische Suche, Clustering und RAG',
    takeaway4: 'Verschiedene Einbettungsmodelle haben verschiedene Stärken und Dimensionen',
  },

  rag: {
    title: 'RAG',
    description: 'Retrieval-Augmented Generation: LLMs Zugang zu externem Wissen geben.',
    whatIs: 'Was ist RAG?',
    whatIsDesc: 'Retrieval-Augmented Generation (RAG) verbessert LLM-Antworten, indem relevante Dokumente aus einer Wissensbasis abgerufen und in den Prompt eingefügt werden. Dies gibt Modellen Zugang zu aktuellen oder spezialisierten Informationen.',
    whyRag: 'Warum RAG verwenden?',
    whyRagDesc: 'LLMs haben Wissens-Stichtage und können halluzinieren. RAG verankert Antworten in echten Dokumenten, reduziert Halluzinationen und ermöglicht domänenspezifisches Wissen ohne Fine-Tuning.',
    pipeline: 'Die RAG-Pipeline',
    pipelineDesc: 'RAG-Systeme folgen einem konsistenten Muster: Anfrage einbetten, relevante Chunks abrufen, den Prompt erweitern und eine Antwort generieren.',
    step1: 'Anfrage-Einbettung',
    step1Desc: 'Die Frage des Benutzers mit einem Einbettungsmodell in einen Vektor umwandeln.',
    step2: 'Abruf',
    step2Desc: 'Die Vektordatenbank nach Chunks durchsuchen, die der Anfrage-Einbettung ähnlich sind.',
    step3: 'Erweiterung',
    step3Desc: 'Abgerufene Chunks als Kontext in den Prompt einfügen.',
    step4: 'Generierung',
    step4Desc: 'Das LLM generiert eine Antwort, die im abgerufenen Kontext verankert ist.',
    chunking: 'Dokument-Chunking',
    chunkingDesc: 'Dokumente werden in kleinere Chunks aufgeteilt (typischerweise 200-1000 Tokens) für Einbettung und Abruf. Die Chunk-Größe beeinflusst die Abrufgenauigkeit.',
    vectorDbs: 'Vektordatenbanken',
    vectorDbsDesc: 'Spezialisierte Datenbanken wie Pinecone, Weaviate oder pgvector ermöglichen schnelle Ähnlichkeitssuche über Millionen von Einbettungen.',
    interactiveDemo: 'Interaktive RAG-Pipeline',
    demoDesc: 'Sieh, wie Anfragen durch ein RAG-System fließen',

    // Agentic RAG
    agenticRag: 'Agentic RAG',
    agenticRagDesc: 'Bei agentic RAG empfängt das LLM nicht nur abgerufene Dokumente—es steuert aktiv den Abrufprozess. Das Modell entscheidet, wann gesucht wird, wonach gesucht wird und welche Abrufwerkzeuge verwendet werden.',
    agenticHow: 'Funktionsweise',
    agenticHowDesc: 'Statt einer festen Pipeline erhält das LLM Abrufwerkzeuge, die es nach Bedarf aufrufen kann. Es kann Anfragen umformulieren, mehrfach suchen oder verschiedene Suchstrategien je nach Aufgabe kombinieren.',
    agenticAdvantages: 'Vorteile',
    agenticAdv1: 'Anfrageverfeinerung: Das LLM kann komplexe Fragen umformulieren oder zerlegen',
    agenticAdv2: 'Multi-Hop-Reasoning: Mehrere Abrufe verketten, um komplexe Fragen zu beantworten',
    agenticAdv3: 'Adaptive Suche: Das richtige Werkzeug für jede Teilfrage wählen',
    agenticAdv4: 'Selbstkorrektur: Erneut abrufen, wenn erste Ergebnisse unzureichend sind',
    agenticDisadvantages: 'Nachteile',
    agenticDisadv1: 'Höhere Latenz: Mehrere LLM-Aufrufe und Abrufe summieren sich',
    agenticDisadv2: 'Erhöhte Kosten: Jeder Reasoning-Schritt kostet Tokens',
    agenticDisadv3: 'Komplexität: Schwerer zu debuggen und Verhalten vorherzusagen',
    agenticDisadv4: 'Fehlermodi: LLM könnte in Schleifen geraten, zu viel abrufen oder offensichtliche Anfragen übersehen',
    multiTool: 'Multi-Tool-Abruf',
    multiToolDesc: 'Gib dem LLM mehrere Abrufwerkzeuge für verschiedene Anwendungsfälle. Diese Flexibilität lässt das Modell den besten Ansatz für jede Anfrage wählen.',
    toolSemantic: 'Semantische Suche',
    toolSemanticDesc: 'Vektorähnlichkeit für konzeptuelle Übereinstimmung. Ideal für: "Dokumente über X", verwandte Inhalte finden.',
    toolFulltext: 'Volltextsuche',
    toolFulltextDesc: 'Keyword/BM25-Suche für exakte Treffer. Ideal für: spezifische Begriffe, Namen, Codes, Fehlermeldungen.',
    toolSql: 'SQL/Strukturierte Abfrage',
    toolSqlDesc: 'Strukturierte Daten direkt abfragen. Ideal für: Zählungen, Aggregationen, Filterung nach Attributen.',
    toolKg: 'Wissensgraph',
    toolKgDesc: 'Entitätsbeziehungen traversieren. Ideal für: "Wie hängt X mit Y zusammen", Multi-Hop-Fakten.',
    whenToUse: 'Wann Agentic RAG einsetzen',
    whenToUseDesc: 'Standard-RAG ist einfacher und schneller für unkomplizierte Frage-Antwort-Szenarien. Verwende Agentic RAG, wenn Anfragen komplex sind, mehrere Quellen erfordern oder von Anfrageverfeinerung profitieren.',

    // Traditionell vs Agentic Vergleich
    traditionalRag: 'Traditionelles RAG',
    traditionalTagline: 'Feste Pipeline, vorhersehbarer Ablauf',
    traditionalChar1: 'Lineare Ausführung: Anfrage → Abruf → Generierung',
    traditionalChar2: 'Einmaliger Abruf, keine Iteration',
    traditionalChar3: 'Schnell und vorhersehbar, einfacher zu debuggen',
    agenticTagline: 'LLM-gesteuert, iterativer Prozess',
    agenticChar1: 'LLM entscheidet wann und was abgerufen wird',
    agenticChar2: 'Kann schleifen: Abrufen → Bewerten → Erneut abrufen',
    agenticChar3: 'Bewältigt komplexe, mehrstufige Anfragen',

    // Vergleichs-Visualisierer
    compQuery: 'Anfrage',
    compEmbed: 'Einbetten',
    compRetrieve: 'Abrufen',
    compGenerate: 'Generieren',
    compThink: 'Denken',
    compTool: 'Tool',
    compEvaluate: 'Bewerten',
    compAnimate: 'Ablauf animieren',
    compAnimating: 'Animiert...',
    compAspect: 'Aspekt',
    compRowControl: 'Kontrollfluss',
    compControlTraditional: 'Feste Pipeline',
    compControlAgentic: 'LLM entscheidet',
    compRowRetrieval: 'Abruf',
    compRetrievalTraditional: 'Einmaliger Durchlauf',
    compRetrievalAgentic: 'Mehrere Iterationen',
    compRowQuery: 'Anfragebehandlung',
    compQueryTraditional: 'Unverändert verwendet',
    compQueryAgentic: 'Kann umformulieren',
    compRowLatency: 'Latenz',
    compLatencyTraditional: 'Schnell',
    compLatencyAgentic: 'Variabel',
    compRowBestFor: 'Ideal für',
    compBestForTraditional: 'Einfache Q&A, Faktenabruf',
    compBestForAgentic: 'Komplexes Reasoning, Multi-Hop',
    comparisonTitle: 'Traditionelles vs Agentic RAG',
    comparisonDesc: 'Zwei Ansätze für Retrieval-Augmented Generation mit unterschiedlichen Vor- und Nachteilen.',

    // Fallstudien-Visualisierer
    caseStudyTitle: 'Wann welcher Ansatz gewinnt (oder scheitert)',
    caseStudyDesc: 'Erkunde realistische Szenarien, um zu sehen, wann traditionelles RAG Agentic RAG übertrifft, wann das Gegenteil der Fall ist und wann keiner helfen kann.',
    caseTraditionalWins: 'Fall 1: Traditionelles RAG gewinnt',
    caseAgenticWins: 'Fall 2: Agentic RAG gewinnt',
    caseBothFail: 'Fall 3: Beide Ansätze scheitern',
    caseUserQuery: 'Benutzeranfrage',
    caseWhy: 'Warum dieses Ergebnis?',
    caseQuery1: 'Was ist die Rückgaberichtlinie des Unternehmens?',
    caseQuery2: 'Vergleiche unseren Q3 2024-Umsatz mit unserem Hauptkonkurrenten und erkläre die wichtigsten Unterschiede.',
    caseQuery3: 'Wie wird unser Aktienkurs im nächsten Quartal sein?',
    caseExplanation1: 'Für einfache Faktenanfragen ist traditionelles RAG effizienter. Die Antwort existiert in einem einzigen Dokument, sodass die direkte Abruf-dann-Generierung-Pipeline perfekt funktioniert. Agentic RAG kommt zur gleichen Antwort, aber mit unnötigem Overhead durch Planungs- und Bewertungsschritte—verschwendet Zeit und Tokens.',
    caseExplanation2: 'Komplexe Anfragen, die mehrere Quellen erfordern, profitieren von Agentic RAG. Der Agent zerlegte die Anfrage in Teilfragen, rief aus verschiedenen Dokumentensets ab (interne Finanzdaten, Konkurrenzberichte) und synthetisierte einen kohärenten Vergleich. Traditionelles RAG rief nur Teilinformationen ab und konnte die Zusammenhänge nicht herstellen.',
    caseExplanation3: 'Keiner der Ansätze kann Fragen über zukünftige Ereignisse oder fehlende Informationen beantworten. Traditionelles RAG halluzinierte aus oberflächlich verwandten Inhalten. Agentic RAG suchte gründlicher und gab die Unsicherheit korrekt zu, konnte aber trotzdem nicht antworten—kein Abruf hilft, wenn die Daten nicht existieren.',
    outcomeSuccess: 'Erfolgreich',
    outcomePartial: 'Teilweise',
    outcomeFailure: 'Fehlgeschlagen',

    // Schrittbezeichnungen
    stepThinking: 'Denken',
    stepSearching: 'Suchen',
    stepRetrieved: 'Abgerufen',
    stepGenerating: 'Generieren',
    processSteps: 'Prozessschritte',
    retrievedDocs: 'Abgerufene Dokumente',
    finalResponse: 'Finale Antwort',
    noRelevantDocs: 'Keine relevanten Dokumente in der Wissensbasis gefunden',

    // Fall 1: Traditionelles RAG gewinnt - Einfache Faktenanfrage
    case1TradSearch: 'Einbettung der Anfrage: "Rückgaberichtlinie"',
    case1TradRetrieve: '1 hochrelevantes Dokument gefunden (Ähnlichkeit: 0.94)',
    case1TradGenerate: 'Generiere Antwort aus abgerufenem Kontext',
    case1TradDoc1: '[richtlinien/rueckgabe.md] "Rückgaberichtlinie: Artikel können innerhalb von 30 Tagen nach Kauf mit Originalbeleg zurückgegeben werden. Erstattungen werden innerhalb von 5-7 Werktagen auf die ursprüngliche Zahlungsmethode verarbeitet. Elektronik muss ungeöffnet sein. Sale-Artikel sind vom Umtausch ausgeschlossen."',
    case1TradResponse: 'Artikel können innerhalb von 30 Tagen mit dem Originalbeleg zurückgegeben werden. Erstattungen werden innerhalb von 5-7 Werktagen auf Ihre ursprüngliche Zahlungsmethode verarbeitet. Beachten Sie, dass Elektronik ungeöffnet sein muss und Sale-Artikel vom Umtausch ausgeschlossen sind.',
    case1AgentThought1: 'Der Benutzer fragt nach der Rückgaberichtlinie. Ich sollte nach Richtlinien-Dokumenten suchen.',
    case1AgentSearch: 'Suche: "Rückgaberichtlinie Erstattung"',
    case1AgentRetrieve: '1 relevantes Dokument gefunden',
    case1AgentThought2: 'Dieses Dokument beantwortet die Frage vollständig. Keine weiteren Suchen nötig.',
    case1AgentGenerate: 'Synthesiere finale Antwort',
    case1AgentResponse: 'Artikel können innerhalb von 30 Tagen mit dem Originalbeleg zurückgegeben werden. Erstattungen werden innerhalb von 5-7 Werktagen auf Ihre ursprüngliche Zahlungsmethode verarbeitet. Beachten Sie, dass Elektronik ungeöffnet sein muss und Sale-Artikel vom Umtausch ausgeschlossen sind.',

    // Fall 2: Agentic RAG gewinnt - Komplexe Multi-Source-Anfrage
    case2TradSearch: 'Einbettung der Anfrage: "Q3 2024 Umsatz Konkurrenz Vergleich"',
    case2TradRetrieve: '1 teilweise relevantes Dokument gefunden (Ähnlichkeit: 0.71)',
    case2TradGenerate: 'Generiere Antwort aus begrenztem Kontext',
    case2TradDoc1: '[finanzen/q3-2024.md] "Q3 2024 Umsatz: 4,2 Mio. € (+12% YoY). Haupttreiber: Enterprise-Vertriebswachstum, neue Produkteinführungen. Operative Marge: 18%."',
    case2TradResponse: 'Unser Q3 2024 Umsatz betrug 4,2 Mio. €, ein Plus von 12% im Jahresvergleich, getrieben durch Enterprise-Vertrieb und neue Produkte. (Hinweis: Ich habe keine Konkurrenzdaten für einen Vergleich.)',
    case2AgentThought1: 'Dies ist eine Vergleichsanfrage. Ich benötige: 1) Unseren Q3 2024 Umsatz, 2) Konkurrenz Q3 2024 Umsatz, 3) Analyse der Unterschiede.',
    case2AgentSearch1: 'Suche: "Q3 2024 Umsatz Finanzergebnisse"',
    case2AgentRetrieve1: 'Internen Finanzbericht gefunden',
    case2AgentThought2: 'Unseren Umsatz habe ich. Jetzt brauche ich Konkurrenzdaten. Suche nach Wettbewerbsanalyse.',
    case2AgentSearch2: 'Suche: "Wettbewerber Marktanalyse 2024"',
    case2AgentRetrieve2: 'Wettbewerbsanalyse-Bericht gefunden',
    case2AgentThought3: 'Jetzt habe ich beide Datensätze. Unser Umsatz: 4,2 Mio. €, Konkurrenz: 3,8 Mio. €. Ich kann die Unterschiede analysieren.',
    case2AgentGenerate: 'Synthesiere Vergleich aus beiden Quellen',
    case2AgentDoc1: '[finanzen/q3-2024.md] "Q3 2024 Umsatz: 4,2 Mio. € (+12% YoY). Haupttreiber: Enterprise-Vertriebswachstum, neue Produkteinführungen. Operative Marge: 18%."',
    case2AgentDoc2: '[research/wettbewerb.md] "Konkurrent X Q3 2024: Umsatz 3,8 Mio. € (+5% YoY). Herausforderungen: Lieferkettenprobleme, langsamere SMB-Adoption. Marktanteil: rückläufig im Enterprise-Segment."',
    case2AgentResponse: 'Unser Q3 2024 Umsatz (4,2 Mio. €) übertraf Konkurrent X (3,8 Mio. €) um 10,5%. Hauptunterschiede: Wir wuchsen 12% YoY vs. deren 5%, getrieben durch unsere Enterprise-Stärke, wo sie Marktanteile verlieren. Deren Lieferkettenprobleme und schwächere SMB-Adoption trugen zum langsameren Wachstum bei. Unsere operative Marge von 18% deutet auf gesündere Stückkosten hin.',

    // Fall 3: Beide scheitern - Zukunftsprognose / fehlende Daten
    case3TradSearch: 'Einbettung der Anfrage: "Aktienkurs nächstes Quartal Prognose"',
    case3TradRetrieve: '1 lose verwandtes Dokument gefunden (Ähnlichkeit: 0.52)',
    case3TradGenerate: 'Generiere Antwort aus tangential verwandtem Inhalt',
    case3TradDoc1: '[finanzen/aktien-historie.md] "Historische Aktienperformance: Q1 2024: 45€, Q2 2024: 52€, Q3 2024: 48€. Analysten-Konsens: Halten-Empfehlung."',
    case3TradResponse: 'Basierend auf aktuellen Trends schwankte der Aktienkurs zwischen 45-52€. Angesichts der Halten-Empfehlung und der jüngsten Performance könnte der Kurs nächstes Quartal um 50€ liegen. (Warnung: Dies ist Spekulation, keine Finanzberatung.)',
    case3AgentThought1: 'Benutzer möchte Aktienkurs-Prognose. Benötigt: 1) Aktuelle Finanzdaten, 2) Marktprognosen, 3) Analysten-Vorhersagen.',
    case3AgentSearch1: 'Suche: "Aktienprognose Q1 2025 Vorhersage"',
    case3AgentRetrieve1: 'Keine relevanten Dokumente gefunden',
    case3AgentThought2: 'Keine Prognosen in der Wissensbasis. Versuche Analystenberichte.',
    case3AgentSearch2: 'Suche: "Analysten Kursziel Forward Guidance"',
    case3AgentRetrieve2: 'Keine relevanten Dokumente gefunden',
    case3AgentThought3: 'Ich kann keine zukunftsgerichteten Daten finden. Die Wissensbasis enthält nur historische Informationen. Ich sollte nicht spekulieren.',
    case3AgentGenerate: 'Generiere ehrliche Unsicherheits-Antwort',
    case3AgentResponse: 'Ich kann keine zukünftigen Aktienkurse vorhersagen. Meine Wissensbasis enthält historische Daten (Q3 2024: 48€, Halten-Empfehlung), aber keine zukunftsgerichteten Prognosen oder Analysten-Kursziele. Aktienvorhersagen erfordern Echtzeit-Marktdaten und Analysen, zu denen ich keinen Zugang habe.',

    // Fortgeschrittene Techniken (2025)
    advancedTechniques: 'Fortgeschrittene RAG-Techniken',
    advancedTechniquesDesc: 'Über das grundlegende RAG hinaus verwenden moderne Systeme ausgefeilte Techniken, um die Abrufqualität, Antwortgenauigkeit und den Umgang mit komplexen Anfragen zu verbessern. Diese 2025-Ansätze repräsentieren den Stand der Technik.',

    // Self-RAG
    selfRag: 'Self-RAG',
    selfRagDesc: 'Self-RAG führt Selbstreflexion in den Abrufprozess ein. Anstatt immer abzurufen, entscheidet das Modell, wann ein Abruf erforderlich ist, und bewertet abgerufene Inhalte kritisch vor der Verwendung.',
    selfRagHow: 'Wie Self-RAG funktioniert',
    selfRagHowDesc: 'Das Modell generiert spezielle Reflexions-Tokens während der Inferenz: [Retrieve] um zu entscheiden, ob ein Abruf nötig ist, [IsRel] um die Relevanz abgerufener Passagen zu bewerten, [IsSup] um zu überprüfen, ob die Antwort vom Kontext unterstutzt wird, und [IsUse] um den Gesamtnutzen zu bewerten.',
    selfRagRetrieve: 'Abrufentscheidung',
    selfRagRetrieveDesc: 'Das Modell entscheidet, ob die Anfrage externes Wissen benötigt oder aus dem parametrischen Gedächtnis allein beantwortet werden kann.',
    selfRagCritique: 'Selbstkritik',
    selfRagCritiqueDesc: 'Abgerufene Passagen werden auf Relevanz bewertet. Irrelevante oder qualitativ schlechte Ergebnisse werden vor der Generierung gefiltert.',
    selfRagGenerate: 'Fundierte Generierung',
    selfRagGenerateDesc: 'Die Antwort wird mit expliziten Fundierungsprüfungen generiert. Das Modell überprüft, ob Aussagen vom abgerufenen Kontext unterstützt werden.',

    // GraphRAG
    graphRag: 'GraphRAG',
    graphRagDesc: 'GraphRAG kombiniert Vektor-Ähnlichkeitssuche mit Wissensgraph-Traversierung. Es erstellt einen Graphen von Entitäten und Beziehungen aus Ihren Dokumenten und ermöglicht sowohl semantische Suche als auch strukturiertes Reasoning.',
    graphRagVector: 'Vektorsuche-Schicht',
    graphRagVectorDesc: 'Traditionelle semantische Suche findet relevante Dokumentenchunks. Dies behandelt den "was ist meiner Anfrage ähnlich"-Teil des Abrufs.',
    graphRagGraph: 'Wissensgraph-Schicht',
    graphRagGraphDesc: 'Entitäten und Beziehungen werden extrahiert und verknüpft. Ermöglicht Multi-Hop-Reasoning wie "Finde alle Produkte, die von Unternehmen erwähnt wurden, die mit X kooperiert haben".',
    graphRagBenefits: 'Hauptvorteile',
    graphRagBenefit1: 'Bessere Handhabung von Fragen, die Beziehungs-Reasoning erfordern',
    graphRagBenefit2: 'Verbesserte Genauigkeit für Multi-Entitäts-Anfragen',
    graphRagBenefit3: 'Ermöglicht globale Zusammenfassung über ganze Dokumentensammlungen',

    // Anfrageerweiterung
    queryAugmentation: 'Anfrageerweiterung',
    queryAugmentationDesc: 'Benutzeranfragen sind oft unvollständig oder schlecht für den Abruf formuliert. Anfrageerweiterungstechniken transformieren Anfragen vor der Suche, um die Abrufqualität zu verbessern.',
    queryHyde: 'HyDE (Hypothetische Dokument-Einbettungen)',
    queryHydeDesc: 'Generiere zuerst eine hypothetische Antwort, dann verwende die Einbettung dieser Antwort fur den Abruf. Dies überbrückt die Lücke zwischen Frage- und Dokument-Einbettungsraumen.',
    queryHydeExample: 'Anfrage: "Klimawandel Auswirkungen" -> Hypothetisches Dok. generieren -> Das einbetten -> Suchen',
    queryDecomposition: 'Anfrage-Zerlegung',
    queryDecompositionDesc: 'Zerlege komplexe Anfragen in einfachere Teilanfragen. Jede Teilanfrage ruft unabhängig ab, dann werden die Ergebnisse kombiniert.',
    queryDecompositionExample: '"Vergleiche A mit B" -> "Was ist A?" + "Was ist B?" -> Ergebnisse zusammenführen',
    queryExpansion: 'Anfrage-Expansion',
    queryExpansionDesc: 'Füge Synonyme, verwandte Begriffe oder Umformulierungen zur ursprunglichen Anfrage hinzu. Erhöht den Recall durch Matching von Dokumenten mit unterschiedlicher Terminologie.',
    queryRewrite: 'Anfrage-Umschreibung',
    queryRewriteDesc: 'Verwende ein LLM, um mehrdeutige oder umgangssprachliche Anfragen in klare, suchoptimierte Formen umzuschreiben. Behandelt Pronomen, Kontext und implizite Referenzen.',

    // RAG-Evaluierung
    evaluation: 'RAG-Evaluierung',
    evaluationDesc: 'Die Messung der RAG-Systemqualität erfordert spezialisierte Metriken, die sowohl Abruf als auch Generierung bewerten. RAGAS (Retrieval Augmented Generation Assessment) bietet ein Standard-Framework.',
    ragasFramework: 'RAGAS-Framework',
    ragasFrameworkDesc: 'RAGAS verwendet LLM-basierte Evaluierung, um RAG-Systeme zu bewerten, ohne Ground-Truth-Labels fur jede Frage zu benötigen. Es misst mehrere Qualitätsdimensionen.',
    metricFaithfulness: 'Treue (Faithfulness)',
    metricFaithfulnessDesc: 'Enthalt die Antwort nur Informationen aus dem abgerufenen Kontext? Misst Halluzination—Behauptungen, die nicht von den bereitgestellten Dokumenten unterstützt werden.',
    metricRelevance: 'Antwortrelevanz',
    metricRelevanceDesc: 'Adressiert die Antwort tatsächlich die gestellte Frage? Eine treue Antwort kann immer noch irrelevant sein, wenn sie das Thema verfehlt.',
    metricContextRecall: 'Kontext-Recall',
    metricContextRecallDesc: 'Hat der Abruf alle benötigten Informationen für die Antwort gefunden? Misst, ob relevante Passagen übersehen wurden.',
    metricContextPrecision: 'Kontext-Precision',
    metricContextPrecisionDesc: 'Sind die abgerufenen Passagen tatsächlich relevant? Hohe Precision bedeutet weniger Rauschen im Kontext, was Verwirrung reduziert.',
    evaluationTips: 'Best Practices für die Evaluierung',
    evaluationTip1: 'Erstelle ein vielfältiges Testset, das verschiedene Anfragetypen und Schwierigkeitsgrade abdeckt',
    evaluationTip2: 'Verfolge Metriken uber die Zeit, während du Chunking, Einbettungen und Prompts iterierst',
    evaluationTip3: 'Kombiniere automatisierte Metriken mit menschlicher Bewertung fur nuancierte Qualitätsbeurteilung',


    keyTakeaways: 'Wichtige Erkenntnisse',
    takeaway1: 'RAG ruft relevante Dokumente ab und fügt sie in den Prompt ein',
    takeaway2: 'Es reduziert Halluzinationen, indem Antworten in echten Quellen verankert werden',
    takeaway3: 'Chunking-Strategie und Einbettungsqualität sind entscheidend für guten Abruf',
    takeaway4: 'RAG ist oft dem Fine-Tuning vorzuziehen, um Domänenwissen hinzuzufügen',
    takeaway5: 'Fortgeschrittene Techniken wie Self-RAG und GraphRAG verbessern die Genauigkeit bei komplexen Anfragen',
    takeaway6: 'Verwende RAGAS-Metriken, um deine RAG-Pipeline systematisch zu evaluieren und zu verbessern',
  },

  // Phase 2: Agent Topics
  toolDesign: {
    title: 'Tool-Design',
    description: 'Best Practices für das Design effektiver Tools, die KI-Agenten zuverlässig nutzen können.',
    whatIs: 'Was macht ein gutes Tool aus?',
    whatIsDesc: 'Gut gestaltete Tools sind die Grundlage fähiger KI-Agenten. Schema, Benennung und Dokumentation eines Tools beeinflussen direkt, wie zuverlässig ein LLM es nutzen kann.',
    principles: 'Design-Prinzipien',
    principlesDesc: 'Befolge diese Prinzipien, um Tools zu erstellen, die Agenten effektiv nutzen können.',
    principle1: 'Klare Benennung',
    principle1Desc: 'Verwende beschreibende, eindeutige Namen. "search_web" ist besser als "sw" oder "query".',
    principle2: 'Explizite Parameter',
    principle2Desc: 'Jeder Parameter sollte einen klaren Typ, eine Beschreibung und Einschränkungen haben.',
    principle3: 'Vorhersehbare Ausgaben',
    principle3Desc: 'Gib konsistente, strukturierte Antworten zurück. Fehlermeldungen in die Ausgabe einbeziehen.',
    principle4: 'Minimaler Umfang',
    principle4Desc: 'Jedes Tool sollte eine Sache gut machen. Bevorzuge viele fokussierte Tools statt weniger komplexer.',
    schemaDesign: 'Schema-Design',
    schemaDesignDesc: 'Tool-Schemas sagen dem LLM, wie es deine Tools verwenden soll. Gute Schemas verhindern Fehler.',
    goodSchema: 'Gutes Schema',
    badSchema: 'Schlechtes Schema',
    errorHandling: 'Fehlerbehandlung',
    errorHandlingDesc: 'Tools sollten Fehler elegant behandeln und informative Meldungen zurückgeben, auf die das LLM reagieren kann.',
    interactiveDemo: 'Tool-Schema-Builder',
    demoDesc: 'Erstelle und validiere Tool-Schemas interaktiv',
    keyTakeaways: 'Wichtige Erkenntnisse',
    takeaway1: 'Tool-Design beeinflusst direkt die Agenten-Zuverlässigkeit',
    takeaway2: 'Explizite Schemas mit Beschreibungen verhindern LLM-Verwirrung',
    takeaway3: 'Gib strukturierte Fehler zurück, die der Agent verstehen und darauf reagieren kann',
    takeaway4: 'Teste Tools mit verschiedenen Eingaben, um Randfälle zu finden',
  },

  memorySystems: {
    title: 'Speichersysteme',
    description: 'Wie KI-Agenten Kontext aufrechterhalten und Informationen über Interaktionen hinweg speichern.',
    whatIs: 'Was sind Agenten-Speichersysteme?',
    whatIsDesc: 'Speichersysteme ermöglichen es Agenten, Informationen über das unmittelbare Kontextfenster hinaus zu behalten und abzurufen. Sie ermöglichen Agenten, aus vergangenen Interaktionen zu lernen und kohärentes Langzeitverhalten aufrechtzuerhalten.',
    types: 'Arten von Speicher',
    typesDesc: 'Agenten-Speichersysteme kombinieren typischerweise mehrere Speichertypen für verschiedene Zwecke.',
    shortTerm: 'Kurzzeitgedächtnis',
    shortTermDesc: 'Der aktuelle Gesprächskontext. Begrenzt durch die Kontextfenstergröße.',
    longTerm: 'Langzeitgedächtnis',
    longTermDesc: 'Dauerhafte Speicherung vergangener Interaktionen, Fakten und gelernter Präferenzen.',
    episodic: 'Episodisches Gedächtnis',
    episodicDesc: 'Spezifische vergangene Ereignisse und Interaktionen, die abgerufen werden können.',
    semantic: 'Semantisches Gedächtnis',
    semanticDesc: 'Allgemeines Wissen und Fakten, die aus Erfahrungen extrahiert wurden.',
    implementation: 'Implementierungsansätze',
    implementationDesc: 'Verschiedene Techniken zur Implementierung von Agenten-Speicher.',
    vectorStore: 'Vektorspeicher',
    vectorStoreDesc: 'Einbettungen vergangener Interaktionen für semantischen Abruf speichern.',
    summaries: 'Gesprächszusammenfassungen',
    summariesDesc: 'Lange Gespräche periodisch zusammenfassen, um wichtige Informationen zu erhalten.',
    keyValue: 'Schlüssel-Wert-Speicher',
    keyValueDesc: 'Explizite Fakten und Benutzerpräferenzen für direkten Abruf speichern.',
    interactiveDemo: 'Speichersystem-Visualisierer',
    demoDesc: 'Sieh, wie verschiedene Speichertypen zusammenarbeiten',

    // Hybrid Memory (2025 Pattern)
    hybridMemory: 'Hybride Speichermuster',
    hybridMemoryDesc: 'Moderne Agenten kombinieren episodisches und semantisches Gedächtnis für menschenähnliche Erinnerung. Das MemGPT-Muster und ähnliche Architekturen behandeln Speicher als erstklassige Ressource, die der Agent aktiv verwaltet.',
    memgptPattern: 'MemGPT-Architektur',
    memgptPatternDesc: 'Agenten mit expliziter Speicherverwaltung – Daten zwischen schnellem Kontext und langsamem Speicher verschieben, wie ein Betriebssystem RAM und Festplatte verwaltet.',
    tieredMemory: 'Gestufter Speicher',
    tieredMemoryDesc: 'Hot (Kontext), Warm (Vektor-Cache) und Cold (Archiv) Stufen mit automatischer Beförderung und Herabstufung basierend auf Zugriffsmustern.',
    selfEditing: 'Selbstbearbeitender Speicher',
    selfEditingDesc: 'Agenten, die ihre eigenen Erinnerungen aktualisieren, konsolidieren und umstrukturieren können, anstatt nur anzuhängen.',
    dualEncoder: 'Dual-Encoder-Abruf',
    dualEncoderDesc: 'Separate Encoder für Abfragen und Erinnerungen ermöglichen asymmetrischen Abruf, der für jede Richtung optimiert ist.',

    // Temporal Knowledge Graphs
    temporalGraphs: 'Temporale Wissensgraphen',
    temporalGraphsDesc: 'Speichere Erinnerungen mit expliziten Zeitbeziehungen, um Abfragen wie "was haben wir letzte Woche besprochen?" zu ermöglichen und Wissensdrift über Zeit zu erkennen.',
    entityRelations: 'Entitäts-Beziehungs-Tracking',
    entityRelationsDesc: 'Extrahiere Entitäten (Personen, Projekte, Konzepte) und ihre Beziehungen aus Gesprächen und baue einen abfragbaren Wissensgraphen.',
    timeWeighted: 'Zeitgewichteter Abruf',
    timeWeightedDesc: 'Kombiniere semantische Ähnlichkeit mit Aktualität, Wichtigkeit und Zugriffshäufigkeit für relevantere Erinnerung.',
    zepApproach: 'ZEP-Stil-Speicher',
    zepApproachDesc: 'Automatische Extraktion von Fakten, Entitäten und temporalen Beziehungen mit bi-temporaler Modellierung (wann etwas passierte vs. wann es aufgezeichnet wurde).',

    // Memory Management
    memoryManagement: 'Speicherverwaltung',
    memoryManagementDesc: 'Produktionsspeichersysteme erfordern aktive Verwaltung, um innerhalb von Token-Budgets zu bleiben und gleichzeitig wertvolle Informationen zu erhalten.',
    deduplication: 'Deduplizierung',
    deduplicationDesc: 'Erkenne und vereinige semantisch ähnliche Erinnerungen, um Aufblähung zu verhindern. Verwende Embedding-Ähnlichkeitsschwellen oder LLM-basierten Vergleich.',
    tokenBudgets: 'Token-Budgets',
    tokenBudgetsDesc: 'Weise verschiedenen Speichertypen feste Token-Anzahlen zu. Bei Überschreitung des Budgets, komprimiere oder entferne Elemente mit niedrigster Priorität.',
    garbageCollection: 'Garbage Collection',
    garbageCollectionDesc: 'Scanne Erinnerungen periodisch auf veraltete, redundante oder wenig wertvolle Einträge. LRU-, LFU- oder wichtigkeitsgewichtete Eviction-Strategien.',
    priorityRules: 'Prioritätsregeln',
    priorityRulesDesc: 'Definiere, welche Erinnerungen am wichtigsten sind: Benutzerpräferenzen, Aufgabenkontext, kürzliche Interaktionen oder explizit fixierte Fakten.',

    // Adaptive Retention
    adaptiveRetention: 'Adaptive Aufbewahrung',
    adaptiveRetentionDesc: 'Intelligente Strategien für was behalten, zusammenfassen oder vergessen werden soll – nachahmen wie menschliches Gedächtnis natürlich verfällt und konsolidiert.',
    contextSummarization: 'Kontextzusammenfassung',
    contextSummarizationDesc: 'Progressive Zusammenfassung: volle Details für aktuellen Kontext, Zusammenfassungen für ältere Gespräche, nur Schlüsselfakten für entfernte Vergangenheit.',
    entityExtraction: 'Entitätsextraktion',
    entityExtractionDesc: 'Identifiziere und speichere automatisch wichtige Entitäten (Namen, Präferenzen, Entscheidungen) getrennt von rohen Gesprächsprotokollen.',
    decayStrategies: 'Verfallsstrategien',
    decayStrategiesDesc: 'Exponentielle oder logarithmische Verfallsfunktionen reduzieren die Wichtigkeit von Erinnerungen über Zeit, es sei denn, sie werden durch Zugriff oder explizite Wichtigkeitsmarkierungen verstärkt.',

    keyTakeaways: 'Wichtige Erkenntnisse',
    takeaway1: 'Speicher erweitert die Agentenfähigkeiten über das Kontextfenster hinaus',
    takeaway2: 'Kombiniere mehrere Speichertypen für beste Ergebnisse',
    takeaway3: 'Speicherabruf fügt Latenz hinzu – balance Vollständigkeit mit Geschwindigkeit',
    takeaway4: 'Berücksichtige Datenschutz und Datenspeicherung beim Speichern von Erinnerungen',
    takeaway5: 'Hybridmuster wie MemGPT ermöglichen Agenten, ihren eigenen Speicher wie ein Betriebssystem zu verwalten',
    takeaway6: 'Temporale Wissensgraphen fügen Zeitbewusstsein für kontextuelleren Abruf hinzu',
  },

  orchestration: {
    title: 'Orchestrierung',
    description: 'Koordination mehrerer Agenten und komplexer mehrstufiger Workflows.',
    whatIs: 'Was ist Agenten-Orchestrierung?',
    whatIsDesc: 'Orchestrierung ist die Koordination mehrerer KI-Agenten oder komplexer mehrstufiger Workflows. Sie umfasst das Routing von Aufgaben, Zustandsverwaltung, Fehlerbehandlung und das Kombinieren von Agenten-Ausgaben.',
    patterns: 'Orchestrierungsmuster',
    patternsDesc: 'Gängige Muster für die Strukturierung von Multi-Agenten-Systemen.',
    sequential: 'Sequenzielle Pipeline',
    sequentialDesc: 'Agenten laufen der Reihe nach, jeder verarbeitet die Ausgabe des vorherigen.',
    parallel: 'Parallele Ausführung',
    parallelDesc: 'Mehrere Agenten arbeiten gleichzeitig an verschiedenen Aspekten einer Aufgabe.',
    hierarchical: 'Hierarchisch',
    hierarchicalDesc: 'Ein Supervisor-Agent delegiert an spezialisierte Worker-Agenten.',
    dynamic: 'Dynamisches Routing',
    dynamicDesc: 'Ein LLM entscheidet, welcher Agent jede Anfrage bearbeiten soll.',
    stateManagement: 'Zustandsverwaltung',
    stateManagementDesc: 'Orchestratoren müssen Fortschritt, Zwischenergebnisse verfolgen und Fehler behandeln.',
    checkpointing: 'Checkpointing',
    checkpointingDesc: 'Zustand an wichtigen Punkten speichern, um Wiederherstellung bei Fehlern zu ermöglichen.',
    rollback: 'Rollback',
    rollbackDesc: 'Fähigkeit, Schritte rückgängig zu machen, wenn Fehler auftreten.',
    interactiveDemo: 'Workflow-Visualisierer',
    demoDesc: 'Agenten-Workflows entwerfen und visualisieren',
    keyTakeaways: 'Wichtige Erkenntnisse',
    takeaway1: 'Orchestrierung ermöglicht komplexe Aufgaben durch Agenten-Komposition',
    takeaway2: 'Wähle Muster basierend auf Aufgabenabhängigkeiten und Parallelität',
    takeaway3: 'Robuste Zustandsverwaltung ist essentiell für Zuverlässigkeit',
    takeaway4: 'Überwache Orchestrierungskosten – Multi-Agenten-Systeme vervielfachen API-Aufrufe',
    // 2025 Multi-Agenten-Muster
    multiAgentPatterns: '2025 Multi-Agenten-Muster',
    multiAgentPatternsDesc: 'Diese aufkommenden Muster definieren, wie moderne KI-Agenten im Unternehmensmaßstab zusammenarbeiten.',
    enterpriseAdoption: '72% der Enterprise-KI-Projekte nutzen jetzt Multi-Agenten-Systeme',
    enterpriseAdoptionSource: 'Gartner 2025',
    supervisorPattern: 'Supervisor-Muster',
    supervisorPatternDesc: 'Ein Koordinator-Agent, der Aufgaben an spezialisierte Worker-Agenten verwaltet und delegiert. Der Supervisor behält das Gesamtziel bei, zerlegt komplexe Aufgaben und synthetisiert Worker-Ausgaben.',
    supervisorBenefits: 'Vorteile: Klare Hierarchie, zentralisierte Entscheidungsfindung, einfacheres Debugging',
    orchestratorWorker: 'Orchestrator-Worker-Muster',
    orchestratorWorkerDesc: 'Ein zentraler Orchestrator verwaltet einen Pool von Worker-Agenten. Worker sind zustandslos und können dynamisch skaliert werden. Der Orchestrator übernimmt Aufgaben-Queuing, Lastverteilung und Ergebnisaggregation.',
    orchestratorWorkerBenefits: 'Vorteile: Skalierbarkeit, Fehlertoleranz, Ressourceneffizienz',
    handoffMechanisms: 'Übergabe-Mechanismen',
    handoffMechanismsDesc: 'Wie Agenten die Kontrolle untereinander übertragen. Populär durch OpenAI Agents SDK ermöglichen Handoffs nahtlose Übergänge zwischen spezialisierten Agenten unter Beibehaltung des Gesprächskontexts.',
    handoffExplicit: 'Explizite Übergabe',
    handoffExplicitDesc: 'Agent ruft direkt Transferfunktion mit Ziel-Agent und Kontext auf.',
    handoffCondition: 'Bedingungsbasiert',
    handoffConditionDesc: 'Automatische Übertragung bei Erfüllung bestimmter Bedingungen (z.B. Themenerkennung).',
    handoffEscalation: 'Eskalation',
    handoffEscalationDesc: 'Agent übergibt an fähigeren Agenten, wenn Aufgabe seinen Rahmen übersteigt.',
    groupChatPattern: 'Gruppenchat-Muster',
    groupChatPatternDesc: 'Mehrere Agenten arbeiten durch eine strukturierte Konversation an einem gemeinsamen Problem zusammen. Jeder Agent bringt seine Expertise ein, während ein Moderator Sprechreihenfolge und Konsens verwaltet.',
    groupChatRoles: 'Typische Rollen',
    groupChatModerator: 'Moderator: Kontrolliert Ablauf, fasst Fortschritt zusammen, löst Konflikte',
    groupChatExpert: 'Experten: Domänenspezifische Agenten mit spezialisiertem Wissen',
    groupChatCritic: 'Kritiker: Überprüft und hinterfragt Vorschläge zur Qualitätsverbesserung',
    groupChatExecutor: 'Ausführer: Implementiert die vereinbarten Entscheidungen',
    patternComparison: 'Mustervergleich',
    patternComparisonDesc: 'Die Wahl des richtigen Musters hängt vom Anwendungsfall ab.',
    comparisonComplexity: 'Komplexität',
    comparisonScalability: 'Skalierbarkeit',
    comparisonUseCase: 'Ideal für',
    supervisorComplexity: 'Mittel',
    supervisorScalability: 'Mittel',
    supervisorUseCase: 'Strukturierte Workflows, klare Aufgabenzerlegung',
    orchestratorComplexity: 'Hoch',
    orchestratorScalability: 'Hoch',
    orchestratorUseCase: 'Hochvolumen-Verarbeitung, dynamische Arbeitslasten',
    handoffComplexity: 'Niedrig',
    handoffScalability: 'Niedrig',
    handoffUseCase: 'Kundenservice, spezialisiertes Routing',
    groupChatComplexity: 'Hoch',
    groupChatScalability: 'Mittel',
    groupChatUseCase: 'Kreative Aufgaben, komplexe Problemlösung',
  },

  evaluation: {
    title: 'Evaluierung',
    description: 'Systematische Messung und Verbesserung der KI-Agenten-Leistung.',
    whatIs: 'Warum Agenten evaluieren?',
    whatIsDesc: 'Agenten-Evaluierung ist entscheidend für das Verständnis der Leistung, das Erkennen von Regressionen und die Verbesserung der Zuverlässigkeit. Ohne Messung fliegst du blind.',
    metrics: 'Wichtige Metriken',
    metricsDesc: 'Wichtige Metriken für Agentensysteme.',
    taskSuccess: 'Aufgaben-Erfolgsrate',
    taskSuccessDesc: 'Prozentsatz der korrekt abgeschlossenen Aufgaben.',
    efficiency: 'Effizienz',
    efficiencyDesc: 'Unternommene Schritte, verwendete Tokens, verstrichene Zeit pro Aufgabe.',
    accuracy: 'Genauigkeit',
    accuracyDesc: 'Korrektheit der Agenten-Ausgaben und -Entscheidungen.',
    reliability: 'Zuverlässigkeit',
    reliabilityDesc: 'Konsistenz über wiederholte Durchläufe derselben Aufgabe.',
    approaches: 'Evaluierungsansätze',
    approachesDesc: 'Verschiedene Wege zur Evaluierung der Agentenleistung.',
    unitTests: 'Unit-Tests',
    unitTestsDesc: 'Einzelne Tools und Komponenten isoliert testen.',
    integration: 'Integrationstests',
    integrationDesc: 'Die vollständige Agentenschleife mit Mock-Umgebungen testen.',
    benchmarks: 'Benchmarks',
    benchmarksDesc: 'Standard-Aufgabensammlungen zum Vergleich von Agenten.',
    humanEval: 'Menschliche Bewertung',
    humanEvalDesc: 'Expertenüberprüfung für nuancierte Qualitätsbewertung.',
    bestPractices: 'Best Practices',
    bestPracticesDesc: 'Richtlinien für effektive Agenten-Evaluierung.',
    practice1: 'Teste Randfälle und Fehlermodi, nicht nur Happy Paths.',
    practice2: 'Verfolge Kosten neben Qualitätsmetriken.',
    practice3: 'Verwende versionierte Evaluierungen, um Regressionen zu erkennen.',
    practice4: 'Schließe adversarielle Tests für Sicherheit ein.',

    // Benchmarks Section
    benchmarksSection: 'Gängige LLM-Benchmarks',
    benchmarksSectionDesc: 'Standard-Benchmarks zur Bewertung und zum Vergleich von Sprachmodell-Fähigkeiten über verschiedene Aufgaben.',
    benchmarkMmlu: 'MMLU',
    benchmarkMmluDesc: 'Massive Multitask Language Understanding - 57 Fächer von MINT bis Geisteswissenschaften. Testet breites Wissen.',
    benchmarkHellaswag: 'HellaSwag',
    benchmarkHellaswagDesc: 'Alltagsverständnis über alltägliche Situationen. Testet Verständnis der physischen Welt.',
    benchmarkHumaneval: 'HumanEval',
    benchmarkHumanevalDesc: 'Code-Generierungs-Benchmark mit 164 Programmieraufgaben. Testet Programmierfähigkeit.',
    benchmarkGsm8k: 'GSM8K',
    benchmarkGsm8kDesc: 'Mathematische Textaufgaben auf Grundschulniveau. Testet mehrstufiges mathematisches Denken.',
    benchmarkArc: 'ARC',
    benchmarkArcDesc: 'AI2 Reasoning Challenge - Wissenschaftsfragen, die Denken jenseits von Mustererkennung erfordern.',
    benchmarkMath: 'MATH',
    benchmarkMathDesc: 'Mathematikaufgaben auf Wettbewerbsniveau. Testet fortgeschrittenes mathematisches Denken.',
    benchmarkCaveats: 'Benchmark-Vorbehalte',
    benchmarkCaveat1: 'Benchmarks können manipuliert werden - Modelle könnten auf Testdaten trainiert sein',
    benchmarkCaveat2: 'Hohe Punktzahlen garantieren keine reale Leistung',
    benchmarkCaveat3: 'Viele Benchmarks sind gesättigt - Top-Modelle punkten ähnlich',
    benchmarkCaveat4: 'Benchmarks übersehen oft wichtige Fähigkeiten wie Anweisungsbefolgung',

    // LLM as a Judge
    llmJudge: 'LLM-als-Richter',
    llmJudgeDesc: 'Verwendung von Sprachmodellen zur Bewertung anderer Modellausgaben - ein skalierbarer aber unvollkommener Ansatz.',
    llmJudgeWhat: 'Wie es funktioniert',
    llmJudgeWhatDesc: 'Ein leistungsfähiges LLM (der "Richter") wird aufgefordert, Ausgaben eines anderen Modells zu bewerten. Der Richter bewertet Antworten nach Kriterien wie Hilfsbereitschaft, Genauigkeit und Sicherheit.',
    llmJudgeAdvantages: 'Vorteile',
    llmJudgeAdv1: 'Skalierbar',
    llmJudgeAdv1Desc: 'Kann Tausende von Ausgaben schnell ohne menschliche Annotatoren bewerten.',
    llmJudgeAdv2: 'Konsistent',
    llmJudgeAdv2Desc: 'Gleiche Kriterien werden einheitlich angewendet (anders als bei menschlicher Ermüdung/Variation).',
    llmJudgeAdv3: 'Kosteneffektiv',
    llmJudgeAdv3Desc: 'Viel günstiger als die Einstellung menschlicher Bewerter im großen Maßstab.',
    llmJudgeAdv4: 'Flexibel',
    llmJudgeAdv4Desc: 'Bewertungskriterien lassen sich einfach durch Ändern des Prompts anpassen.',
    llmJudgeProblems: 'Probleme & Verzerrungen',
    llmJudgeProb1: 'Selbstpräferenz-Verzerrung',
    llmJudgeProb1Desc: 'Modelle bevorzugen tendenziell Ausgaben, die dem ähneln, was sie selbst generieren würden.',
    llmJudgeProb2: 'Positions-Verzerrung',
    llmJudgeProb2Desc: 'Richter bevorzugen möglicherweise die erste oder letzte Option unabhängig von der Qualität.',
    llmJudgeProb3: 'Ausführlichkeits-Verzerrung',
    llmJudgeProb3Desc: 'Längere Antworten werden oft höher bewertet, selbst wenn sie weniger genau sind.',
    llmJudgeProb4: 'Stil über Substanz',
    llmJudgeProb4Desc: 'Gut formatierte falsche Antworten können schlecht formatierte richtige schlagen.',
    llmJudgeProb5: 'Fähigkeitsobergrenze',
    llmJudgeProb5Desc: 'Der Richter kann Ausgaben jenseits seines eigenen Fähigkeitsniveaus nicht zuverlässig bewerten.',
    llmJudgeBestPractices: 'Best Practices für LLM-Richter',
    llmJudgePractice1: 'Verwende das leistungsfähigste verfügbare Modell als Richter',
    llmJudgePractice2: 'Randomisiere die Optionsreihenfolge um Positionsverzerrung zu mindern',
    llmJudgePractice3: 'Fordere Begründung vor Bewertungen an (Chain-of-Thought)',
    llmJudgePractice4: 'Validiere gegen menschliche Urteile bei einer Teilmenge',
    llmJudgePractice5: 'Verwende mehrere Richter und aggregiere die Bewertungen',

    // CLASSIC Framework
    classicFramework: 'CLASSIC-Framework',
    classicFrameworkDesc: 'Ein umfassendes Enterprise-Evaluierungsframework für KI-Agenten mit sieben kritischen Dimensionen.',
    classicCost: 'Kosten',
    classicCostDesc: 'Gesamtbetriebskosten einschließlich API-Aufrufe, Rechenleistung, Infrastruktur und Wartung. Verfolge Kosten pro Aufgabe und pro erfolgreichem Ergebnis.',
    classicLatency: 'Latenz',
    classicLatencyDesc: 'Zeit bis zum ersten Token, End-to-End-Antwortzeit und Aufgabenabschlusszeit. Kritisch für Benutzererfahrung und Echtzeitanwendungen.',
    classicAccuracy: 'Genauigkeit',
    classicAccuracyDesc: 'Korrektheit der Ausgaben gemessen an der Grundwahrheit. Umfasst faktische Genauigkeit, logische Konsistenz und aufgabenspezifische Präzision.',
    classicStability: 'Stabilität',
    classicStabilityDesc: 'Konsistenz der Ausgaben bei identischen Eingaben. Niedrige Varianz zeigt zuverlässiges Verhalten; hohe Varianz deutet auf unvorhersehbare Leistung hin.',
    classicSecurity: 'Sicherheit',
    classicSecurityDesc: 'Widerstandsfähigkeit gegen Prompt-Injection, Jailbreaks und Datenlecks. Umfasst Eingabevalidierung, Ausgabefilterung und Zugriffskontrolle.',
    classicInterpretability: 'Interpretierbarkeit',
    classicInterpretabilityDesc: 'Fähigkeit, Entscheidungen und Begründungen zu erklären. Unterstützt Debugging, Compliance-Audits und Benutzervertrauen durch transparenten Betrieb.',
    classicCompliance: 'Compliance',
    classicComplianceDesc: 'Einhaltung regulatorischer Anforderungen (DSGVO, HIPAA, SOC2), Branchenstandards und organisatorischer Richtlinien.',
    classicNote: 'Enterprise-Evaluierung sollte alle sieben Dimensionen verfolgen. Optimiere für deine spezifischen Anwendungsfallprioritäten.',

    // Agent-Specific Benchmarks
    agentBenchmarks: 'Agentenspezifische Benchmarks',
    agentBenchmarksDesc: 'Moderne Benchmarks, die speziell zur Bewertung von KI-Agenten bei komplexen, mehrstufigen Aufgaben in realistischen Umgebungen entwickelt wurden.',
    benchmarkAgentBench: 'AgentBench',
    benchmarkAgentBenchDesc: 'Bewertet LLMs als Agenten in 8 Umgebungen: OS, Datenbank, Wissensgraph, Web-Browsing und mehr. Testet realen Tool-Einsatz.',
    benchmarkGaia: 'GAIA',
    benchmarkGaiaDesc: 'General AI Assistants Benchmark mit 466 Fragen, die mehrstufiges Reasoning, Web-Browsing und Tool-Nutzung erfordern. Menschlich verifizierte Antworten.',
    benchmarkBfcl: 'Berkeley Function-Calling Leaderboard',
    benchmarkBfclDesc: 'Testet Funktionsaufruf-Genauigkeit bei einfachen, parallelen und verschachtelten Aufrufen. Enthält reale API-Szenarien und Grenzfälle.',
    benchmarkSwe: 'SWE-bench',
    benchmarkSweDesc: 'Echte GitHub-Issues aus beliebten Python-Repos. Agenten müssen Kontext verstehen, Code schreiben und bestehende Tests bestehen.',
    benchmarkWebArena: 'WebArena',
    benchmarkWebArenaDesc: 'Testet Agenten bei realistischen Web-Aufgaben über E-Commerce, Foren und Content-Management-Sites mit komplexen mehrseitigen Workflows.',
    benchmarkTau: 'TAU-bench',
    benchmarkTauDesc: 'Tool-Agent-User Benchmark, der Agenten bei echten Kundenservice-Szenarien mit Tools, Richtlinien und Benutzerinteraktionen testet.',

    // Interactive Evaluation
    interactiveEval: 'Interaktive Evaluierung',
    interactiveEvalDesc: 'Dynamische Evaluierungsansätze, die das Agentenverhalten in sich ändernden Umgebungen und unter adversen Bedingungen testen.',
    interactiveWhat: 'Jenseits statischer Benchmarks',
    interactiveWhatDesc: 'Statische Benchmarks haben feste Fragen und Antworten. Interaktive Evaluierung testet, wie Agenten sich an dynamische Umgebungen anpassen, unerwartete Situationen bewältigen und die Leistung unter sich ändernden Bedingungen aufrechterhalten.',
    interactiveApproach1: 'Umgebungsperturbation',
    interactiveApproach1Desc: 'Ändere die Umgebung während der Aufgabenausführung – modifiziere Dateien, ändere API-Antworten, führe Fehler ein – um Agentenrobustheit und Wiederherstellung zu testen.',
    interactiveApproach2: 'Adverse Benutzersimulation',
    interactiveApproach2Desc: 'Simuliere Benutzer, die mehrdeutige Anweisungen geben, ihre Meinung ändern oder versuchen, den Agenten zu manipulieren. Testet reale Widerstandsfähigkeit.',
    interactiveApproach3: 'Multi-Turn-Konsistenz',
    interactiveApproach3Desc: 'Bewerte Kohärenz über lange Konversationen mit Kontextwechseln. Prüfe, ob der Agent genauen Zustand beibehält und Anweisungen über die Zeit befolgt.',
    interactiveApproach4: 'Curriculare Schwierigkeit',
    interactiveApproach4Desc: 'Beginne mit einfachen Aufgaben und steigere progressiv die Komplexität. Identifiziert Fähigkeitsgrenzen und graduelle Abbaumuster.',
    interactiveNote: 'Interaktive Evaluierung sagt reale Leistung besser voraus als statische Benchmarks allein.',

    keyTakeaways: 'Wichtige Erkenntnisse',
    takeaway1: 'Evaluierung ist essentiell – ungemessene Systeme können nicht verbessert werden',
    takeaway2: 'Kombiniere automatisierte Tests mit menschlicher Bewertung',
    takeaway3: 'Verfolge mehrere Metriken: Erfolg, Effizienz, Kosten',
    takeaway4: 'Integriere Evaluierung in deinen Entwicklungsworkflow',
    takeaway5: 'LLM-als-Richter ist nützlich, hat aber erhebliche Verzerrungen zu berücksichtigen',
    takeaway6: 'Verwende das CLASSIC-Framework für umfassende Enterprise-Evaluierung',
    takeaway7: 'Agentenspezifische Benchmarks wie AgentBench und GAIA testen reale Fähigkeiten',
  },

  // Agent Skills Seite
  agentSkills: {
    title: 'Agenten-Skills',
    description: 'Wiederverwendbare Instruktionspakete, die Agenten bei Bedarf spezialisierte Fähigkeiten verleihen.',
    whatIs: 'Was sind Agenten-Skills?',
    whatIsDesc: 'sind Ordner mit Anweisungen, Prompts, Beispielen und Ressourcen, die ein LLM bei Bedarf laden kann, um spezialisierte Aufgaben konsistent auszuführen. Anstatt alles in den System-Prompt zu packen, ermöglichen Skills die Modularisierung von Expertise.',
    metaphor: '"Skills sind wie Apps für deinen Agenten – einmal installieren, bei Bedarf verwenden."',
    metaphorDesc: 'Genau wie du Apps auf deinem Handy für bestimmte Funktionen installierst, geben Skills Agenten spezialisierte Fähigkeiten, ohne jede Konversation aufzublähen.',

    // Wie es funktioniert
    howItWorks: 'Wie Agenten-Skills funktionieren',
    step1Title: 'Skill-Erkennung',
    step1Desc: 'Wenn eine Benutzeranfrage eingeht, prüft der Agent, ob verfügbare Skills zur Aufgabe passen, basierend auf Triggern, Schlüsselwörtern oder explizitem Aufruf.',
    step2Title: 'Skill-Laden',
    step2Desc: 'Die Anweisungen, Beispiele und der Kontext des relevanten Skills werden in den Arbeitsspeicher des Agenten geladen. Dies fügt spezialisiertes Wissen hinzu, ohne den Basis-System-Prompt zu belasten.',
    step3Title: 'Skill-Ausführung',
    step3Desc: 'Der Agent folgt den Anweisungen des Skills, um die Aufgabe abzuschließen, unter Verwendung bereitgestellter Vorlagen, Checklisten oder Skripte. Die Ergebnisse werden dem Benutzer zurückgegeben.',

    // Interaktive Demo
    interactiveDemo: 'Interaktive Skill-Demo',
    interactiveDemoDesc: 'Erkunde, wie Skills ausgelöst werden, ihre Manifest-Struktur und Skill-Verkettung',

    // Struktur
    structureTitle: 'Skill-Struktur',
    structureSubtitle: 'Anatomie eines Skill-Ordners',
    skillMdDesc: 'Metadaten und Hauptanweisungen',
    instructionsDesc: 'Detaillierte Anleitungen für die Aufgabe',
    examplesDesc: 'Beispiel-Ein- und -Ausgaben',
    templatesDesc: 'Wiederverwendbare Ausgabeformate',
    scriptsDesc: 'Hilfsskripte bei Bedarf',
    skillMdNote: 'ist der Einstiegspunkt. Sie enthält Metadaten (Name, Trigger, Beschreibung) und die Kernanweisungen, denen der Agent folgt.',

    // Arten von Skills
    typesTitle: 'Arten von Agenten-Skills',
    skillType1Title: 'Domänen-Skills',
    skillType1Desc: 'Spezialisiertes Wissen für bestimmte Bereiche – Rechtsverträge, medizinische Terminologie, Finanzanalyse. Verwandeln einen allgemeinen Agenten in einen Domänenexperten.',
    skillType2Title: 'Workflow-Skills',
    skillType2Desc: 'Mehrstufige Prozesse mit definierten Phasen – Code-Review-Workflows, Content-Publishing-Pipelines, Incident-Response-Verfahren.',
    skillType3Title: 'Format-Skills',
    skillType3Desc: 'Konsistente Ausgabeformatierung – API-Dokumentation, Changelog-Einträge, Meeting-Zusammenfassungen. Stellen sicher, dass Ausgaben deinen Standards entsprechen.',
    skillType4Title: 'Integrations-Skills',
    skillType4Desc: 'Anweisungen für die Arbeit mit bestimmten Tools oder Diensten – GitHub-Workflows, Jira-Ticket-Erstellung, Slack-Benachrichtigungen.',

    // Skills vs Tools
    vsToolsTitle: 'Skills vs. Tools',
    tools: 'Tools',
    tool1: 'Führen Aktionen aus (Dateien lesen, APIs aufrufen, Code ausführen)',
    tool2: 'Definiert durch Funktionssignaturen und Schemas',
    tool3: 'Die "Hände" des Agenten',
    skills: 'Skills',
    skill1: 'Liefern Wissen und Methodik (wie man Aufgaben angeht)',
    skill2: 'Definiert durch Anweisungen und Beispiele',
    skill3: 'Die "Expertise" des Agenten',
    vsNote: 'Skills und Tools arbeiten zusammen: Ein Code-Review-Skill sagt dem Agenten, worauf er achten soll, während Tools ihm erlauben, den Code zu lesen und Kommentare zu hinterlassen.',

    // Vorteile
    benefitsTitle: 'Vorteile von Skills',
    benefit1Title: 'Spezialisierung ohne Aufblähung',
    benefit1Desc: 'Halte den Basis-System-Prompt schlank. Lade spezialisiertes Wissen nur bei Bedarf und bewahre das Kontextfenster für die eigentliche Aufgabe.',
    benefit2Title: 'Konsistenz',
    benefit2Desc: 'Definiere einen Prozess einmal, wende ihn jedes Mal konsistent an. Keine Variationen mehr in der Herangehensweise an Aufgaben.',
    benefit3Title: 'Teilbarkeit',
    benefit3Desc: 'Skills sind nur Ordner – teile sie projektübergreifend, teamübergreifend oder öffentlich. Einmal erstellen, überall verwenden.',
    benefit4Title: 'Iteration',
    benefit4Desc: 'Verbessere Skills unabhängig vom Agenten. Aktualisiere den Code-Review-Skill, ohne den Rest deines Agenten-Setups anzufassen.',

    // Beispiel
    exampleTitle: 'Beispiel: Code-Review-Skill',
    exampleDesc: 'Führt gründliche Code-Reviews nach Team-Standards durch',
    exampleInstructions: 'Beim Code-Review auf Korrektheit, Performance, Sicherheit und Wartbarkeit analysieren.',
    exampleCheck1: 'Auf häufige Sicherheitslücken prüfen',
    exampleCheck2: 'Fehlerbehandlung auf Vollständigkeit überprüfen',
    exampleCheck3: 'Nach Performance-Antipatterns suchen',
    exampleCheck4: 'Sicherstellen, dass der Code den Style-Guidelines folgt',

    // Best Practices
    practicesTitle: 'Best Practices',
    practice1Title: 'Skills fokussiert halten',
    practice1Desc: 'Ein Skill, ein Zweck. Wenn ein Skill zu viele Dinge tut, teile ihn auf. Fokussierte Skills sind einfacher zu warten und zu kombinieren.',
    practice2Title: 'Beispiele einbeziehen',
    practice2Desc: 'Zeigen, nicht nur erzählen. Füge Ein-/Ausgabe-Beispiele ein, die genau demonstrieren, wie gute Ausführung aussieht.',
    practice3Title: 'Skills versionieren',
    practice3Desc: 'Verfolge Änderungen an Skills über die Zeit. Wenn sich das Verhalten unerwartet ändert, kannst du es auf ein Skill-Update zurückführen.',

    // Wichtige Erkenntnisse
    keyTakeaways: 'Wichtige Erkenntnisse',
    takeaway1: 'Skills sind wiederverwendbare Instruktionspakete, die Agenten bei Bedarf spezialisierte Expertise verleihen',
    takeaway2: 'Im Gegensatz zu Tools (die Aktionen ausführen) liefern Skills Wissen und Methodik',
    takeaway3: 'Gut gestaltete Skills verbessern die Konsistenz und reduzieren die Aufblähung des System-Prompts',
    takeaway4: 'Das Skill-Framework ermöglicht modulare Agentenentwicklung – einmal erstellen, überall teilen',
  },

  // Phase 3: ML Fundamentals
  neuralNetworks: {
    title: 'Neuronale Netzwerke',
    description: 'Die grundlegende Architektur, die moderne KI antreibt.',
    whatIs: 'Was ist ein neuronales Netzwerk?',
    whatIsDesc: 'Ein neuronales Netzwerk ist ein vom Gehirn inspiriertes Rechenmodell. Es besteht aus Schichten verbundener Knoten (Neuronen), die lernen, Eingaben durch Training in Ausgaben umzuwandeln.',
    components: 'Kernkomponenten',
    componentsDesc: 'Die Bausteine neuronaler Netzwerke.',
    neurons: 'Neuronen',
    neuronsDesc: 'Grundeinheiten, die gewichtete Summen von Eingaben berechnen und Aktivierungsfunktionen anwenden.',
    layers: 'Schichten',
    layersDesc: 'Gruppen von Neuronen: Eingabeschicht, versteckte Schichten und Ausgabeschicht.',
    weights: 'Gewichte & Bias',
    weightsDesc: 'Lernbare Parameter, die bestimmen, wie Eingaben transformiert werden.',
    activations: 'Aktivierungsfunktionen',
    activationsDesc: 'Nichtlineare Funktionen, die es Netzwerken ermöglichen, komplexe Muster zu lernen.',
    typesOfNetworks: 'Arten von Netzwerken',
    feedforward: 'Feedforward (MLP)',
    feedforwardDesc: 'Informationen fließen in eine Richtung. Gut für tabellarische Daten.',
    cnn: 'Konvolutionell (CNN)',
    cnnDesc: 'Spezialisiert für Bilder und räumliche Daten.',
    rnn: 'Rekurrent (RNN)',
    rnnDesc: 'Verarbeitet Sequenzen mit Gedächtnis vergangener Eingaben.',
    transformer: 'Transformer',
    transformerDesc: 'Aufmerksamkeitsbasierte Architektur, die moderne LLMs antreibt.',
    interactiveDemo: 'Neuronales Netzwerk Visualisierer',
    demoDesc: 'Netzwerkarchitekturen erstellen und erkunden',
    keyTakeaways: 'Wichtige Erkenntnisse',
    takeaway1: 'Neuronale Netzwerke lernen durch Anpassung der Gewichte während des Trainings',
    takeaway2: 'Tiefe (mehr Schichten) ermöglicht das Lernen hierarchischer Merkmale',
    takeaway3: 'Verschiedene Architekturen eignen sich für verschiedene Datentypen',
    takeaway4: 'Moderne LLMs sind massive Transformer-Netzwerke',
  },

  gradientDescent: {
    title: 'Gradientenabstieg',
    description: 'Der Optimierungsalgorithmus, der neuronalen Netzwerken das Lernen ermöglicht.',
    whatIs: 'Was ist Gradientenabstieg?',
    whatIsDesc: 'Gradientenabstieg ist ein Optimierungsalgorithmus, der iterativ Modellparameter anpasst, um eine Verlustfunktion zu minimieren. So lernen neuronale Netzwerke aus Daten.',
    intuition: 'Die Intuition',
    intuitionDesc: 'Stelle dir vor, du stehst mit verbundenen Augen in einer hügeligen Landschaft und versuchst, den tiefsten Punkt zu erreichen. Du fühlst die Neigung unter deinen Füßen und gehst bergab. Wiederhole, bis du ein Tal erreichst.',
    howWorks: 'Wie es funktioniert',
    howWorksDesc: 'Der Algorithmus berechnet, wie viel jeder Parameter zum Fehler beiträgt, und passt die Parameter dann in die entgegengesetzte Richtung an.',
    step1: 'Verlust berechnen',
    step1Desc: 'Messen, wie falsch die aktuellen Vorhersagen sind.',
    step2: 'Gradienten berechnen',
    step2Desc: 'Backpropagation verwenden, um herauszufinden, wie jedes Gewicht den Verlust beeinflusst.',
    step3: 'Gewichte aktualisieren',
    step3Desc: 'Gewichte in die Richtung anpassen, die den Verlust reduziert.',
    step4: 'Wiederholen',
    step4Desc: 'Iterieren, bis der Verlust nicht mehr abnimmt.',
    learningRate: 'Lernrate',
    learningRateDesc: 'Kontrolliert, wie groß jeder Schritt ist. Zu hoch: Überschießen. Zu niedrig: langsamer Fortschritt.',
    variants: 'Varianten',
    sgd: 'Stochastischer Gradientenabstieg',
    sgdDesc: 'Verwendet zufällige Mini-Batches anstelle des gesamten Datensatzes.',
    momentum: 'Momentum',
    momentumDesc: 'Akkumuliert Geschwindigkeit, um lokale Minima zu überwinden.',
    adam: 'Adam',
    adamDesc: 'Adaptive Lernraten pro Parameter. Kombiniert Momentum mit RMSprop.',
    adamw: 'AdamW',
    adamwDesc: 'Adam mit entkoppeltem Weight Decay. Heute für die meisten Anwendungen bevorzugt, besonders beim Training großer Sprachmodelle.',

    // Learning Rate Scheduling section
    lrScheduling: 'Lernraten-Scheduling',
    lrSchedulingDesc: 'Anstatt eine feste Lernrate zu verwenden, passen Schedules sie während des Trainings für bessere Konvergenz an.',
    stepDecay: 'Stufen-Abnahme',
    stepDecayDesc: 'Lernrate um einen Faktor zu bestimmten Epochen reduzieren (z.B. alle 30 Epochen halbieren).',
    exponentialDecay: 'Exponentielle Abnahme',
    exponentialDecayDesc: 'Kontinuierliche Verringerung der Lernrate: lr = lr_0 * e^(-kt). Glatt, kann aber zu schnell abklingen.',
    cosineAnnealing: 'Kosinus-Annealing',
    cosineAnnealingDesc: 'Folgt einer Kosinuskurve von der initialen zur minimalen LR. Beliebt im modernen Training, ermöglicht sanftes Abkühlen.',
    warmup: 'Warmup',
    warmupDesc: 'Mit sehr niedriger LR starten, graduell zum Ziel erhöhen, dann abklingen. Stabilisiert frühes Training, essentiell für Transformer.',

    // Convergence Challenges section
    convergenceChallenges: 'Konvergenz-Herausforderungen',
    convergenceChallengesDesc: 'Hindernisse verstehen, die den Gradientenabstieg daran hindern können, das globale Optimum zu finden.',
    localMinima: 'Lokale Minima',
    localMinimaDesc: 'Punkte, wo der Verlust niedriger ist als in der Umgebung, aber nicht das globale Minimum. Momentum und adaptive Methoden helfen zu entkommen.',
    saddlePoints: 'Sattelpunkte',
    saddlePointsDesc: 'Punkte, wo der Gradient null ist, aber weder Minimum noch Maximum. Häufig in hohen Dimensionen, verlangsamt Konvergenz.',
    plateaus: 'Plateaus',
    plateausDesc: 'Flache Regionen, wo Gradienten sehr klein sind. Fortschritt stagniert, bis der Optimierer entkommt. Adaptive LR hilft bei der Navigation.',

    interactiveDemo: 'Gradientenabstieg-Visualisierer',
    demoDesc: 'Beobachte, wie der Gradientenabstieg das Minimum findet',
    keyTakeaways: 'Wichtige Erkenntnisse',
    takeaway1: 'Gradientenabstieg minimiert den Verlust, indem er dem Gefälle folgt',
    takeaway2: 'Die Lernrate ist der wichtigste Hyperparameter',
    takeaway3: 'AdamW ist jetzt der bevorzugte Optimierer für die meisten Deep-Learning-Anwendungen',
    takeaway4: 'Backpropagation berechnet Gradienten effizient',
  },

  training: {
    title: 'Trainingsprozess',
    description: 'Wie neuronale Netzwerke durch iterative Optimierung aus Daten lernen.',
    whatIs: 'Was ist Training?',
    whatIsDesc: 'Training ist der Prozess, einem neuronalen Netzwerk beizubringen, eine Aufgabe auszuführen, indem man es Beispielen aussetzt und seine Parameter basierend auf Fehlern anpasst.',
    phases: 'Trainingsphasen',
    phasesDesc: 'Die Stufen des Trainings eines neuronalen Netzwerks.',
    initialization: 'Initialisierung',
    initializationDesc: 'Zufällige Startgewichte setzen. Gute Initialisierung hilft beim Training.',
    forwardPass: 'Forward Pass',
    forwardPassDesc: 'Eingabe fließt durch das Netzwerk, um Vorhersagen zu produzieren.',
    lossCalc: 'Verlustberechnung',
    lossCalcDesc: 'Vorhersagen mit der Ground Truth durch eine Verlustfunktion vergleichen.',
    backprop: 'Backpropagation',
    backpropDesc: 'Gradienten des Verlusts bezüglich jedes Gewichts berechnen.',
    optimization: 'Optimierung',
    optimizationDesc: 'Gewichte mit Gradientenabstieg aktualisieren.',
    concepts: 'Schlüsselkonzepte',
    epoch: 'Epoche',
    epochDesc: 'Ein vollständiger Durchlauf durch den gesamten Trainingsdatensatz.',
    batch: 'Batch-Größe',
    batchDesc: 'Anzahl der Beispiele, die vor der Gewichtsaktualisierung verarbeitet werden.',
    overfitting: 'Überanpassung',
    overfittingDesc: 'Das Modell merkt sich Trainingsdaten, versagt aber bei neuen Daten.',
    regularization: 'Regularisierung',
    regularizationDesc: 'Techniken zur Vermeidung von Überanpassung (Dropout, Gewichtszerfall).',
    interactiveDemo: 'Trainingsfortschritt-Visualisierer',
    demoDesc: 'Beobachte, wie ein Netzwerk in Echtzeit lernt',
    keyTakeaways: 'Wichtige Erkenntnisse',
    takeaway1: 'Training reduziert iterativ Vorhersagefehler',
    takeaway2: 'Überanpassung ist der Hauptfeind – immer auf zurückgehaltenen Daten validieren',
    takeaway3: 'Batch-Größe und Lernrate beeinflussen das Training erheblich',
    takeaway4: 'Moderne LLMs erfordern massive Rechenleistung für das Training',
  },

  // Phase 3: Prompting
  promptBasics: {
    title: 'Prompt-Grundlagen',
    description: 'Grundlagen für das Schreiben effektiver Prompts für KI-Modelle.',
    whatIs: 'Was ist ein Prompt?',
    whatIsDesc: 'Ein Prompt ist die Eingabe, die du einem LLM gibst. Die Qualität deines Prompts bestimmt direkt die Qualität der Antwort. Prompting ist sowohl Kunst als auch Wissenschaft.',
    principles: 'Kernprinzipien',
    principlesDesc: 'Grundlegende Richtlinien für effektive Prompts.',
    beSpecific: 'Sei spezifisch',
    beSpecificDesc: 'Vage Prompts bekommen vage Antworten. Füge relevante Details und Einschränkungen ein.',
    showExamples: 'Zeige Beispiele',
    showExamplesDesc: 'Demonstriere das gewünschte Format und den Stil mit konkreten Beispielen.',
    giveContext: 'Gib Kontext',
    giveContextDesc: 'Hintergrundinformationen helfen dem Modell, deine Bedürfnisse zu verstehen.',
    setFormat: 'Spezifiziere das Format',
    setFormatDesc: 'Sage dem Modell genau, wie du die Ausgabe strukturiert haben möchtest.',
    anatomy: 'Anatomie eines Prompts',
    anatomyDesc: 'Die Komponenten, die einen effektiven Prompt ausmachen.',
    role: 'Rolle/Persona',
    roleDesc: 'Wer das Modell sein soll.',
    task: 'Aufgabenbeschreibung',
    taskDesc: 'Was das Modell tun soll.',
    context: 'Kontext/Hintergrund',
    contextDesc: 'Relevante Informationen für die Aufgabe.',
    format: 'Ausgabeformat',
    formatDesc: 'Wie du die Antwort strukturiert haben möchtest.',
    interactiveDemo: 'Prompt-Vergleich',
    demoDesc: 'Vergleiche schwache vs. starke Prompts',
    keyTakeaways: 'Wichtige Erkenntnisse',
    takeaway1: 'Klare, spezifische Prompts liefern bessere Ergebnisse',
    takeaway2: 'Beispiele sind mächtig – zeigen, nicht nur erzählen',
    takeaway3: 'Iteriere an Prompts; erste Versuche sind selten optimal',
    takeaway4: 'Berücksichtige die Perspektive des Modells beim Erstellen von Prompts',
  },

  advancedPrompting: {
    title: 'Fortgeschrittene Techniken',
    description: 'Ausgefeilte Prompting-Strategien für komplexe Aufgaben.',
    overview: 'Über die Grundlagen hinaus',
    overviewDesc: 'Fortgeschrittene Techniken ermöglichen fähigeres und zuverlässigeres KI-Verhalten für komplexe Aufgaben.',
    cot: 'Chain of Thought',
    cotDesc: 'Fördere schrittweises Denken, indem du das Modell bittest, Probleme "durchzudenken".',
    cotExample: 'Beispiel: "Lass uns das Schritt für Schritt lösen..."',
    cotLimitations: 'Wichtig: CoT ist nicht universell',
    cotLimitationsDesc: 'Forschung aus 2025 zeigt, dass Chain of Thought Prompting NICHT universell vorteilhaft ist. Während es die Leistung bei denkintensiven Aufgaben erheblich verbessert, bringt es minimale Gewinne bei nicht-denkbasierten Aufgaben.',
    cotLimitationItem1: 'Am effektivsten für Mathematik, Logik und mehrstufige Denkprobleme',
    cotLimitationItem2: 'Minimaler Nutzen für einfache Abruf-, Klassifizierungs- oder kreative Aufgaben',
    cotLimitationItem3: 'Erhöht Latenz und Token-Kosten—strategisch einsetzen, nicht standardmäßig',
    fewShot: 'Few-Shot-Lernen',
    fewShotDesc: 'Gib mehrere Beispiele an, um Muster zu etablieren, denen das Modell folgen soll.',
    fewShotExample: 'Füge 3-5 diverse Beispiele ein, die Randfälle abdecken.',
    selfConsistency: 'Selbstkonsistenz',
    selfConsistencyDesc: 'Generiere mehrere Antworten und wähle die konsistenteste aus.',
    selfConsistencyExample: 'Nützlich für Mathematik, Logik und Faktenfragen.',
    decomposition: 'Aufgabenzerlegung',
    decompositionDesc: 'Zerlege komplexe Aufgaben in kleinere, handhabbare Teilaufgaben.',
    decompositionExample: 'Löse Teilaufgaben unabhängig, dann kombiniere die Ergebnisse.',
    treeOfThoughts: 'Tree of Thoughts (ToT)',
    totDesc: 'Eine Erweiterung von Chain of Thought, die mehrere Denkpfade gleichzeitig erkundet, bewertet und bei Bedarf zurückverfolgt, um optimale Lösungen zu finden.',
    totHowItWorks: 'Wie es funktioniert',
    totHowItWorksDesc: 'Generiere mehrere Denkzweige bei jedem Schritt. Bewerte vielversprechende Pfade, beschneide Sackgassen und verfolge Alternativen zurück.',
    totBestFor: 'Am besten geeignet für',
    totBestForDesc: 'Planungsprobleme, Rätsel, kreative Aufgaben, die Exploration erfordern, und Probleme, bei denen der erste Ansatz möglicherweise nicht optimal ist.',
    totExample: 'Beispiel: "Betrachte 3 verschiedene Ansätze zur Lösung. Denke für jeden 2 Schritte voraus. Bewerte, welcher Pfad am vielversprechendsten ist, dann fahre fort."',
    graphOfThoughts: 'Graph of Thoughts (GoT)',
    gotDesc: 'Eine nichtlineare Denkstruktur, bei der Gedanken verschmelzen, sich verzweigen und Zyklen bilden können—modelliert, wie Menschen tatsächlich über komplexe Probleme nachdenken.',
    gotKeyFeature: 'Hauptmerkmal',
    gotKeyFeatureDesc: 'Im Gegensatz zu linearem CoT oder baumstrukturiertem ToT ermöglicht GoT das Kombinieren von Erkenntnissen aus verschiedenen Denkpfaden und das Überdenken früherer Schlussfolgerungen.',
    gotBestFor: 'Am besten geeignet für',
    gotBestForDesc: 'Komplexe Probleme mit Abhängigkeiten, Syntheseaufgaben und Probleme, bei denen Teillösungen kombiniert werden müssen.',
    gotExample: 'Beispiel: "Analysiere dieses Problem aus den Blickwinkeln A, B und C unabhängig. Identifiziere dann Verbindungen zwischen deinen Analysen und synthetisiere eine einheitliche Lösung."',
    costBenefit: 'Kosten-Nutzen-Analyse',
    costBenefitDesc: 'Fortgeschrittene Prompting-Techniken erhöhen den Token-Verbrauch, die Latenz und die API-Kosten. Zu verstehen, wann diese Kompromisse sich lohnen, ist entscheidend für Produktionssysteme.',
    worthIt: 'Die zusätzlichen Kosten wert',
    worthItItem1: 'Komplexes Denken: Mathematik, Logik, mehrstufige Analyse',
    worthItItem2: 'Entscheidungen mit hohem Einsatz: medizinische, rechtliche, finanzielle Beratung',
    worthItItem3: 'Probleme, bei denen Genauigkeit wichtiger ist als Geschwindigkeit',
    notWorthIt: 'Oft nicht lohnenswert',
    notWorthItItem1: 'Einfache Klassifizierungs- oder Extraktionsaufgaben',
    notWorthItItem2: 'Hochvolumige, latenzempfindliche Anwendungen',
    notWorthItItem3: 'Aufgaben, bei denen einfachere Prompts bereits hohe Genauigkeit erreichen',
    costBenefitTip: 'Tipp: Beginne mit einfachen Prompts und füge Komplexität nur bei Bedarf hinzu. Miss die Genauigkeitsverbesserung gegen den Kostenanstieg, um fundierte Entscheidungen zu treffen.',
    techniques: 'Zusätzliche Techniken',
    rolePlay: 'Rollenzuweisung',
    rolePlayDesc: 'Weise eine spezifische Experten-Persona zu, um das Wissen des Modells zu fokussieren.',
    constraints: 'Explizite Einschränkungen',
    constraintsDesc: 'Liste auf, was das Modell NICHT tun soll, um häufige Fehler zu vermeiden.',
    verification: 'Selbstverifikation',
    verificationDesc: 'Bitte das Modell, seine eigene Arbeit auf Fehler zu überprüfen.',
    interactiveDemo: 'Chain of Thought Demo',
    demoDesc: 'Sieh, wie Denkschritte die Ausgaben verbessern',
    keyTakeaways: 'Wichtige Erkenntnisse',
    takeaway1: 'Chain of Thought verbessert Denkaufgaben, ist aber nicht universell vorteilhaft',
    takeaway2: 'Few-Shot-Beispiele etablieren zuverlässige Muster',
    takeaway3: 'ToT und GoT erweitern CoT für komplexe, nichtlineare Probleme',
    takeaway4: 'Berücksichtige immer Kosten vs. Nutzen—fortgeschrittene Techniken erhöhen den Token-Verbrauch',
    takeaway5: 'Beginne einfach, füge Komplexität nur hinzu, wenn die Genauigkeit es erfordert',
  },

  systemPrompts: {
    title: 'System-Prompts',
    description: 'KI-Verhalten durch Anweisungen auf Systemebene konfigurieren.',
    whatIs: 'Was ist ein System-Prompt?',
    whatIsDesc: 'Ein System-Prompt ist eine spezielle Anweisung, die den Kontext, die Persona und die Verhaltensrichtlinien für ein KI-Modell festlegt. Er ist typischerweise vor Benutzern verborgen und bleibt während eines Gesprächs bestehen.',
    purpose: 'Zweck von System-Prompts',
    purposeDesc: 'System-Prompts legen die Grundlage dafür, wie sich die KI verhalten soll.',
    setPersona: 'Persona definieren',
    setPersonaDesc: 'Festlegen, wer die KI ist: ein Assistent, Experte, Charakter, etc.',
    setBoundaries: 'Grenzen setzen',
    setBoundariesDesc: 'Definieren, was die KI tun und nicht tun soll.',
    establishTone: 'Ton festlegen',
    establishToneDesc: 'Kommunikationsstil festlegen: formell, locker, technisch.',
    provideKnowledge: 'Kontext bereitstellen',
    provideKnowledgeDesc: 'Domänenwissen oder anwendungsspezifische Regeln einbeziehen.',
    structure: 'Struktur effektiver System-Prompts',
    structureDesc: 'Gut organisierte System-Prompts sind für Modelle leichter zu befolgen.',
    identity: 'Identitätsabschnitt',
    identityDesc: 'Wer ist die KI? Was ist ihre Rolle?',
    capabilities: 'Fähigkeiten',
    capabilitiesDesc: 'Was kann die KI tun? Welche Tools hat sie?',
    limitations: 'Einschränkungen',
    limitationsDesc: 'Was soll die KI vermeiden oder ablehnen?',
    guidelines: 'Richtlinien',
    guidelinesDesc: 'Spezifische Regeln für Verhalten und Antworten.',
    bestPractices: 'Best Practices',
    practice1: 'Sei explizit über Randfälle und Fehlerbehandlung.',
    practice2: 'Teste System-Prompts mit adversariellen Eingaben.',
    practice3: 'Versioniere deine System-Prompts.',
    practice4: 'Halte Prompts fokussiert – nicht mit Anweisungen überladen.',
    examplePrompt: 'Beispiel System-Prompt',
    interactiveBuilder: 'Interaktiver Builder',
    builderDesc: 'Erstelle deinen eigenen System-Prompt aus Komponenten',
    keyTakeaways: 'Wichtige Erkenntnisse',
    takeaway1: 'System-Prompts definieren die Persona und das Verhalten der KI',
    takeaway2: 'Strukturiere Prompts klar: Identität, Fähigkeiten, Einschränkungen',
    takeaway3: 'Teste mit Randfällen – Benutzer werden sie finden',
    takeaway4: 'System-Prompts können überschrieben werden – verlasse dich nicht allein auf sie für Sicherheit',
  },

  // LLM Training page
  llmTraining: {
    title: 'LLM-Training',
    description: 'Wie große Sprachmodelle trainiert werden: von Pretraining bis RLHF.',
    whatIs: 'Wie LLMs trainiert werden',
    whatIsDesc: 'Große Sprachmodelle durchlaufen mehrere Trainingsphasen, jede mit unterschiedlichen Zielen und Techniken. Das Verständnis dieser Pipeline ist entscheidend für das Verständnis der Modellfähigkeiten und -einschränkungen.',
    whyMatters: 'Warum Training wichtig ist',
    whyMattersDesc: 'Der Trainingsprozess formt grundlegend, was LLMs können und was nicht. Verschiedene Trainingsansätze produzieren Modelle mit unterschiedlichen Stärken, Schwächen und Verhaltensweisen.',

    // LLM Training Pipeline
    trainingPipeline: 'Die LLM-Trainingspipeline',
    trainingPipelineDesc: 'Moderne LLMs durchlaufen mehrere Trainingsstufen, jede mit unterschiedlichen Zielen. Das Verständnis dieser Pipeline ist entscheidend für das Verständnis, wo Alignment hineinpasst.',

    pretraining: 'Stufe 1: Pretraining',
    pretrainingDesc: 'Das Foundation-Modell wird auf massiven Textkorpora (Billionen von Tokens) mit selbstüberwachtem Lernen trainiert. Das Modell lernt, das nächste Token vorherzusagen und entwickelt dabei breites Wissen und Sprachfähigkeiten.',
    pretrainingGoal: 'Ziel: Sprachmuster, Fakten und Denken aus Rohtext lernen.',
    pretrainingData: 'Daten: Webseiten, Bücher, Code, wissenschaftliche Paper – typischerweise 1-10+ Billionen Tokens.',
    pretrainingResult: 'Ergebnis: Ein fähiges, aber nicht-aligniertes "Basismodell", das Text vervollständigt, aber keine Anweisungen befolgt.',

    sft: 'Stufe 2: Supervised Fine-Tuning (SFT)',
    sftDesc: 'Das Basismodell wird auf kuratierten Anweisung-Antwort-Paaren feingetunt, die von menschlichen Annotatoren erstellt wurden. Dies lehrt das Modell, Anweisungen zu befolgen und hilfreich zu antworten.',
    sftGoal: 'Ziel: Das Basismodell in einen anweisungsfolgenden Assistenten verwandeln.',
    sftData: 'Daten: ~10K-100K hochwertige Anweisung-Antwort-Beispiele.',
    sftResult: 'Ergebnis: Ein Modell, das Anweisungen befolgen kann, aber möglicherweise noch schädliche oder nicht hilfreiche Ausgaben produziert.',

    rlhfStage: 'Stufe 3: RLHF / Präferenz-Tuning',
    rlhfStageDesc: 'Menschliche Bewerter ranken Modellausgaben nach Qualität. Ein Reward-Modell lernt diese Präferenzen, dann wird das LLM optimiert, um die Belohnung mit Reinforcement Learning (PPO) oder Direct Preference Optimization (DPO) zu maximieren.',
    rlhfGoal: 'Ziel: Das Modell mit menschlichen Präferenzen für Hilfsbereitschaft, Harmlosigkeit und Ehrlichkeit alignieren.',
    rlhfData: 'Daten: Menschliche Präferenzvergleiche (A ist besser als B).',
    rlhfResult: 'Ergebnis: Ein Modell, das Ausgaben produziert, die Menschen bevorzugen, und schädliches Verhalten vermeidet.',

    continuedTraining: 'Stufe 4: Fortgesetztes Training & Spezialisiertes Alignment',
    continuedTrainingDesc: 'Modelle können zusätzliches Training für spezifische Fähigkeiten (Coding, Mathematik, Tool-Nutzung) oder Sicherheitsverfeinerungen (Red Teaming, Constitutional AI) durchlaufen. Diese Stufe ist während der Bereitstellung fortlaufend.',

    // RL Paradigm
    rlParadigm: 'Das RL-Paradigma: Lernen ohne menschliche Labels',
    rlParadigmDesc: 'Ein revolutionärer Ansatz, bei dem Modelle Denken durch reines Reinforcement Learning bei verifizierbaren Aufgaben lernen, ohne menschliche Demonstrationen oder Präferenz-Labels.',
    rlParadigmWhat: 'Was ist das RL-Paradigma?',
    rlParadigmWhatDesc: 'Anstatt aus von Menschen geschriebenen Beispielen (SFT) oder menschlichen Präferenzen (RLHF) zu lernen, lernen Modelle direkt aus ergebnisbasierten Belohnungen. Wenn die Antwort korrekt ist, wird das Modell belohnt. Wenn falsch, wird es bestraft. Keine menschliche Beschriftung erforderlich.',
    deepseekR1: 'DeepSeek R1-Zero: Eine Fallstudie',
    deepseekR1Desc: 'DeepSeek R1-Zero demonstrierte, dass leistungsfähiges Denken aus reinem RL entstehen kann, ohne jegliches Supervised Fine-Tuning. Das Modell entwickelte Chain-of-Thought-Denken, Selbstverifikation und sogar "Aha-Momente" vollständig durch Reinforcement Learning.',
    rlKey1: 'Kein SFT erforderlich',
    rlKey1Desc: 'R1-Zero wurde direkt aus einem Basismodell nur mit RL trainiert und übersprang die SFT-Stufe vollständig. Denkverhalten entstand natürlich.',
    rlKey2: 'Verifizierbare Belohnungen',
    rlKey2Desc: 'Training konzentrierte sich auf Aufgaben mit objektiv verifizierbaren Antworten: Matheprobleme, Coding-Challenges, logische Rätsel. Kein subjektives menschliches Urteil nötig.',
    rlKey3: 'Emergente Verhaltensweisen',
    rlKey3Desc: 'Das Modell entwickelte spontan erweitertes Denken, Selbstkorrektur und Reflexion – Verhaltensweisen, die frühere Modelle nur aus menschlichen Demonstrationen lernten.',
    rlKey4: 'Lesbarkeits-Herausforderungen',
    rlKey4Desc: 'Reine RL-Modelle können ungewöhnliche Denkmuster entwickeln, die schwer zu interpretieren sind. DeepSeek fügte eine kleine Menge menschlicher Daten hinzu, um die Lesbarkeit zu verbessern.',
    rlVsRlhf: 'RL-Paradigma vs. Traditionelles RLHF',
    rlVsRlhfDesc: 'Diese Ansätze lösen unterschiedliche Probleme und können komplementär sein.',
    rlhfApproach: 'RLHF-Ansatz',
    rlhfApproachDesc: 'Aus menschlichen Präferenzen lernen. Erfordert teure menschliche Beschriftung. Gut für subjektive Aufgaben wie Schreibqualität und Hilfsbereitschaft.',
    rlApproach: 'RL-Paradigma-Ansatz',
    rlApproachDesc: 'Aus verifizierbaren Ergebnissen lernen. Keine menschliche Beschriftung nötig. Hervorragend für Denken, Mathematik und Coding, wo Korrektheit objektiv ist.',
    hybridApproach: 'Hybrid-Ansatz',
    hybridApproachDesc: 'Moderne Modelle kombinieren oft beides: RL für Denkfähigkeiten, RLHF für Alignment und Benutzerpräferenzen.',

    // Key Alignment Concepts
    concepts: 'Schlüssel-Alignment-Konzepte',
    conceptsDesc: 'Grundlegende Ideen in der KI-Alignment-Forschung.',
    outerAlignment: 'Outer Alignment',
    outerAlignmentDesc: 'Sicherstellen, dass das Trainingsziel (Reward-Funktion) korrekt erfasst, was wir wollen. Selbst perfekte Optimierung eines falsch spezifizierten Ziels führt zu schlechten Ergebnissen.',
    innerAlignment: 'Inner Alignment',
    innerAlignmentDesc: 'Sicherstellen, dass das gelernte Modell tatsächlich für das Trainingsziel optimiert, nicht für ein Proxy-Ziel, das zufällig während des Trainings korreliert.',
    specification: 'Spezifikationsproblem',
    specificationDesc: 'Die fundamentale Schwierigkeit, präzise zu formulieren, was wir in allen Situationen wollen. Menschliche Werte sind komplex, kontextabhängig und manchmal widersprüchlich.',
    robustness: 'Robustheit',
    robustnessDesc: 'Aufrechterhaltung des Alignments unter Verteilungsverschiebung, adversariellem Druck und neuartigen Situationen, auf die das Modell nicht trainiert wurde.',
    deception: 'Täuschendes Alignment',
    deceptionDesc: 'Ein theoretisches Risiko, bei dem ein Modell während des Trainings aligned erscheint, aber bei der Bereitstellung andere Ziele verfolgt – sich nur gut verhält, weil es evaluiert wird.',
    goalMisgeneralization: 'Ziel-Fehlgeneralisierung',
    goalMisgeneralizationDesc: 'Wenn ein Modell ein Proxy-Ziel lernt, das im Training funktioniert, aber bei der Bereitstellung versagt. Beispiel: Lernen, positives Feedback zu bekommen, statt wirklich hilfreich zu sein.',

    // Alignment Techniques
    techniques: 'Alignment-Techniken',
    rlhf: 'RLHF (Reinforcement Learning from Human Feedback)',
    rlhfDesc: 'Ein Reward-Modell auf menschlichen Präferenzen trainieren, dann RL verwenden, um das LLM dagegen zu optimieren. Die dominante Alignment-Technik seit GPT-4.',
    constitutionalAi: 'Constitutional AI (CAI)',
    constitutionalAiDesc: 'Prinzipien definieren (eine "Verfassung") und das Modell seine eigenen Ausgaben kritisieren und überarbeiten lassen. Reduziert die Abhängigkeit von menschlichen Labeln und skaliert besser.',
    dpo: 'Direct Preference Optimization (DPO)',
    dpoDesc: 'Das Reward-Modell überspringen – das LLM direkt auf Präferenzdaten optimieren. Einfacher und stabiler als RLHF.',
    redTeaming: 'Red Teaming',
    redTeamingDesc: 'Adversarielle Tests durch Menschen oder andere KI-Modelle, um Fehlermodi, Jailbreaks und schädliche Ausgaben vor der Bereitstellung zu finden.',
    interpretability: 'Interpretierbarkeit',
    interpretabilityDesc: 'Verstehen, was Modelle tatsächlich intern lernen. Entscheidend für die Verifizierung von Alignment statt nur Verhaltenmessung.',
    safetyFilters: 'Sicherheitsfilter & Guardrails',
    safetyFiltersDesc: 'Zusätzliche Schichten, die Eingaben/Ausgaben auf schädlichen Inhalt filtern. Eine Defense-in-Depth-Maßnahme, kein Ersatz für Alignment.',

    // DPO vs RLHF Deep Dive
    dpoVsRlhf: 'DPO vs RLHF: Ein tiefgreifender Vergleich',
    dpoVsRlhfDesc: 'Direct Preference Optimization (DPO) und Reinforcement Learning from Human Feedback (RLHF) sind die zwei dominanten Ansätze zur Alignierung von LLMs mit menschlichen Präferenzen. Das Verständnis ihrer Unterschiede ist entscheidend für die Wahl der richtigen Technik.',

    rlhfDeep: 'RLHF: Der traditionelle Ansatz',
    rlhfDeepDesc: 'RLHF verwendet ein separates Reward-Modell, das auf menschlichen Präferenzen trainiert wird, und optimiert dann das LLM mit Reinforcement Learning (typischerweise PPO), um diese Belohnung zu maximieren.',
    rlhfStep1: 'Schritt 1: Präferenzen sammeln',
    rlhfStep1Desc: 'Menschen vergleichen Paare von Modellausgaben und wählen, welche sie bevorzugen. Dies erstellt einen Datensatz von Präferenz-Rankings.',
    rlhfStep2: 'Schritt 2: Reward-Modell trainieren',
    rlhfStep2Desc: 'Ein separates neuronales Netzwerk lernt, menschliche Präferenzen vorherzusagen und weist Modellausgaben Scores zu.',
    rlhfStep3: 'Schritt 3: RL-Optimierung',
    rlhfStep3Desc: 'PPO (Proximal Policy Optimization) verwenden, um das LLM zu aktualisieren, damit es Ausgaben generiert, die die Scores des Reward-Modells maximieren.',

    dpoDeep: 'DPO: Die vereinfachte Alternative',
    dpoDeepDesc: 'DPO überspringt das Reward-Modell vollständig und optimiert das LLM direkt auf Präferenzdaten durch eine clevere mathematische Umformulierung.',
    dpoStep1: 'Schritt 1: Präferenzen sammeln',
    dpoStep1Desc: 'Wie bei RLHF—Menschen vergleichen Ausgabepaare und geben an, welche sie bevorzugen.',
    dpoStep2: 'Schritt 2: Direkte Optimierung',
    dpoStep2Desc: 'Anstatt ein separates Reward-Modell zu trainieren, aktualisiert DPO das LLM direkt, um die Wahrscheinlichkeit bevorzugter Ausgaben zu erhöhen.',
    dpoStep3: 'Schritt 3: Kein RL erforderlich',
    dpoStep3Desc: 'Verwendet Standard-Supervised-Learning-Techniken und vermeidet die Instabilität und Komplexität von Reinforcement Learning.',

    comparisonTable: 'Direkter Vergleich',
    aspect: 'Aspekt',
    complexity: 'Komplexität',
    rlhfComplexity: 'Hoch: erfordert Reward-Modell + RL-Training',
    dpoComplexity: 'Niedrig: einstufiges Supervised Learning',
    rewardModel: 'Reward-Modell',
    rlhfRewardModel: 'Erforderlich (separates neuronales Netzwerk)',
    dpoRewardModel: 'Nicht benötigt (implizit in der Verlustfunktion)',
    stability: 'Trainingsstabilität',
    rlhfStability: 'Kann instabil sein, erfordert sorgfältiges Tuning',
    dpoStability: 'Generell stabiler und vorhersagbarer',
    flexibility: 'Flexibilität',
    rlhfFlexibility: 'Flexibler, Reward-Modell wiederverwendbar',
    dpoFlexibility: 'Weniger flexibel, an spezifische Präferenzen gebunden',
    usedBy: 'Verwendet von',
    rlhfUsedBy: 'GPT-4, Claude, frühe Llama-Modelle',
    dpoUsedBy: 'Llama 3, Zephyr, viele Open-Source-Modelle',

    // GRPO Section
    grpo: 'GRPO: Group Relative Policy Optimization',
    grpoDesc: 'GRPO ist eine von DeepSeek entwickelte Alignment-Technik, die relative Rankings innerhalb von Antwortgruppen verwendet und dabei die Notwendigkeit eines separaten Reward-Modells eliminiert, während die Trainingsstabilität erhalten bleibt.',
    grpoHow: 'Wie GRPO funktioniert',
    grpoHowDesc: 'Anstelle von absoluten Reward-Scores vergleicht GRPO mehrere Antworten auf denselben Prompt und verwendet ihre relativen Rankings zur Berechnung von Policy-Gradienten.',
    grpoStep1: 'Antwortgruppe generieren',
    grpoStep1Desc: 'Für jeden Prompt werden mehrere Kandidaten-Antworten (typischerweise 4-16) von der aktuellen Policy generiert.',
    grpoStep2: 'Innerhalb der Gruppe ranken',
    grpoStep2Desc: 'Antworten innerhalb jeder Gruppe bewerten und ranken. Das Ranking kann verifizierbare Belohnungen (für Mathe/Code) oder gelernte Präferenzen verwenden.',
    grpoStep3: 'Relatives Gradienten-Update',
    grpoStep3Desc: 'Die Policy aktualisieren, um die Wahrscheinlichkeit höher gerankter Antworten relativ zu niedriger gerankten innerhalb jeder Gruppe zu erhöhen.',
    grpoAdvantages: 'Vorteile',
    grpoAdv1: 'Kein separates Reward-Modell nötig—reduziert Speicher und Komplexität',
    grpoAdv2: 'Stabiler als PPO—relative Vergleiche sind robuster als absolute Scores',
    grpoAdv3: 'Funktioniert gut mit verifizierbaren Belohnungen (Mathe, Code) und gelernten Präferenzen',
    grpoUseCases: 'Wichtige Anwendungen',
    grpoUse1: 'DeepSeek R1 Reasoning-Modell-Training',
    grpoUse2: 'Optimierung mathematischer und Coding-Aufgaben',
    grpoUse3: 'Effizientes Alignment ohne Reward-Modell-Overhead',

    // Synthetic Data Section
    syntheticData: 'Synthetische Daten für Alignment',
    syntheticDataDesc: 'Die Verwendung von KI-Modellen zur Generierung von Trainingsdaten revolutioniert das Alignment. Dieser Ansatz kann über die menschliche Annotationskapazität hinaus skalieren und dabei durch sorgfältiges Design Qualität bewahren.',
    syntheticHow: 'Methoden zur Generierung synthetischer Daten',
    syntheticHowDesc: 'Mehrere Techniken haben sich für die Generierung hochwertiger synthetischer Trainingsdaten für Alignment entwickelt.',
    syntheticCAI: 'Constitutional AI (Anthropic)',
    syntheticCAIDesc: 'Das Modell kritisiert und überarbeitet seine eigenen Ausgaben basierend auf einem Satz von Prinzipien. Die KI generiert sowohl die problematische Antwort als auch die verbesserte Version und erstellt so Präferenzpaare ohne menschliche Beschriftung.',
    syntheticSelfInstruct: 'Self-Instruct & Evol-Instruct',
    syntheticSelfInstructDesc: 'Modelle generieren ihre eigenen Anweisung-Antwort-Paare, die dann auf Qualität gefiltert werden. Evol-Instruct (verwendet in WizardLM) macht Anweisungen iterativ komplexer.',
    syntheticDistillation: 'Modell-Destillation',
    syntheticDistillationDesc: 'Ein größeres, fähigeres Modell generiert Trainingsdaten für ein kleineres Modell. Dies überträgt Wissen und Alignment-Eigenschaften, wie bei vielen Open-Source-Modellen zu sehen, die auf GPT-4-Ausgaben trainiert wurden.',
    syntheticBenefits: 'Vorteile',
    syntheticBenefit1: 'Massive Skalierung—Millionen von Beispielen günstig generieren',
    syntheticBenefit2: 'Konsistente Qualität—keine Ermüdung oder Uneinigkeit menschlicher Annotatoren',
    syntheticBenefit3: 'Gezielte Generierung—Daten für spezifische Schwächen erstellen',
    syntheticRisks: 'Risiken & Einschränkungen',
    syntheticRisk1: 'Modellkollaps—Training auf KI-generierten Daten kann Fähigkeiten verschlechtern',
    syntheticRisk2: 'Bias-Verstärkung—KI-Biases werden in synthetischen Daten verstärkt',
    syntheticRisk3: 'Qualitätsobergrenze—Qualität synthetischer Daten durch Quellmodell begrenzt',

    // Fine-tuning vs Alignment
    fineTuningVsAlignment: 'Fine-Tuning vs. Alignment',
    fineTuningVsAlignmentDesc: 'Fine-Tuning und Alignment sind verwandte, aber unterschiedliche Konzepte.',
    fineTuningDef: 'Fine-Tuning',
    fineTuningDefDesc: 'Ein Modell an neue Aufgaben oder Domänen anpassen, indem auf aufgabenspezifischen Daten trainiert wird. Kann für jeden Zweck durchgeführt werden.',
    alignmentDef: 'Alignment',
    alignmentDefDesc: 'Speziell das Verhalten eines Modells an menschliche Werte und Absichten anpassen. Eine Teilmenge von Fine-Tuning mit einem spezifischen Ziel.',
    postTrainingDef: 'Post-Training',
    postTrainingDefDesc: 'Der Oberbegriff für alles nach dem Pretraining: SFT, RLHF, spezialisiertes Fine-Tuning, Sicherheitstraining, etc.',

    keyTakeaways: 'Wichtige Erkenntnisse',
    takeaway1: 'LLM-Training hat distinkte Stufen: Pretraining → SFT → RLHF → spezialisiertes Alignment',
    takeaway2: 'Das RL-Paradigma (z.B. DeepSeek R1-Zero) zeigt, dass Denken aus reinem RL ohne menschliche Demonstrationen entstehen kann',
    takeaway3: 'RLHF aligniert Modelle mit menschlichen Präferenzen; reines RL optimiert für verifizierbare Ergebnisse',
    takeaway4: 'Moderne Modelle kombinieren oft mehrere Techniken: SFT für Anweisungsbefolgung, RLHF für Präferenzen, RL für Denken',
    takeaway5: 'Das Verständnis der Trainingspipeline hilft, Modellverhalten und -einschränkungen zu verstehen',
    takeaway6: 'Das Feld entwickelt sich schnell – neue Paradigmen wie reines RL verändern, wie wir über Training denken',
  },

  // Mixture of Experts Seite
  moe: {
    title: 'Mixture of Experts',
    description: 'Verstehen von spärlich aktivierten Modellen, die spezialisierte Expertennetzwerke für effiziente Skalierung nutzen.',
    whatIs: 'Was ist Mixture of Experts?',
    whatIsDesc: 'ist eine neuronale Netzwerkarchitektur, die Berechnungen auf spezialisierte Teilnetzwerke namens "Experten" aufteilt. Für jede Eingabe wird nur eine Teilmenge der Experten aktiviert, was massive Modellkapazität bei handhabbaren Rechenkosten ermöglicht.',
    brainAnalogy: '"Genau wie das Gehirn je nach Aufgabe bestimmte Regionen aktiviert, aktivieren MoE-Modelle nur die relevanten Experten für jedes Token."',
    brainAnalogyDesc: '— Dieser biomimetische Ansatz ermöglicht Modelle mit Billionen von Parametern, während bei der Inferenz nur ein Bruchteil verwendet wird.',

    // Wie es funktioniert
    howItWorks: 'Wie MoE funktioniert',
    step1Title: 'Eingabe kommt an',
    step1Desc: 'Jedes Token (oder Gruppe von Tokens) wird durch die Transformer-Schichten verarbeitet, bis es die MoE-Schicht erreicht, die das traditionelle dichte Feed-Forward-Netzwerk (FFN) ersetzt.',
    step2Title: 'Router wählt Experten',
    step2Desc: 'Ein Gating-Netzwerk (Router) untersucht die Eingabe und bestimmt, welche Experten sie verarbeiten sollen. Typischerweise werden nur die top-K Experten (z.B. top-2 oder top-8) mit den höchsten Werten ausgewählt.',
    step3Title: 'Experten verarbeiten & kombinieren',
    step3Desc: 'Die ausgewählten Experten verarbeiten die Eingabe parallel. Ihre Ausgaben werden mit den Router-Scores gewichtet und kombiniert, um das Endergebnis zu erzeugen.',

    // Router
    routerTitle: 'Der Router (Gating-Netzwerk)',
    routerSubtitle: 'Das Gehirn des MoE-Systems',
    routerDesc: 'Der Router ist ein kleines neuronales Netzwerk, das lernt, Tokens zu geeigneten Experten zu leiten. Er gibt eine Wahrscheinlichkeitsverteilung über alle Experten aus und bestimmt, welche aktiviert werden.',
    topKRouting: 'Top-K Routing',
    topKRoutingDesc: 'Nur die K Experten mit den höchsten Scores werden aktiviert. Übliche Werte sind top-2 (Mixtral) oder top-8 (DeepSeek, Qwen). Dies stellt sicher, dass die Rechenkosten unabhängig von der Gesamtzahl der Experten konstant bleiben.',
    loadBalancing: 'Lastverteilung',
    loadBalancingDesc: 'Das Training beinhaltet Hilfsverluste, um "Expertenkollaps" zu verhindern, bei dem alle Tokens zu den gleichen wenigen Experten geleitet werden. Dies stellt sicher, dass alle Experten genutzt werden und unterschiedliche Spezialisierungen entwickeln.',

    // Expertenspezialisierung
    expertSpecialization: 'Expertenspezialisierung',
    expert1Title: 'Domänenexperten',
    expert1Desc: 'Einige Experten spezialisieren sich natürlich auf Domänen wie Code, Mathematik oder bestimmte Sprachen. Dies entsteht aus dem Training, nicht aus explizitem Design.',
    expert2Title: 'Musterexperten',
    expert2Desc: 'Experten können sich auf linguistische Muster wie formelles Schreiben, Konversationston oder technische Terminologie spezialisieren.',
    expert3Title: 'Aufgabenexperten',
    expert3Desc: 'Einige Experten werden besser bei bestimmten Aufgaben wie Zusammenfassung, Übersetzung oder Schlussfolgerung – obwohl die Grenzen oft fließend sind.',
    expertNote: 'Expertenspezialisierung entsteht organisch während des Trainings. Forscher arbeiten noch daran, vollständig zu verstehen, was jeder Experte lernt.',

    // Skalierung
    scaleTitle: 'MoE im großen Maßstab: Reale Modelle',
    modelColumn: 'Modell',
    totalParams: 'Gesamtparameter',
    activeParams: 'Aktiv pro Token',
    expertsColumn: 'Experten (Routing)',
    scaleNote: 'Beachte, wie die aktiven Parameter 5-20x kleiner sind als die Gesamtparameter – das ist der Effizienzvorteil von MoE.',

    // Vorteile
    advantagesTitle: 'Warum MoE wichtig ist',
    advantage1Title: 'Massive Kapazität, effiziente Inferenz',
    advantage1Desc: 'MoE-Modelle können Billionen von Parametern haben, aktivieren aber nur einen Bruchteil pro Token. Dies ermöglicht viel größere Modellkapazität ohne proportional steigende Inferenzkosten.',
    advantage2Title: 'Schnelleres Training',
    advantage2Desc: 'Recheneffizienteres Pretraining, da jeder Parameter nur von einer Teilmenge der Tokens aktualisiert wird. Die gleiche Leistung kann mit weniger Gesamt-Rechenaufwand erreicht werden.',
    advantage3Title: 'Spezialisierte Verarbeitung',
    advantage3Desc: 'Verschiedene Experten können sich auf verschiedene Inhaltstypen spezialisieren – Code, Mathematik, Sprachen – was bessere Leistung über diverse Aufgaben bietet.',
    advantage4Title: 'Skalierbare Architektur',
    advantage4Desc: 'Mehr Experten hinzuzufügen erhöht die Kapazität ohne die Inferenzkosten zu ändern (solange top-K gleich bleibt). Dies ermöglicht kontinuierliche Skalierung.',

    // Herausforderungen
    challengesTitle: 'Herausforderungen von MoE',
    challenge1Title: 'Hohe Speicheranforderungen',
    challenge1Desc: 'Alle Expertenparameter müssen in den Speicher geladen werden, obwohl nur eine Teilmenge pro Token verwendet wird. Ein 671B-Parameter-Modell benötigt 671B Parameter im VRAM.',
    challenge2Title: 'Trainingsinstabilität',
    challenge2Desc: 'Die Lastverteilung zwischen Experten ist knifflig. Ohne sorgfältiges Tuning werden einige Experten möglicherweise nie verwendet ("tote Experten") oder alle Tokens werden zu den gleichen wenigen Experten geleitet.',
    challenge3Title: 'Kommunikationsoverhead',
    challenge3Desc: 'Bei verteiltem Training/Inferenz führt das Routing von Tokens zu Experten auf verschiedenen GPUs zu Netzwerk-Kommunikationsoverhead.',

    // Vergleich
    comparisonTitle: 'Dichte vs. Spärliche Modelle',
    denseModel: 'Dichtes Modell',
    dense1: 'Alle Parameter aktiv für jedes Token',
    dense2: 'Einfacheres Training und Deployment',
    dense3: 'Speicher = Rechenkosten (beide skalieren zusammen)',
    sparseModel: 'Spärliches MoE-Modell',
    sparse1: 'Nur top-K Experten aktiv pro Token',
    sparse2: 'Höhere Gesamtkapazität bei gleichem Rechenaufwand',
    sparse3: 'Speicher >> Rechenkosten (entkoppelt)',

    // Wichtige Erkenntnisse
    keyTakeaways: 'Wichtige Erkenntnisse',
    takeaway1: 'MoE ermöglicht massive Modellkapazität mit handhabbaren Inferenzkosten, indem nur eine Teilmenge der Experten pro Token aktiviert wird',
    takeaway2: 'Fast alle führenden Frontier-Modelle (DeepSeek, Qwen, Mixtral, Llama 4) nutzen jetzt MoE-Architekturen',
    takeaway3: 'Das Router/Gating-Netzwerk lernt, Tokens zu spezialisierten Experten zu leiten – Spezialisierung entsteht aus dem Training',
    takeaway4: 'Der Hauptkompromiss: hohe Speicheranforderungen (alle Experten geladen) vs. effiziente Berechnung (wenige Experten aktiv)',

    // Interaktiver Visualizer
    vizTitle: 'MoE Generierungs-Visualizer',
    vizSubtitle: '8 Experten, top-2 Routing (wie Mixtral)',
    vizGenerate: 'Generieren',
    vizVramWarning: 'Alle Experten müssen im VRAM geladen sein',
    vizVramExplain: 'Obwohl nur 2 Experten pro Token aktiviert werden, müssen alle 8 Experten im GPU-Speicher geladen bleiben. Deshalb haben MoE-Modelle trotz effizienter Berechnung hohe Speicheranforderungen.',
    vizVramUsage: 'VRAM-Nutzung',
    vizLoaded: 'geladen',
    vizActive: 'aktiv',
    vizMemoryFootprint: '100% Speicherbedarf',
    vizCannotOffload: 'Inaktive Experten können nicht ausgelagert werden',
    vizRouter: 'Router',
    vizNextToken: 'Nächstes Token zu generieren',
    vizRouterLabel: 'Gating-Netzwerk',
    vizExpertsLabel: 'Experten (alle im VRAM geladen)',
    vizGeneratedText: 'Generierter Text',
    vizKeyInsight: 'Wichtige Erkenntnis: Speicher vs. Rechen-Kompromiss',
    vizKeyInsightDesc: 'Ein 46,7B Parameter MoE-Modell wie Mixtral 8x7B benötigt VRAM für alle 46,7B Parameter, nutzt aber nur ~12,9B Parameter pro Token. Man zahlt den Speicherpreis im Voraus, erhält aber effiziente Inferenz.',
    vizTrainingTitle: 'Trainingskomplexität: Lastverteilung',
    vizTrainingDesc: 'Experten haben keine festen Spezialisierungen – was jeder Experte lernt, entsteht organisch während des Trainings. Das schafft eine große Herausforderung:',
    vizTraining1: 'Ohne sorgfältige Balancierung könnte der Router immer dieselben wenigen Experten wählen, sodass andere als "tote Experten" zurückbleiben, die sich nie verbessern',
    vizTraining2: 'Hilfsverlustfunktionen bestrafen ungleiche Expertennutzung und zwingen den Router, Tokens gleichmäßiger über alle Experten zu verteilen',
    vizTraining3: 'Selbst mit Balancierung bleibt die Experten-Spezialisierung unscharf – derselbe Experte kann Mathematik, bestimmte Sprachen UND spezifische Syntax-Muster verarbeiten',
  },

  // Quantization page
  quantization: {
    title: 'Quantisierung',
    description: 'Wie die Reduzierung numerischer Präzision es ermöglicht, große Modelle auf Consumer-Hardware mit minimalem Qualitätsverlust auszuführen.',

    // What is Quantization
    whatIs: 'Was ist Quantisierung?',
    whatIsDesc: 'ist der Prozess der Reduzierung der numerischen Präzision von Modellgewichten von 32-Bit-Gleitkomma (FP32) auf niedrigere Bit-Darstellungen wie FP16, INT8 oder INT4. Dies reduziert den Speicherbedarf dramatisch und beschleunigt die Inferenz.',
    analogy: '"Wie das Komprimieren eines hochauflösenden Fotos für dein Handy – du verlierst etwas Detail, aber das Bild bleibt erkennbar und nützlich."',
    analogyDesc: '— Die wichtigste Erkenntnis ist, dass neuronale Netzwerke überraschend robust gegenüber Präzisionsverlust sind. Die meisten Gewichte können mit weit weniger Bits gespeichert werden, ohne katastrophale Qualitätsverschlechterung.',

    // Why Quantize
    whyQuantize: 'Warum Quantisieren?',
    whyQuantizeDesc: 'Quantisierung ermöglicht es, große Modelle auf Consumer-Hardware auszuführen und reduziert die Inferenzkosten in der Produktion.',
    benefit1Title: 'Speicherreduktion',
    benefit1Desc: 'Ein 70B-Parameter-Modell bei FP16 benötigt ~140GB VRAM. Bei INT4 passt es in ~35GB – ausführbar auf High-End-Consumer-GPUs.',
    benefit2Title: 'Schnellere Inferenz',
    benefit2Desc: 'Arithmetik mit niedrigerer Präzision ist schneller. INT8-Operationen sind 2-4x schneller als FP32 auf moderner Hardware.',
    benefit3Title: 'Niedrigere Kosten',
    benefit3Desc: 'Kleinere Modelle bedeuten weniger GPUs, niedrigere Cloud-Kosten und Machbarkeit für Edge-Deployment.',
    benefit4Title: 'Demokratisierung',
    benefit4Desc: 'Ermöglicht Forschern und Hobbyisten, Frontier-Klasse-Modelle lokal ohne Enterprise-Hardware auszuführen.',

    // Interactive Visualizer
    vizTitle: 'Quantisierungs-Visualizer',
    vizSubtitle: 'Sieh, wie Präzision Modellgröße und Qualität beeinflusst',
    vizPrecision: 'Präzisionsstufe',
    vizModelSize: 'Modellgröße',
    vizAccuracy: 'Erhaltene Genauigkeit',
    vizPerplexity: 'Perplexitätsanstieg',
    vizOfOriginal: 'vom Original',
    vizRetained: 'erhalten',
    vizWeightDist: 'Gewichtsverteilung',
    vizDiscreteLevel: 'diskrete Stufen',
    vizExplanation: 'Erklärung',
    vizFp32Explain: 'Volle Präzision (32 Bit). Maximale Genauigkeit, maximaler Speicher. Wird hauptsächlich für Training verwendet.',
    vizFp16Explain: 'Halbe Präzision (16 Bit). Vernachlässigbarer Qualitätsverlust für die meisten Aufgaben. Standard für Inferenz.',
    vizInt8Explain: 'Integer-Präzision (8 Bit). Exzellente Balance aus Qualität und Effizienz. Produktionsstandard.',
    vizInt4Explain: 'Stark komprimiert (4 Bit). Sweet Spot für Consumer-Hardware. Die meisten Nutzer bemerken keinen Qualitätsunterschied.',
    vizInt2Explain: 'Extreme Kompression (2 Bit). Signifikanter Qualitätsverlust. Nur für extreme Speicherbeschränkungen.',

    // Quantization Levels
    levelsTitle: 'Quantisierungsstufen erklärt',
    levelsDesc: 'Jede Präzisionsstufe repräsentiert einen unterschiedlichen Kompromiss zwischen Modellgröße und Ausgabequalität.',
    levelBits: 'Bits',
    levelSize: 'Größe',
    levelAccuracy: 'Genauigkeit',
    levelUseCase: 'Anwendungsfall',
    levelFp32: 'FP32 (Voll)',
    levelFp32Size: '100%',
    levelFp32Accuracy: '100%',
    levelFp32Use: 'Training, Referenz-Inferenz',
    levelFp16: 'FP16 (Halb)',
    levelFp16Size: '50%',
    levelFp16Accuracy: '~99%',
    levelFp16Use: 'Standard-Inferenz',
    levelInt8: 'INT8',
    levelInt8Size: '25%',
    levelInt8Accuracy: '~97%',
    levelInt8Use: 'Produktions-Deployment',
    levelInt4: 'INT4',
    levelInt4Size: '12.5%',
    levelInt4Accuracy: '~90-95%',
    levelInt4Use: 'Consumer-GPUs, Edge',
    levelInt2: 'INT2',
    levelInt2Size: '6.25%',
    levelInt2Accuracy: '~70-80%',
    levelInt2Use: 'Extreme Edge-Fälle',

    // Recommendation
    recommendTitle: 'Empfehlung: Q4 ist der Sweet Spot',
    recommendDesc: 'Für die meisten Nutzer, die große Modelle (70B+ Parameter) lokal ausführen:',
    recommend1: 'Q4 (INT4) bietet ein exzellentes Qualitäts-zu-Speicher-Verhältnis',
    recommend2: 'Die meisten Nutzer können Q4-Ausgabe in Blindtests nicht von FP16 unterscheiden',
    recommend3: 'Ermöglicht die Ausführung von 70B-Modellen auf 24GB Consumer-GPUs',
    recommend4: 'Empfohlene Formate: Q4_K_M oder Q4_K_S für GGUF-Modelle',
    recommendNote: 'Für kritische Anwendungen, die maximale Genauigkeit erfordern, verwende FP16 oder INT8. Für gelegentliche Nutzung und Experimente ist Q4 ideal.',

    // Techniques
    techniquesTitle: 'Quantisierungstechniken',
    techniquesDesc: 'Verschiedene Methoden zur Konvertierung von Modellen auf niedrigere Präzision.',
    techPtq: 'PTQ (Post-Training-Quantisierung)',
    techPtqDesc: 'Quantisierung auf ein bereits trainiertes Modell anwenden. Schnell und einfach, aber möglicherweise etwas höherer Genauigkeitsverlust. Funktioniert durch Kalibrierung der Quantisierungsparameter auf einem kleinen Datensatz.',
    techQat: 'QAT (Quantization-Aware Training)',
    techQatDesc: 'Quantisierung in den Trainingsprozess einbeziehen. Das Modell lernt, robust gegenüber Präzisionsverlust zu sein, was bessere Genauigkeit ergibt, aber vollständiges Neutraining erfordert.',
    techGptq: 'GPTQ',
    techGptqDesc: 'One-Shot-Quantisierungsmethode für LLMs. Nutzt Informationen zweiter Ordnung, um den Quantisierungsfehler Schicht für Schicht zu minimieren. Beliebt für Geschwindigkeit und Qualität.',
    techAwq: 'AWQ (Activation-aware Weight Quantization)',
    techAwqDesc: 'Identifiziert und bewahrt "wichtige" Gewichte, die am meisten für die Genauigkeit zählen. Erreicht bessere Qualität als naive Quantisierung durch Schutz wichtiger Parameter.',
    techGguf: 'GGUF-Format',
    techGgufDesc: 'Dateiformat, das von llama.cpp für quantisierte Modelle verwendet wird. Unterstützt verschiedene Quantisierungsstufen (Q2-Q8) und ist der Standard für lokales LLM-Deployment.',

    // GGUF K-quants
    ggufTitle: 'GGUF K-Quant-Methoden',
    ggufDesc: 'Verständnis der Namenskonvention für GGUF-quantisierte Modelle.',
    ggufMethod: 'Methode',
    ggufQuality: 'Qualität',
    ggufSize: 'Größe',
    ggufUseCase: 'Anwendungsfall',
    ggufQ2K: 'Q2_K',
    ggufQ2KQuality: 'Schlecht',
    ggufQ2KSize: 'Kleinste',
    ggufQ2KUse: 'Nur extreme Kompression',
    ggufQ3KS: 'Q3_K_S',
    ggufQ3KSQuality: 'Niedrig',
    ggufQ3KSSize: 'Sehr klein',
    ggufQ3KSUse: 'Speicherbeschränkte Systeme',
    ggufQ3KM: 'Q3_K_M',
    ggufQ3KMQuality: 'Niedrig-Mittel',
    ggufQ3KMSize: 'Klein',
    ggufQ3KMUse: 'Budget-Hardware',
    ggufQ3KL: 'Q3_K_L',
    ggufQ3KLQuality: 'Mittel',
    ggufQ3KLSize: 'Moderat',
    ggufQ3KLUse: 'Bessere Q3-Qualität',
    ggufQ4KS: 'Q4_K_S',
    ggufQ4KSQuality: 'Gut',
    ggufQ4KSSize: 'Klein',
    ggufQ4KSUse: 'Empfohlene Balance',
    ggufQ4KM: 'Q4_K_M',
    ggufQ4KMQuality: 'Sehr gut',
    ggufQ4KMSize: 'Moderat',
    ggufQ4KMUse: 'Beste Gesamtwahl',
    ggufQ5KS: 'Q5_K_S',
    ggufQ5KSQuality: 'Exzellent',
    ggufQ5KSSize: 'Größer',
    ggufQ5KSUse: 'Qualitätsorientiert',
    ggufQ5KM: 'Q5_K_M',
    ggufQ5KMQuality: 'Exzellent',
    ggufQ5KMSize: 'Größer',
    ggufQ5KMUse: 'Nahe FP16-Qualität',
    ggufQ6K: 'Q6_K',
    ggufQ6KQuality: 'Nahezu perfekt',
    ggufQ6KSize: 'Groß',
    ggufQ6KUse: 'Minimaler Verlust',
    ggufQ8: 'Q8_0',
    ggufQ8Quality: 'Exzellent',
    ggufQ8Size: 'Groß',
    ggufQ8Use: 'Referenzqualität',
    ggufExplainTitle: 'K-Quant-Benennung erklärt',
    ggufExplainK: 'K = "K-quant" — verwendet wichtigkeitsbasierte Quantisierung, die die Präzision pro Schicht variiert',
    ggufExplainS: 'S (Small) = Aggressivere Quantisierung bei Attention-Schichten, kleinere Dateien',
    ggufExplainM: 'M (Medium) = Ausgewogene Quantisierung über alle Schichten, bestes Qualitäts-/Größenverhältnis',
    ggufExplainL: 'L (Large) = Weniger Quantisierung bei wichtigen Schichten, bessere Qualität',
    ggufKeyInsight: 'Wichtige Erkenntnis: K-Quants sind "gemischte Präzision" – sie quantisieren verschiedene Schichten unterschiedlich basierend auf ihrer Wichtigkeit für die Modellqualität. Attention-Schichten verwenden typischerweise höhere Präzision als Feed-Forward-Schichten.',

    // Real-World Impact
    impactTitle: 'Praxisauswirkungen',
    impactDesc: 'Konkrete Beispiele, was Quantisierung ermöglicht.',
    impactExample1Title: 'Llama 3.1 70B bei verschiedenen Quants',
    impactExample1Desc: 'Ein 70B-Parameter-Modell benötigt ~140GB bei FP16. Mit Quantisierung:',
    impactExample1Q8: 'Q8: ~70GB — Passt auf 2x A100 40GB oder 1x H100',
    impactExample1Q4: 'Q4_K_M: ~40GB — Passt auf 2x RTX 4090 oder 1x A100 80GB',
    impactExample1Q3: 'Q3_K_M: ~30GB — Passt auf einzelne RTX 4090 (24GB + etwas Offload)',
    impactExample2Title: 'Qualitätsvergleich',
    impactExample2Desc: 'In Blindtests beim Vergleich von Q4_K_M mit FP16-Ausgaben:',
    impactExample2Stat1: '85% der Nutzer konnten nicht identifizieren, welche quantisiert war',
    impactExample2Stat2: 'Perplexitätsanstieg von nur 0,1-0,5 Punkten auf gängigen Benchmarks',
    impactExample2Stat3: 'Code-Completion und Reasoning-Aufgaben zeigen minimale Verschlechterung',
    impactExample3Title: 'Kosteneinsparungen',
    impactExample3Desc: 'Ausführen eines 70B-Modells für Inferenz:',
    impactExample3Fp16: 'FP16: ~4-8€/Stunde in der Cloud (2x A100)',
    impactExample3Q4: 'Q4: ~1-2€/Stunde (einzelne A100 oder High-End Consumer-GPU)',
    impactExample3Local: 'Lokal: Einmalige Kosten einer Consumer-GPU vs. laufende Cloud-Gebühren',

    // Key Takeaways
    keyTakeaways: 'Wichtige Erkenntnisse',
    takeaway1: 'Quantisierung reduziert den Modellspeicher um das 2-16-fache mit überraschend geringem Genauigkeitsverlust',
    takeaway2: 'Q4 (INT4) ist der Sweet Spot für die meisten lokalen LLM-Anwendungsfälle – exzellente Qualität bei 1/8 des Speichers',
    takeaway3: 'K-Quant-Methoden (Q4_K_M, Q5_K_S) sind "gemischte Präzision" und übertreffen gleichmäßige Quantisierung',
    takeaway4: 'GPTQ und AWQ sind die führenden Techniken für LLM-Quantisierung, mit GGUF als Standardformat',
    takeaway5: 'Quantisierung demokratisiert KI, indem sie Frontier-Modelle auf Consumer-Hardware ermöglicht',
    takeaway6: 'Für kritische Anwendungen höhere Präzision (INT8/FP16) bevorzugen; für Experimente ist Q4 ideal',
  },

  // Nested Learning page
  nestedLearning: {
    title: 'Verschachteltes Lernen',
    description: 'Ein neues Paradigma, das ML-Modelle als verbundene Optimierungsprobleme behandelt und kontinuierliches Lernen ohne katastrophales Vergessen ermöglicht.',

    // Research disclaimer
    researchDisclaimer: 'Forschungsvorschau',
    researchDisclaimerDesc: 'Verschachteltes Lernen wurde auf der NeurIPS 2025 von Google Research vorgestellt. Dies ist Spitzenforschung, die noch nicht breit in Produktionssystemen eingesetzt wird.',

    // What is Nested Learning
    whatIs: 'Was ist Verschachteltes Lernen?',
    whatIsDesc: 'Verschachteltes Lernen ist ein neues Paradigma, das maschinelle Lernmodelle nicht als einen kontinuierlichen Lernprozess betrachtet, sondern als ein System von verbundenen, mehrstufigen Optimierungsproblemen, die gleichzeitig mit unterschiedlichen Geschwindigkeiten optimiert werden.',
    whatIsDesc2: 'Die zentrale Erkenntnis ist, dass die Architektur eines Modells (Schichten, Module) und sein Optimierungsverfahren (der Lernalgorithmus) nicht getrennte Belange sein müssen – sie können als verschiedene Ebenen eines einheitlichen Lernsystems betrachtet werden.',

    // The Problem
    problemTitle: 'Das Problem: Katastrophales Vergessen',
    problemDesc: 'Aktuelle LLMs haben eine fundamentale Einschränkung: Sie können nach dem Training nicht wirklich "lernen". Wenn man versucht, einem Modell neue Informationen beizubringen, vergisst es tendenziell das zuvor Gelernte – ein Phänomen namens katastrophales Vergessen.',
    problemExample1: 'Training auf Aufgabe B verschlechtert die Leistung bei Aufgabe A',
    problemExample2: 'Fine-Tuning "zerstört" oft allgemeine Fähigkeiten',
    problemExample3: 'Wissen ist zum Zeitpunkt des Pre-Trainings eingefroren',

    // Core Insight
    insightTitle: 'Kernerkenntnis: Architektur = Optimierung',
    insightDesc: 'Traditionelles Deep Learning behandelt Modellarchitektur und Lernalgorithmus als getrennt. Verschachteltes Lernen vereint sie:',
    insightPoint1: 'Jede "Schicht" ist selbst ein Lernproblem mit eigenem Kontext und eigener Aktualisierungsregel',
    insightPoint2: 'Verschiedene Komponenten werden mit unterschiedlichen Zeitskalen aktualisiert (wie biologische Gehirne)',
    insightPoint3: 'Die Hierarchie der Aktualisierungsfrequenzen erzeugt "Ebenen" des Lernens',

    // Nested Structure
    structureTitle: 'Die verschachtelte Struktur',
    outerLoop: 'Äußere Schleife',
    outerLoopDesc: 'Langsame Aktualisierungen — konsolidiert Langzeitwissen',
    middleLoop: 'Mittlere Schleife',
    middleLoopDesc: 'Mittlere Aktualisierungen — lernt wiederkehrende Muster',
    innerLoop: 'Innere Schleife',
    innerLoopDesc: 'Schnelle Aktualisierungen — passt sich an unmittelbaren Kontext an',
    structureExplain: 'Durch die Trennung des Lernens in mehrere Zeitskalen kann sich jede Ebene auf verschiedene Aspekte der Aufgabe konzentrieren, ohne andere zu beeinträchtigen.',

    // Comparison
    comparisonTitle: 'Traditionell vs. Verschachteltes Lernen',
    traditionalTitle: 'Traditionelles Lernen',
    traditionalDesc: 'Einzelne Optimierungsschleife. Lernen von Aufgabe B überschreibt Wissen von Aufgabe A. Keine Zeitskalentrennung.',
    nestedTitle: 'Verschachteltes Lernen',
    nestedDesc: 'Mehrstufige Optimierung. Jede Ebene bewahrt verschiedene Arten von Wissen. Natürliches kontinuierliches Lernen.',

    // Hope Architecture
    hopeTitle: 'Die Hope-Architektur',
    hopeDesc: 'Google Research stellte Hope vor, eine Proof-of-Concept-Architektur, die Prinzipien des verschachtelten Lernens implementiert:',
    hopeFeature1: 'Selbstmodifizierendes Lernmodul, das seine eigenen Aktualisierungsregeln lernen kann',
    hopeFeature2: 'Kontinuierliches Speichersystem (CMS) für erweiterte Kontextverarbeitung',
    hopeFeature3: 'Unbegrenztes In-Context-Lernen durch selbstreferenzielle Optimierung',
    hopeResults: 'Ergebnisse',
    hopeResult1: 'Übertrifft Transformer bei Sprachmodellierung (niedrigere Perplexität)',
    hopeResult2: 'Bessere Genauigkeit beim Common-Sense-Reasoning',
    hopeResult3: 'Überlegene Leistung bei Langkontext-Needle-In-Haystack-Aufgaben',

    // Why it matters
    mattersTitle: 'Warum das wichtig ist',
    mattersDesc: 'Wenn es sich in großem Maßstab bestätigt, könnte Verschachteltes Lernen grundlegend verändern, wie wir KI-Systeme bauen und einsetzen:',
    matter1Title: 'Kontinuierliches Lernen',
    matter1Desc: 'Modelle, die aus dem Einsatz lernen können, ohne vollständiges Neutraining',
    matter2Title: 'Effizienz',
    matter2Desc: 'Potenziell viel effizienter als aktuelle Architekturen',
    matter3Title: 'Biologische Ausrichtung',
    matter3Desc: 'Näher daran, wie biologische Gehirne tatsächlich lernen und sich erinnern',

    // Key Takeaways
    keyTakeaways: 'Wichtige Erkenntnisse',
    takeaway1: 'Verschachteltes Lernen behandelt Modelle als mehrstufige Optimierungsprobleme, nicht als einzelne kontinuierliche Prozesse',
    takeaway2: 'Es adressiert katastrophales Vergessen durch Trennung des Lernens in verschiedene Zeitskalen',
    takeaway3: 'Die Hope-Architektur zeigt vielversprechende Ergebnisse bei Sprachmodellierung und Reasoning-Aufgaben',
    takeaway4: 'Dies ist aktive Forschung (NeurIPS 2025) – noch nicht produktionsreif, aber beobachtenswert',
  },

  distillation: {
    title: 'Destillation',
    description: 'Wie kleinere Modelle von gr\u00F6\u00DFeren lernen, indem sie auf Wahrscheinlichkeitsverteilungen statt auf einzelne Tokens trainiert werden, nach dem Lehrer-Sch\u00FCler-Paradigma.',

    // What is Distillation
    whatIs: 'Was ist Wissensdestillation?',
    whatIsDesc: 'Wissensdestillation ist eine Modellkomprimierungstechnik, bei der ein kleineres \u201ESch\u00FCler\u201C-Modell trainiert wird, das Verhalten eines gr\u00F6\u00DFeren, leistungsf\u00E4higeren \u201ELehrer\u201C-Modells nachzubilden. Anstatt den Sch\u00FCler von Grund auf mit Rohdaten zu trainieren, lernt er aus den Ausgabe-Wahrscheinlichkeitsverteilungen des Lehrers \u2013 und erfasst nicht nur, was der Lehrer vorhersagt, sondern wie sicher er \u00FCber alle m\u00F6glichen Vorhersagen hinweg ist.',
    analogy: '\u201EStell dir einen Meisterkoch vor, der einem Lehrling beibringt \u2013 nicht nur die Rezepte, sondern all die subtilen Intuitionen: warum dieses Gew\u00FCrz fast passt, warum diese Technik nah dran, aber nicht ganz richtig ist.\u201C',
    analogyDesc: 'Destillation \u00FCbertr\u00E4gt diese nuancierten Einsch\u00E4tzungen, indem die vollst\u00E4ndige Wahrscheinlichkeitsverteilung geteilt wird, nicht nur die endg\u00FCltige Antwort.',

    // Teacher-Student
    teacherStudentTitle: 'Das Lehrer-Sch\u00FCler-Paradigma',
    teacherStudentDesc: 'Destillation folgt einem einfachen zweistufigen Prozess: Zuerst wird ein gro\u00DFes, leistungsf\u00E4higes Lehrer-Modell trainiert, dann werden seine Ausgaben verwendet, um einen kleineren, effizienten Sch\u00FCler zu trainieren.',
    teacherTitle: 'Lehrer-Modell',
    teacherDesc: 'Ein gro\u00DFes, hochkapazit\u00E4res Modell (z.B. GPT-4, Claude Opus), trainiert auf massiven Datens\u00E4tzen. Es hat reichhaltige Repr\u00E4sentationen und nuancierte Entscheidungsgrenzen gelernt. Seine Rolle ist es, weiche Wahrscheinlichkeitsverteilungen zu erzeugen, die sein Wissen kodieren.',
    studentTitle: 'Sch\u00FCler-Modell',
    studentDesc: 'Ein kleineres, effizienteres Modell, das f\u00FCr den Einsatz konzipiert ist. Es lernt, indem es die Wahrscheinlichkeitsverteilungen des Lehrers abgleicht, anstatt nur die Ground-Truth-Labels. Dies erm\u00F6glicht es, das \u201Edunkle Wissen\u201C des Lehrers zu erfassen \u2013 die Beziehungen zwischen Klassen, die harte Labels verwerfen.',
    flowTeacher: 'Lehrer-Modell',
    flowSoftDistribution: 'Weiche Wahrscheinlichkeitsverteilung',
    flowStudent: 'Sch\u00FCler-Modell lernt',

    // Key Insight
    keyInsightTitle: 'Die Kernidee: Verteilungen, nicht Tokens',
    keyInsightSubtitle: 'Warum Verteilungen Destillation so effektiv machen',
    keyInsightDesc: 'Der fundamentale Grund, warum Destillation so gut funktioniert, ist, dass wir auf vollst\u00E4ndige Wahrscheinlichkeitsverteilungen trainieren, nicht auf einzelne Tokens oder harte Labels. Wenn ein Lehrer-Modell \u201EDie Hauptstadt von Frankreich ist ___\u201C verarbeitet, gibt es nicht einfach \u201EParis\u201C aus \u2013 es erzeugt eine Wahrscheinlichkeitsverteilung \u00FCber sein gesamtes Vokabular.',
    keyInsightDesc2: 'Diese Verteilung enth\u00E4lt reichhaltige Informationen: \u201EParis\u201C erh\u00E4lt 92%, aber \u201ELyon\u201C erh\u00E4lt 3%, \u201EMarseille\u201C erh\u00E4lt 1,5% und \u201EBerlin\u201C erh\u00E4lt 0,8%. Diese \u201Efalschen\u201C Antworten kodieren das Verst\u00E4ndnis des Lehrers f\u00FCr Geografie, \u00C4hnlichkeit zwischen St\u00E4dten und konzeptuelle Beziehungen. Ein hartes Label von nur \u201EParis\u201C wirft all dieses Wissen weg.',

    // Hard vs Soft Labels
    hardLabelTitle: 'Harte Labels (Traditionelles Training)',
    hardLabelExample: '\u201EParis\u201C = 1,0, alles andere = 0,0',
    hardLabelExplain: 'Bin\u00E4r: entweder richtig oder falsch. Keine Nuancen. Das Modell lernt nichts \u00FCber die Beziehungen zwischen Ausgaben.',
    softLabelTitle: 'Weiche Labels (Destillation)',
    softLabelExample: '\u201EParis\u201C = 0,92, \u201ELyon\u201C = 0,03, \u201EMarseille\u201C = 0,015, \u201EBerlin\u201C = 0,008, ...',
    softLabelExplain: 'Reichhaltiges Signal: Jede Wahrscheinlichkeit kodiert eine Beziehung. Der Sch\u00FCler lernt, dass Lyon Paris \u00E4hnlicher ist als Berlin.',

    // Visualizer
    vizTitle: 'Temperatur & Verteilungsgl\u00E4ttung',
    vizToken1: 'Paris',
    vizToken2: 'Lyon',
    vizToken3: 'Mars.',
    vizToken4: 'Berlin',
    vizToken5: 'Rom',
    hardLabels: 'Harte Verteilung',
    hardLabelsDesc: 'Bei T=1 \u00FCberw\u00E4ltigt der dominante Token die anderen. Wenig Information im Schwanz.',
    softLabels: 'Weiche Verteilung',
    softLabelsDesc: 'H\u00F6here Temperatur enth\u00FCllt Beziehungen zwischen Tokens, die harte Labels verbergen.',
    distillTemp: 'Destillationstemperatur',
    tempSharp: 'scharf',
    tempSmooth: 'glatt',
    tempExplainLow: 'Niedrige Temperatur: Die Verteilung ist noch spitz. Der Sch\u00FCler lernt haupts\u00E4chlich, was die Top-Vorhersage ist.',
    tempExplainMid: 'Mittlere Temperatur: Die Verteilung ist gegl\u00E4ttet und enth\u00FCllt bedeutungsvolle Beziehungen zwischen Tokens. Dies ist der optimale Bereich f\u00FCr Destillation.',
    tempExplainHigh: 'Hohe Temperatur: Die Verteilung n\u00E4hert sich der Gleichverteilung. Zu viel Gl\u00E4ttung kann das Signal, das der Lehrer gelernt hat, auswaschen.',

    // Why it Works
    whyWorks: 'Warum Destillation funktioniert',
    whyWorksDesc: 'Destillation ist bemerkenswert effektiv, weil weiche Labels ein viel reichhaltigeres Trainingssignal liefern als harte Labels:',
    benefit1Title: 'Reichhaltigeres Gradientensignal',
    benefit1Desc: 'Jedes Trainingsbeispiel liefert Informationen \u00FCber alle Ausgabeklassen gleichzeitig, nicht nur \u00FCber die korrekte. Das bedeutet, dass jedes Beispiel dem Sch\u00FCler effektiv Tausende von Beziehungen gleichzeitig beibringt.',
    benefit2Title: '\u00DCbertragung von dunklem Wissen',
    benefit2Desc: 'Die \u201EFehler\u201C des Lehrers sind informativ. Wenn der Lehrer 3% Wahrscheinlichkeit f\u00FCr \u201ELyon\u201C bei einer Frage \u00FCber Frankreichs Hauptstadt zuweist, sagt er dem Sch\u00FCler, dass Lyon f\u00FCr Frankreich relevant ist \u2013 Wissen, das harte Labels komplett verwerfen.',
    benefit3Title: 'Bessere Generalisierung',
    benefit3Desc: 'Sch\u00FCler, die \u00FCber Destillation trainiert werden, generalisieren oft besser als Modelle, die nur auf harten Labels trainiert wurden, selbst wenn der Sch\u00FCler viel weniger Parameter hat. Die weichen Labels wirken als leistungsstarker Regularisierer.',
    benefit4Title: 'Stichprobeneffizienz',
    benefit4Desc: 'Da jedes Trainingsbeispiel mehr Information tr\u00E4gt (eine vollst\u00E4ndige Verteilung vs. ein einzelnes Label), ben\u00F6tigt der Sch\u00FCler weniger Beispiele, um effektiv zu lernen. Dies reduziert Trainingszeit und Datenanforderungen.',

    // Loss Function
    lossTitle: 'Die Destillationsverlustfunktion',
    lossDesc: 'Das Trainingsziel kombiniert zwei Verlustfunktionen: die Standard-Kreuzentropie mit Ground-Truth-Labels und die KL-Divergenz zwischen Lehrer- und Sch\u00FClerverteilungen:',
    lossCE: 'Kreuzentropie mit Ground Truth: stellt sicher, dass der Sch\u00FCler weiterhin aus echten Labels lernt',
    lossKL: 'KL-Divergenz: misst, wie unterschiedlich die Verteilung des Sch\u00FClers von der des Lehrers ist. Der Sch\u00FCler wird f\u00FCr Abweichungen von den weichen Wahrscheinlichkeiten des Lehrers bestraft.',
    lossT: 'Temperatur: steuert, wie weich/glatt die Verteilungen sind. H\u00F6here T enth\u00FCllt mehr Beziehungen zwischen Klassen.',
    lossAlpha: 'Alpha: balanciert die beiden Verlustterme. Typische Werte liegen zwischen 0,1 und 0,9, wobei h\u00F6here Werte mehr Gewicht auf die \u00DCbereinstimmung mit dem Lehrer legen.',
    lossInsight: 'Der T\u00B2-Faktor kompensiert den Skalierungseffekt der Temperatur auf Gradienten und stellt sicher, dass Destillationsverlust und Kreuzentropieverlust unabh\u00E4ngig von der Temperaturwahl ausgewogen bleiben.',

    // Types
    typesTitle: 'Arten der Destillation',
    typesDesc: 'Verschiedene Ans\u00E4tze, je nachdem welches Wissen vom Lehrer zum Sch\u00FCler \u00FCbertragen wird:',
    typeResponseTitle: 'Antwortbasiert',
    typeResponseDesc: 'Der Sch\u00FCler ahmt die endg\u00FCltige Ausgabeverteilung des Lehrers nach. Dies ist die urspr\u00FCngliche und h\u00E4ufigste Form, eingef\u00FChrt von Hinton et al. (2015). Einfach zu implementieren und effektiv f\u00FCr Klassifikation und Sprachmodellierung.',
    typeFeatureTitle: 'Merkmalsbasiert',
    typeFeatureDesc: 'Der Sch\u00FCler lernt, Zwischendarstellungen (versteckte Zust\u00E4nde) des Lehrers abzugleichen, nicht nur die Ausgabe. Erfasst tieferes strukturelles Wissen. Verwendet in Modellen wie DistilBERT und TinyBERT.',
    typeRelationTitle: 'Beziehungsbasiert',
    typeRelationDesc: '\u00DCbertr\u00E4gt die Beziehungen zwischen verschiedenen Beispielen oder Schichten, anstatt einzelne Ausgaben. Bewahrt, wie der Lehrer seine internen Repr\u00E4sentationen strukturiert und wie er verschiedene Eingaben zueinander in Beziehung setzt.',
    typeOnlineTitle: 'Online-Destillation',
    typeOnlineDesc: 'Lehrer und Sch\u00FCler trainieren gleichzeitig und lernen voneinander. Kein vortrainierter Lehrer erforderlich. N\u00FCtzlich, wenn man es sich nicht leisten kann, zuerst ein massives Lehrer-Modell zu trainieren.',

    // Examples
    examplesTitle: 'Praxisbeispiele',
    examplesDesc: 'Destillation wird umfangreich in produktiven KI-Systemen eingesetzt:',
    example1Title: 'DistilBERT (Hugging Face)',
    example1Desc: 'Eine destillierte Version von BERT, die 60% kleiner, 60% schneller ist und 97% von BERTs Sprachverst\u00E4ndnis beh\u00E4lt. Trainiert mit einer Kombination aus antwort- und merkmalsbasierter Destillation. Eines der am weitesten verbreiteten destillierten Modelle.',
    example2Title: 'OpenAI GPT-4 zu GPT-4o-mini',
    example2Desc: 'GPT-4o-mini wird weithin als destilliert aus gr\u00F6\u00DFeren GPT-4-Klasse-Modellen angesehen. Es bietet deutlich geringere Latenz und Kosten bei wettbewerbsf\u00E4higer Leistung bei den meisten Aufgaben. Dieses Muster \u2013 ein gro\u00DFes Frontier-Modell destilliert in eine kleinere, schnellere Variante \u2013 ist zur Standardpraxis geworden.',
    example3Title: 'DeepSeek R1 Destillation',
    example3Desc: 'DeepSeek ver\u00F6ffentlichte destillierte Versionen ihres R1-Reasoning-Modells in Qwen- und Llama-Basismodelle. Diese destillierten Varianten bringen fortgeschrittene Reasoning-F\u00E4higkeiten in viel kleinere, besser einsetzbare Modelle und zeigen, dass selbst komplexes Chain-of-Thought-Reasoning effektiv destilliert werden kann.',

    // Key Takeaways
    keyTakeaways: 'Wichtige Erkenntnisse',
    takeaway1: 'Wissensdestillation trainiert kleinere Modelle, gr\u00F6\u00DFere nachzubilden, indem sie aus vollst\u00E4ndigen Wahrscheinlichkeitsverteilungen lernen, nicht nur aus endg\u00FCltigen Antworten',
    takeaway2: 'Die entscheidende Erkenntnis ist, dass wir auf Verteilungen trainieren, nicht auf einzelne Tokens \u2013 weiche Labels kodieren reichhaltiges relationales Wissen (\u201Edunkles Wissen\u201C), das harte Labels komplett verwerfen',
    takeaway3: 'Temperaturgl\u00E4ttung enth\u00FCllt Beziehungen zwischen Klassen, die in der Verteilung des Lehrers verborgen sind, und macht Destillation weitaus effektiver als einfaches Label-Matching',
    takeaway4: 'Destillierte Modelle k\u00F6nnen 95-99% der Lehrerleistung bei einem Bruchteil der Gr\u00F6\u00DFe beibehalten und machen Frontier-KI-F\u00E4higkeiten f\u00FCr den realen Einsatz zug\u00E4nglich',
    takeaway5: 'Destillation ist zur Standardpraxis in der Industrie geworden \u2013 die meisten kleinen, schnellen Modelle, die man t\u00E4glich nutzt (GPT-4o-mini, DistilBERT, Gemini Flash), sind wahrscheinlich von gr\u00F6\u00DFeren Lehrern destilliert',
  },

  bias: {
    title: 'Bias & Fairness',
    description: 'Verstehen und Mindern schädlicher Biases in KI-Systemen.',
    whatIs: 'Was ist KI-Bias?',
    whatIsDesc: 'KI-Bias tritt auf, wenn maschinelle Lernsysteme systematisch unfaire Ergebnisse für bestimmte Gruppen produzieren. Biases können aus Trainingsdaten, Modelldesign oder dem Einsatzkontext entstehen.',
    sources: 'Quellen von Bias',
    sourcesDesc: 'Wo Bias in KI-Systeme eindringt.',
    dataBias: 'Trainingsdaten',
    dataBiasDesc: 'Historische Biases in den Daten werden vom Modell gelernt.',
    labelBias: 'Label-Bias',
    labelBiasDesc: 'Menschliche Annotatoren führen ihre eigenen Biases ein.',
    selectionBias: 'Selektions-Bias',
    selectionBiasDesc: 'Trainingsdaten repräsentieren nicht die Einsatzpopulation.',
    measurementBias: 'Mess-Bias',
    measurementBiasDesc: 'Proxies, die zur Messung verwendet werden, kodieren Bias.',
    types: 'Arten von Bias',
    typesDesc: 'Häufige Kategorien von Bias in KI-Systemen.',
    stereotyping: 'Stereotypisierung',
    stereotypingDesc: 'Verstärkung schädlicher Stereotypen über Gruppen.',
    erasure: 'Auslöschung',
    erasureDesc: 'Unterrepräsentation oder Ignorieren bestimmter Gruppen.',
    disparateImpact: 'Unterschiedliche Auswirkung',
    disparateImpactDesc: 'Verschiedene Ergebnisse für verschiedene Gruppen.',
    mitigation: 'Minderungsstrategien',
    mitigationDesc: 'Ansätze zur Reduzierung von Bias.',
    diverseData: 'Diverse Daten',
    diverseDataDesc: 'Sicherstellen, dass Trainingsdaten alle relevanten Gruppen repräsentieren.',
    auditing: 'Bias-Audit',
    auditingDesc: 'Systematisch auf Bias über demografische Gruppen hinweg testen.',
    constraints: 'Fairness-Einschränkungen',
    constraintsDesc: 'Fairness-Metriken in das Training einbeziehen.',
    interactiveDemo: 'Bias-Erkennungs-Demo',
    demoDesc: 'Erkunde, wie sich Bias in Modellausgaben manifestiert',
    keyTakeaways: 'Wichtige Erkenntnisse',
    takeaway1: 'Bias wird oft von Trainingsdaten geerbt',
    takeaway2: 'Verschiedene Fairness-Metriken können in Konflikt stehen – wähle sorgfältig',
    takeaway3: 'Regelmäßiges Auditing ist essentiell für eingesetzte Systeme',
    takeaway4: 'Bias-Minderung ist ein fortlaufender Prozess, keine einmalige Lösung',
  },

  responsibleAi: {
    title: 'Verantwortungsvolle KI',
    description: 'KI-Systeme ethisch und nachhaltig entwickeln und einsetzen.',
    whatIs: 'Was ist verantwortungsvolle KI?',
    whatIsDesc: 'Verantwortungsvolle KI umfasst die Praktiken, Richtlinien und Prinzipien, die sicherstellen, dass KI-Systeme ethisch, sicher und zum Nutzen der Gesellschaft entwickelt und eingesetzt werden.',
    pillars: 'Säulen verantwortungsvoller KI',
    pillarsDesc: 'Kernprinzipien, die die verantwortungsvolle KI-Entwicklung leiten.',
    transparency: 'Transparenz',
    transparencyDesc: 'Offen sein über KI-Fähigkeiten, Einschränkungen und Entscheidungsfindung.',
    accountability: 'Verantwortlichkeit',
    accountabilityDesc: 'Klare Eigentümerschaft und Verantwortung für KI-Ergebnisse.',
    privacy: 'Datenschutz',
    privacyDesc: 'Benutzerdaten schützen und Datenschutzrechte respektieren.',
    safety: 'Sicherheit',
    safetyDesc: 'Sicherstellen, dass Systeme robust sind und keinen Schaden anrichten.',
    practices: 'Verantwortungsvolle Praktiken',
    practicesDesc: 'Konkrete Schritte für verantwortungsvolle KI-Entwicklung.',
    documentation: 'Dokumentation',
    documentationDesc: 'Modellfähigkeiten, Trainingsdaten und bekannte Einschränkungen dokumentieren.',
    testing: 'Umfassende Tests',
    testingDesc: 'Vor der Bereitstellung auf Sicherheit, Bias und Randfälle testen.',
    monitoring: 'Fortlaufende Überwachung',
    monitoringDesc: 'Systemverhalten in der Produktion auf Probleme überwachen.',
    feedback: 'Benutzer-Feedback',
    feedbackDesc: 'Kanäle für Benutzer schaffen, um Probleme zu melden.',
    considerations: 'Ethische Überlegungen',
    environmental: 'Umweltauswirkungen',
    environmentalDesc: 'KI-Training hat einen erheblichen CO2-Fußabdruck.',
    labor: 'Arbeitsmarkt-Auswirkungen',
    laborDesc: 'Auswirkungen auf Arbeitnehmer und Beschäftigung berücksichtigen.',
    access: 'Gerechter Zugang',
    accessDesc: 'Sicherstellen, dass KI-Vorteile breit verteilt werden.',
    keyTakeaways: 'Wichtige Erkenntnisse',
    takeaway1: 'Verantwortungsvolle KI erfordert proaktiven Einsatz während des gesamten Lebenszyklus',
    takeaway2: 'Transparenz baut Vertrauen auf und ermöglicht Verantwortlichkeit',
    takeaway3: 'Gesellschaftliche Auswirkungen über unmittelbare Benutzer hinaus berücksichtigen',
    takeaway4: 'Ethik ist nicht optional – integriere sie in Entwicklungsprozesse',
    // Governance Frameworks
    frameworks: 'Governance-Rahmenwerke',
    frameworksDesc: 'Internationale Standards und Vorschriften bieten strukturierte Ansätze für verantwortungsvolle KI-Entwicklung und -Einsatz.',
    // NIST AI RMF
    nistTitle: 'NIST AI Risk Management Framework',
    nistDesc: 'Ein freiwilliges Rahmenwerk des U.S. National Institute of Standards and Technology zur Steuerung von KI-Risiken während des gesamten KI-Lebenszyklus.',
    nistGovern: 'Govern',
    nistGovernDesc: 'Kultur, Richtlinien, Verantwortlichkeit',
    nistMap: 'Map',
    nistMapDesc: 'Kontext und Risikoidentifikation',
    nistMeasure: 'Measure',
    nistMeasureDesc: 'Bewertung und Analyse',
    nistManage: 'Manage',
    nistManageDesc: 'Priorisieren und reagieren',
    // OECD AI Principles
    oecdTitle: 'OECD KI-Prinzipien',
    oecdDesc: 'Internationale Prinzipien, die von 46 Ländern angenommen wurden, um vertrauenswürdige KI zu fördern, die Menschenrechte und demokratische Werte respektiert.',
    oecdInclusive: 'Inklusives Wachstum',
    oecdHuman: 'Menschenzentriert',
    oecdTransparency: 'Transparenz',
    oecdRobust: 'Robustheit',
    oecdAccountability: 'Verantwortlichkeit',
    // ISO/IEC 42001
    isoTitle: 'ISO/IEC 42001',
    isoDesc: 'Der erste internationale Standard, der Anforderungen für die Einrichtung, Implementierung und Verbesserung eines KI-Managementsystems in Organisationen festlegt.',
    isoPolicy: 'KI-Richtlinie',
    isoPolicyDesc: 'Organisatorische KI-Ziele und Prinzipien festlegen',
    isoRisk: 'Risikobewertung',
    isoRiskDesc: 'KI-spezifische Risiken identifizieren und bewerten',
    isoImprovement: 'Kontinuierliche Verbesserung',
    isoImprovementDesc: 'KI-Praktiken überwachen, messen und verbessern',
    // EU AI Act
    euActTitle: 'EU AI Act',
    euActDesc: 'Die weltweit erste umfassende KI-Regulierung, die einen risikobasierten Ansatz zur Kategorisierung und Regulierung von KI-Systemen verfolgt.',
    euProhibited: 'Verboten',
    euProhibitedDesc: 'Social Scoring, manipulative KI, Echtzeit-Biometrie',
    euHighRisk: 'Hohes Risiko',
    euHighRiskDesc: 'Gesundheitswesen, Bildung, Beschäftigung, Strafverfolgung',
    euLimited: 'Begrenztes Risiko',
    euLimitedDesc: 'Chatbots, Deepfakes (Transparenz erforderlich)',
    euMinimal: 'Minimales Risiko',
    euMinimalDesc: 'Die meisten KI-Anwendungen (keine spezifischen Anforderungen)',
  },

  // European AI page
  europeanAi: {
    title: 'KI aus Europa',
    description: 'Das wachsende europäische KI-Ökosystem erkunden – Unternehmen, die souveräne, offene und datenschutzorientierte KI entwickeln.',
    intro: 'Die europäische KI-Landschaft',
    introDesc: 'Europa entwickelt sich zu einem bedeutenden Akteur im globalen KI-Wettbewerb, mit einem einzigartigen Ansatz, der Datensouveränität, Datenschutz, Open-Source-Modelle und regulatorische Konformität betont. Während US-amerikanische und chinesische Unternehmen die Schlagzeilen dominieren, haben europäische KI-Startups insgesamt über 13 Milliarden Euro an Finanzierung eingeworben und eine neue Generation von KI-Einhörnern geschaffen, die auf europäischen Werten aufbauen.',
    stat1Title: 'Gesamtfinanzierung',
    stat1Value: '€13,2 Mrd.+',
    stat1Desc: 'Von europäischen KI-Startups eingeworben',
    stat2Title: 'Führende Standorte',
    stat2Value: 'FR, DE, UK',
    stat2Desc: 'Frankreich, Deutschland und UK führen die KI-Entwicklung an',
    stat3Title: 'Regulatorischer Vorteil',
    stat3Value: 'EU AI Act',
    stat3Desc: 'Erstes umfassendes KI-Gesetz weltweit',
    keyCompanies: 'Wichtige europäische KI-Unternehmen',
    keyCompaniesDesc: 'Führende Organisationen, die die europäische KI gestalten',
    focus: 'Fokus',
    funding: 'Finanzierung',
    // Company names
    companies: {
      mistral: 'Mistral AI',
      alephAlpha: 'Aleph Alpha',
      kyutai: 'Kyutai',
      poolside: 'Poolside',
      elevenLabs: 'ElevenLabs',
      photoroom: 'Photoroom',
      lightOn: 'LightOn',
      sana: 'Sana',
      deepL: 'DeepL',
    },
    // Countries
    countries: {
      france: 'Frankreich',
      germany: 'Deutschland',
      franceParis: 'Frankreich / USA',
      ukPoland: 'UK / Polen',
      sweden: 'Schweden',
    },
    // Focus areas
    focuses: {
      mistralFocus: 'Open-Weight LLMs',
      alephAlphaFocus: 'Enterprise-KI, Souveränität',
      kyutaiFocus: 'Echtzeit-Sprach-KI',
      poolsideFocus: 'KI-gestützte Programmierung',
      elevenLabsFocus: 'Sprach-KI & Sprachsynthese',
      photoroomFocus: 'KI-Bildbearbeitung',
      lightOnFocus: 'Enterprise GenAI-Plattform',
      sanaFocus: 'Enterprise KI-Agenten',
      deepLFocus: 'KI-Übersetzung & Sprache',
    },
    // Descriptions
    descriptions: {
      mistralDesc: 'Gegründet von ehemaligen DeepMind- und Meta-Forschern, baut Mistral Open-Weight-Modelle, die mit proprietären Alternativen konkurrieren. Ihre Le Chat-App bietet ultraschnelle Inferenz mit bis zu 1.000 Wörtern/Sekunde.',
      alephAlphaDesc: 'Deutscher Pionier mit Fokus auf Enterprise-KI und starker Datensouveränität. Der einzige deutsche LLM-Anbieter mit BSI C5-Zertifizierung. Kürzlich auf ihr generatives KI-Betriebssystem Pharia umgestellt.',
      kyutaiDesc: 'Französische Non-Profit-Organisation, die Moshi entwickelt, das erste vollständig offene Echtzeit-Sprachmodell. Erreicht 160ms Latenz und nutzt ihren Mimi-Codec für 24kHz Audio bei nur 1,1 kbps.',
      poolsideDesc: 'Gegründet vom ehemaligen GitHub-CTO, entwickelt KI-Modelle speziell für Code-Generierung. Nutzt Reinforcement Learning aus Code-Ausführung für synthetische Trainingsdaten. Stark von Nvidia unterstützt.',
      elevenLabsDesc: 'Führendes Sprach-KI-Unternehmen mit hochrealistischer Sprachsynthese und Stimmenklonen. Gegründet von Ex-Google- und Ex-Palantir-Ingenieuren, jetzt mit 3,3 Milliarden Dollar bewertet.',
      photoroomDesc: 'In Paris ansässige KI-Fotobearbeitungsplattform mit Hunderten Millionen Nutzern. Macht professionelle Bildqualität ohne tiefe Designkenntnisse zugänglich.',
      lightOnDesc: 'Europas erstes börsennotiertes GenAI-Startup. Bietet On-Premises Enterprise-KI ohne Datenspeicherung. Hat ModernBERT mit über 20 Millionen Downloads entwickelt.',
      sanaDesc: 'Schwedisches Enterprise-KI-Unternehmen, das 2025 für 1,1 Mrd. Dollar von Workday übernommen wurde. Ihre Sana Agents-Plattform ermöglicht No-Code KI-Agenten-Entwicklung mit über 100 Enterprise-Konnektoren.',
      deepLDesc: 'In Köln ansässiger Pionier für neuronale maschinelle Übersetzung, gegründet 2017. Bedient über 200.000 Unternehmen in 228 Märkten mit Enterprise-Übersetzung. In Forbes AI 50 (2025) gelistet und erwägt einen $5 Mrd. Börsengang.',
    },
    // Funding
    fundings: {
      mistralFunding: '€6,2 Mrd. gesamt (inkl. ASML, Nvidia)',
      alephAlphaFunding: '500 Mio. $ (Bosch, SAP, HPE)',
      kyutaiFunding: 'Non-Profit (Xavier Niel unterstützt)',
      poolsideFunding: '2 Mrd. $ Runde bei 12 Mrd. $ Bewertung',
      elevenLabsFunding: '281 Mio. $ (a16z, Sequoia)',
      photoroomFunding: 'Series B, 65 Mio. $+',
      lightOnFunding: 'Börsennotiert (Euronext Growth)',
      sanaFunding: 'Für 1,1 Mrd. $ übernommen',
      deepLFunding: '536 Mio. $ gesamt, 2 Mrd. $ Bewertung',
    },
    // Notable
    notables: {
      mistralNotable: 'Le Chat, Mixtral, Open Weights',
      alephAlphaNotable: 'Pharia OS, BSI C5 zertifiziert',
      kyutaiNotable: 'Moshi, MoshiVis, Open Source',
      poolsideNotable: 'Project Horizon, 40K+ GPUs',
      elevenLabsNotable: 'Stimmenklonen, KI-Dubbing',
      photoroomNotable: 'Hintergrundentfernung, Produktfotos',
      lightOnNotable: 'ModernBERT, On-Prem Deployment',
      sanaNotable: 'Sana Agents, Workday-Übernahme',
      deepLNotable: 'Forbes AI 50, DeepL Agent, 1.257 Mitarbeiter',
    },
    // EU AI Act section
    euAiAct: 'Der EU AI Act Vorteil',
    euAiActDesc: 'Der EU AI Act ist der weltweit erste umfassende Rechtsrahmen für KI. Europäische Unternehmen gestalten ihre KI von Anfang an nach diesen Standards, was einen regulatorischen "Heimvorteil" schafft, während ausländische Anbieter sich anpassen müssen, um in Europa tätig zu sein.',
    advantage1Title: 'Integrierte Compliance',
    advantage1Desc: 'Europäische KI-Unternehmen entwickeln von Anfang an für DSGVO und den AI Act, was sie für datenschutzbewusste Enterprise-Kunden attraktiv macht.',
    advantage2Title: 'Datensouveränität',
    advantage2Desc: 'On-Premises-Bereitstellungsoptionen ermöglichen es, sensible Daten innerhalb organisatorischer oder nationaler Grenzen zu halten – entscheidend für Regierung und Verteidigung.',
    advantage3Title: 'Mehrsprachiger Fokus',
    advantage3Desc: 'Europäische Modelle sind von Grund auf für mehrsprachige Nutzung konzipiert und bedienen vielfältige europäische Sprachen und Märkte effektiv.',
    advantage4Title: 'Ethische KI-Führung',
    advantage4Desc: 'Europas Betonung auf verantwortungsvolle KI-Entwicklung positioniert seine Unternehmen als vertrauenswürdige Partner für Organisationen, die Ethik priorisieren.',
    // Open Source section
    openSource: 'Open Source & Open Weights',
    openSourceDesc: 'Viele europäische KI-Unternehmen setzen auf Open-Source-Prinzipien und veröffentlichen Modellgewichte und Code unter freizügigen Lizenzen. Diese Transparenz baut Vertrauen auf, ermöglicht Anpassungen und unterstützt die breitere KI-Forschungsgemeinschaft.',
    model1Desc: 'Open-Weight LLMs, die privat bereitgestellt und angepasst werden können',
    model2Desc: 'Vollständig offenes Sprachmodell mit Apache 2.0 Code und CC BY 4.0 Gewichten',
    model3Desc: 'State-of-the-Art Encoder-Modell mit über 20 Mio. Downloads',
    model4Desc: 'Lettisches 30B-Parameter Open Model, trainiert auf dem EuroHPC LUMI Supercomputer',
    // Key Takeaways
    keyTakeaways: 'Wichtige Erkenntnisse',
    takeaway1: 'Europa baut KI mit einzigartigem Fokus auf Souveränität, Datenschutz und Open-Source-Prinzipien',
    takeaway2: 'Französische Startups wie Mistral und Kyutai sind führend bei Open-Weight und Open-Source KI-Modellen',
    takeaway3: 'Der EU AI Act schafft sowohl Herausforderungen als auch Chancen – europäische Unternehmen haben einen Compliance-Vorteil',
    takeaway4: 'Während US-Unternehmen bei der Größe führen, glänzt europäische KI bei Enterprise-Vertrauen, mehrsprachiger Unterstützung und regulatorischer Ausrichtung',
  },

  // Open Source Advantages page
  openSource: {
    title: 'Open-Source-Vorteile',
    description: 'Warum Open Source in der KI wichtig ist – Transparenz, Community, Kosten, Innovationsgeschwindigkeit, Anbieterunabhängigkeit und Sicherheit durch Auditing.',

    // Introduction
    intro: 'Warum Open Source in der KI wichtig ist',
    introDesc: 'Open-Source-KI hat grundlegend verändert, wie künstliche Intelligenz entwickelt, eingesetzt und verbessert wird. Von grundlegenden Modellen wie LLaMA bis hin zu spezialisierten Tools wie Hugging Face Transformers hat die Open-Source-Bewegung den Zugang zu modernster KI-Technologie demokratisiert und ein lebendiges Ökosystem der Innovation geschaffen.',

    // Key Advantages Section
    advantagesTitle: 'Wichtige Vorteile von Open-Source-KI',
    advantagesDesc: 'Open-Source-KI bietet einzigartige Vorteile, die geschlossene, proprietäre Systeme nicht bieten können.',

    advantage1Title: 'Transparenz',
    advantage1Desc: 'Vollständige Einsicht in Modellarchitektur, Trainingsdaten und Gewichte. Sie können prüfen, wie Entscheidungen getroffen werden, und Sicherheitseigenschaften verifizieren.',

    advantage2Title: 'Community-Innovation',
    advantage2Desc: 'Tausende von Mitwirkenden verbessern Modelle, beheben Fehler und erstellen Derivate. Die kollektive Intelligenz der Community beschleunigt den Fortschritt.',

    advantage3Title: 'Kosteneffizienz',
    advantage3Desc: 'Keine Lizenzgebühren oder API-Kosten pro Token. Betreiben Sie Modelle auf Ihrer eigenen Infrastruktur mit vorhersehbaren, kontrollierbaren Ausgaben.',

    advantage4Title: 'Innovationsgeschwindigkeit',
    advantage4Desc: 'Offene Modelle können schnell feingetunt, zusammengeführt und angepasst werden. Neue Techniken verbreiten sich in der Community in Tagen, nicht Monaten.',

    advantage5Title: 'Anbieterunabhängigkeit',
    advantage5Desc: 'Keine Bindung an bestimmte Anbieter. Wechseln Sie frei zwischen Modellen, Hosting-Optionen oder kombinieren Sie mehrere Modelle.',

    advantage6Title: 'Sicherheit durch Auditing',
    advantage6Desc: 'Tausende Augen überprüfen den Code. Schwachstellen werden schneller gefunden und behoben als in geschlossenen Systemen.',

    // Notable Projects Section
    projectsTitle: 'Bedeutende Open-Source-KI-Projekte',
    projectsDesc: 'Schlüsselprojekte, die die Open-Source-KI-Revolution 2025 vorantreiben',

    project1Name: 'DeepSeek R1',
    project1Org: 'DeepSeek',
    project1Desc: 'Chinesisches Reasoning-Modell mit GPT-4-Leistung zu einem Bruchteil der Kosten. Für unter 6 Mio. $ trainiert, zeigt effiziente Skalierung.',

    project2Name: 'Qwen-Serie',
    project2Org: 'Alibaba',
    project2Desc: 'Jetzt die meistgeladenen offenen Modelle weltweit. Qwen2.5 bietet Größen von 0,5B bis 72B mit starken mehrsprachigen Fähigkeiten.',

    project3Name: 'Llama 3.3 70B',
    project3Org: 'Meta',
    project3Desc: 'Metas neueste Veröffentlichung, die GPT-4 bei vielen Benchmarks erreicht. Setzt das LLaMA-Erbe mit verbessertem Reasoning und Coding fort.',

    project4Name: 'Mistral / Mixtral',
    project4Org: 'Mistral AI',
    project4Desc: 'Europäische Open-Weight-Modelle, bekannt für Effizienz. Mixtral war Pionier der offenen Mixture-of-Experts-Architektur.',

    project5Name: 'Hugging Face Transformers',
    project5Org: 'Hugging Face',
    project5Desc: 'Die De-facto-Bibliothek für die Arbeit mit Transformer-Modellen. Hostet über 1 Million Modelle und Datensätze.',

    project6Name: 'Ollama',
    project6Org: 'Ollama',
    project6Desc: 'Einfaches Tool zum lokalen Ausführen von LLMs. Ein-Befehl-Setup für Dutzende offene Modelle inklusive aller neuesten Releases.',

    // 2025 Trends Section
    trendsTitle: '2025 Modelllandschaft-Trends',
    trendsDesc: 'Die Open-Source-KI-Landschaft hat sich 2025 dramatisch verändert, wobei offene Modelle die Lücke zu proprietären Systemen schließen.',

    trend1Title: 'Leistungslücke schrumpft',
    trend1Desc: 'Die Lücke zwischen Open-Source- und Closed-Source-Modellen hat sich auf etwa 1,7% verringert, was offene Modelle für die meisten Produktionsfälle geeignet macht.',

    trend2Title: 'Chinesische Modelle dominieren Downloads',
    trend2Desc: 'Chinesische Modelle wie Qwen und DeepSeek führen jetzt die globalen Downloads an und verschieben die Open-Source-KI-Landschaft nach Asien.',

    trend3Title: '20-32B Parameter Sweet Spot',
    trend3Desc: 'Modelle im 20-32B-Parameterbereich erweisen sich als optimal für Consumer-Hardware und balancieren Leistungsfähigkeit mit Zugänglichkeit.',

    trend4Title: 'Small Language Models (SLMs)',
    trend4Desc: 'Sub-3B-Parametermodelle, optimiert für Edge-Geräte und Smartphones, ermöglichen On-Device-KI ohne Cloud-Abhängigkeiten.',

    // Business Perspective Section
    businessTitle: 'Wann Open Source wählen',
    businessDesc: 'Strategische Überlegungen für Organisationen, die Open-Source-KI bewerten',

    businessCase1Title: 'Datensouveränität',
    businessCase1Desc: 'Wenn Daten aufgrund von Vorschriften, Datenschutz oder Wettbewerbsbedenken Ihre Infrastruktur nicht verlassen dürfen.',

    businessCase2Title: 'Anpassungsbedarf',
    businessCase2Desc: 'Wenn Sie Modelle mit proprietären Daten feintunen oder für spezialisierte Bereiche anpassen müssen.',

    businessCase3Title: 'Kosten bei Skalierung',
    businessCase3Desc: 'Wenn API-Kosten die Selbst-Hosting-Kosten übersteigen würden, typischerweise bei hohem Nutzungsvolumen.',

    businessCase4Title: 'Offline- oder Edge-Deployment',
    businessCase4Desc: 'Wenn Modelle ohne Internetverbindung oder auf Edge-Geräten laufen müssen.',

    // Considerations
    considerTitle: 'Zu beachten',
    consider1: 'Selbst-Hosting erfordert Infrastruktur-Expertise und Rechenressourcen',
    consider2: 'Offene Modelle können bei rohen Fähigkeiten hinter proprietären Modellen zurückbleiben',
    consider3: 'Support kommt von der Community statt von Anbieterverträgen',
    consider4: 'Feintuning erfordert ML-Expertise und qualitativ hochwertige Trainingsdaten',

    // Key Takeaways
    keyTakeaways: 'Wichtige Erkenntnisse',
    takeaway1: 'Open-Source-KI bietet Transparenz, Anpassung und Freiheit von Anbieterbindung',
    takeaway2: 'Das Community-getriebene Modell beschleunigt Innovation durch Zusammenarbeit und schnelle Iteration',
    takeaway3: 'Für Organisationen mit Datensouveränitätsanforderungen kann Open Source die einzige praktikable Option sein',
    takeaway4: 'Die Lücke zwischen Open-Source- und Closed-Source-Modellen verringert sich weiter, während das Ökosystem reift',
    takeaway5: 'Die Wahl zwischen Open und Closed Source hängt von Ihren spezifischen Bedürfnissen nach Kontrolle, Fähigkeit und Ressourcen ab',
  },

  // Visual Challenges page (expanded)
  visualChallenges: {
    title: 'Visuelle Herausforderungen',
    description: 'Häufige Herausforderungen und Einschränkungen bei der Arbeit mit bildverarbeitungsfähigen KI-Modellen.',
    overview: 'Häufige visuelle Herausforderungen',
    overviewDesc: 'Obwohl Bildmodelle beeindruckend sind, stehen sie vor mehreren systematischen Herausforderungen, die beim Erstellen von Anwendungen wichtig zu verstehen sind. Diese Einschränkungen entstehen dadurch, wie Bildmodelle Bilder verarbeiten – durch Patches, Einbettungen und Aufmerksamkeit – und nicht so, wie Menschen visuelle Informationen wahrnehmen.',

    // Challenge 1: Counting
    challenge1: 'Objekte zählen',
    challenge1Desc: 'Modelle haben oft Schwierigkeiten, Objekte in Bildern genau zu zählen, besonders wenn es viele ähnliche Elemente gibt.',
    challenge1Why: 'Warum das passiert',
    challenge1WhyDesc: 'Bildmodelle verarbeiten Bilder als Patches (typischerweise 14x14 oder 16x16 Pixel), nicht als diskrete Objekte. Ihnen fehlt das eingebaute Konzept der "Objektpermanenz" und sie haben Schwierigkeiten, genaue Zählungen über überlappende oder dichte Anordnungen aufrechtzuerhalten.',
    challenge1Examples: 'Häufige Fehler',
    challenge1Example1: 'Menschen in einer Menge zählen (oft 20-50% daneben)',
    challenge1Example2: 'Elemente in einem Raster oder Array zählen',
    challenge1Example3: 'Zwischen "wenig" und "viele" unterscheiden, wenn Elemente überlappen',
    challenge1Mitigation: 'Workarounds',
    challenge1MitigationDesc: 'Für kritische Zählaufgaben erwäge spezialisierte Objekterkennungsmodelle (YOLO, Faster R-CNN) oder bitte das Modell, jeden Gegenstand einzeln zu identifizieren und zu beschreiben, anstatt eine Gesamtzahl anzugeben.',

    // Challenge 2: Spatial Reasoning
    challenge2: 'Räumliches Denken',
    challenge2Desc: 'Das Verstehen präziser räumlicher Beziehungen zwischen Objekten (links/rechts, oben/unten) kann unzuverlässig sein.',
    challenge2Why: 'Warum das passiert',
    challenge2WhyDesc: 'Positionsinformationen werden durch Patch-Positionseinbettungen kodiert, aber diese bieten keine Pixel-genaue Präzision. Das Modell lernt statistische Korrelationen zwischen Positionen statt explizites räumliches Denken.',
    challenge2Examples: 'Häufige Fehler',
    challenge2Example1: 'Links/Rechts-Beziehungen in gespiegelten oder symmetrischen Bildern verwechseln',
    challenge2Example2: 'Relative Entfernungen falsch einschätzen ("näher an" oder "weiter von")',
    challenge2Example3: 'Schwierigkeiten mit gedrehten oder ungewöhnlichen Orientierungen',
    challenge2Mitigation: 'Workarounds',
    challenge2MitigationDesc: 'Sei explizit in deinen Prompts, welchen Bezugsrahmen du verwendest. Erwäge, Bilder mit visuellen Markern oder Rastern für kritische räumliche Aufgaben zu annotieren.',

    // Challenge 3: Small Text Recognition
    challenge3: 'Kleine Texterkennung',
    challenge3Desc: 'Feiner Text in Bildern kann falsch gelesen oder ganz übersehen werden, besonders bei niedrigen Auflösungen.',
    challenge3Why: 'Warum das passiert',
    challenge3WhyDesc: 'Text kleiner als die Patch-Größe (14-16 Pixel) wird in eine einzelne Einbettung komprimiert, wobei Details auf Zeichenebene verloren gehen. OCR ist nicht in Bild-LLMs eingebaut – sie lernen Texterkennung als Nebenprodukt des Trainings, nicht als dedizierte Fähigkeit.',
    challenge3Examples: 'Häufige Fehler',
    challenge3Example1: 'Nummernschilder, Straßenschilder oder kleine Etiketten falsch lesen',
    challenge3Example2: 'Ähnliche Zeichen verwechseln (0/O, 1/l/I, 5/S)',
    challenge3Example3: 'Text in geschäftigen oder kontrastarmen Hintergründen übersehen',
    challenge3Mitigation: 'Workarounds',
    challenge3MitigationDesc: 'Verwende hochauflösende Bilder und zoome in Textbereiche. Für kritische OCR-Aufgaben verwende dedizierte OCR-Tools (Tesseract, Google Vision API, Amazon Textract) neben oder anstelle von Bild-LLMs.',

    // Challenge 4: Hallucination
    challenge4: 'Visuelle Halluzination',
    challenge4Desc: 'Modelle können Objekte oder Details beschreiben, die nicht wirklich im Bild vorhanden sind.',
    challenge4Why: 'Warum das passiert',
    challenge4WhyDesc: 'Bild-LLMs sind darauf trainiert, plausible Beschreibungen zu generieren. Wenn Bildmerkmale mehrdeutig sind, füllt das Modell Lücken mit statistisch wahrscheinlichem Inhalt – auch wenn dieser Inhalt nicht im Bild ist. Dies ist derselbe Mechanismus, der Text-Halluzinationen verursacht.',
    challenge4Examples: 'Häufige Fehler',
    challenge4Example1: 'Objekte hinzufügen, die in einer Szene "sein sollten" (eine Tastatur neben einem Monitor)',
    challenge4Example2: 'Markennamen oder Text beschreiben, der nicht sichtbar ist',
    challenge4Example3: 'Details erfinden, wenn nach unklaren Bereichen gefragt wird',
    challenge4Mitigation: 'Workarounds',
    challenge4MitigationDesc: 'Bitte das Modell, Unsicherheit auszudrücken. Verwende Prompts wie "beschreibe nur, was du klar sehen kannst" oder "wenn du X nicht bestimmen kannst, sage es". Kritische Details gegenchecken.',

    // Challenge 5: Fine Detail Recognition
    challenge5: 'Feine Detailerkennung',
    challenge5Desc: 'Subtile Details, Texturen oder kleine unterscheidende Merkmale werden oft übersehen oder falsch identifiziert.',
    challenge5Why: 'Warum das passiert',
    challenge5WhyDesc: 'Die patch-basierte Architektur mittelt Informationen innerhalb jedes Patches und verliert dabei feinkörnige Details. Hochfrequente visuelle Informationen (Kanten, Texturen, kleine Merkmale) werden komprimiert.',
    challenge5Examples: 'Häufige Fehler',
    challenge5Example1: 'Zwischen ähnlichen Objekten unterscheiden (Hunderassen, Automodelle)',
    challenge5Example2: 'Messgeräte, Zähler oder Instrumentenanzeigen ablesen',
    challenge5Example3: 'Subtile Schäden oder Defekte bei Inspektionsaufgaben identifizieren',
    challenge5Mitigation: 'Workarounds',
    challenge5MitigationDesc: 'Verwende die höchste verfügbare Auflösung. Schneide zu und fokussiere auf spezifische Interessenbereiche. Für spezialisierte Aufgaben erwäge feingetunete Modelle, die auf domänenspezifischen Daten trainiert wurden.',

    // Challenge 6: Multi-Image Reasoning
    challenge6: 'Multi-Bild-Denken',
    challenge6Desc: 'Vergleichen oder Denken über mehrere Bilder hinweg ist deutlich schwieriger als Einzelbild-Aufgaben.',
    challenge6Why: 'Warum das passiert',
    challenge6WhyDesc: 'Jedes Bild wird separat in Token-Sequenzen kodiert. Cross-Image-Aufmerksamkeit muss durch das Kontextfenster des Sprachmodells erfolgen, was weniger effizient ist als dedizierte Multi-Bild-Architekturen.',
    challenge6Examples: 'Häufige Fehler',
    challenge6Example1: 'Unterschiede zwischen zwei ähnlichen Bildern finden ("Finde den Unterschied")',
    challenge6Example2: 'Objektidentität über Frames hinweg verfolgen',
    challenge6Example3: 'Feine Details zwischen Produktbildern vergleichen',
    challenge6Mitigation: 'Workarounds',
    challenge6MitigationDesc: 'Beschreibe jedes Bild zuerst separat, dann frage nach dem Vergleich. Erwäge, Bilder zu einem einzigen Komposit für direkten Vergleich zu kombinieren.',

    keyTakeaways: 'Wichtige Erkenntnisse',
    takeaway1: 'Bild-LLMs verarbeiten Bilder als Patches – Details unter der Patch-Auflösung gehen verloren',
    takeaway2: 'Zählen und räumliches Denken sind fundamentale Schwächen, keine Randfälle',
    takeaway3: 'Visuelle Halluzination folgt demselben Muster wie Text-Halluzination – plausible Erfindung',
    takeaway4: 'Verwende höhere Auflösung, zugeschnittene Bereiche und explizite Prompts, um die Genauigkeit zu verbessern',
    takeaway5: 'Für kritische Aufgaben kombiniere Bild-LLMs mit spezialisierten Tools (OCR, Objekterkennung)',
    takeaway6: 'Verifiziere wichtige visuelle Informationen immer auf anderen Wegen',
  },

  // Agentic Vision Seite
  agenticVision: {
    title: 'Agentische Vision',
    description: 'Wie KI-Modelle passives Betrachten von Bildern durch Code-Ausführung und iteratives Reasoning in aktive visuelle Untersuchung verwandeln.',
    whatIs: 'Was ist Agentische Vision?',
    whatIsDesc: 'Agentische Vision verwandelt Bildverständnis von einem statischen, einmaligen Prozess in eine aktive Untersuchung. Anstatt einfach zu beschreiben, was es sieht, formuliert das Modell Pläne zum Heranzoomen, Inspizieren, Manipulieren und schrittweisen Analysieren von Bildern—und begründet Antworten mit visuellen Beweisen, die durch Code-Ausführung gesammelt werden.',

    // Die Schleife
    loopTitle: 'Die Denken-Handeln-Beobachten-Schleife',
    loopDesc: 'Im Kern der agentischen Vision steht ein rigoroser iterativer Prozess, der widerspiegelt, wie Menschen komplexe visuelle Informationen untersuchen.',
    thinkTitle: 'Denken',
    thinkDesc: 'Das Modell analysiert die Anfrage des Nutzers und das ursprüngliche Bild und formuliert dann einen mehrstufigen Plan, wie die benötigten Informationen extrahiert werden können.',
    actTitle: 'Handeln',
    actDesc: 'Das Modell generiert und führt Python-Code aus, um das Bild zu manipulieren oder zu analysieren—Interessenbereiche zuschneiden, Berechnungen durchführen, Objekte zählen oder Anmerkungen zeichnen.',
    observeTitle: 'Beobachten',
    observeDesc: 'Das transformierte Bild wird dem Kontextfenster des Modells hinzugefügt, sodass es die Ergebnisse inspizieren kann, bevor es über die nächste Aktion entscheidet oder eine endgültige Antwort liefert.',

    // Fähigkeiten
    capabilitiesTitle: 'Kernfähigkeiten',
    capabilitiesDesc: 'Agentische Vision ermöglicht mehrere leistungsstarke Fähigkeiten, die passive Bildmodelle nicht erreichen können.',
    capability1Title: 'Zoomen & Inspizieren',
    capability1Desc: 'Das Modell erkennt, wenn Details zu klein zum Lesen sind (wie eine entfernte Anzeige oder Seriennummer) und schreibt Code, um den Bereich zuzuschneiden und in höherer Auflösung erneut zu untersuchen.',
    capability2Title: 'Visuelle Mathematik',
    capability2Desc: 'Führe mehrstufige Berechnungen mit Code durch—Summen von Positionen auf einer Quittung, Winkelmessung in einem Diagramm oder Diagramme aus extrahierten Daten generieren.',
    capability3Title: 'Bildannotation',
    capability3Desc: 'Zeichne Pfeile, Begrenzungsrahmen oder andere Anmerkungen direkt auf Bilder, um räumliche Fragen wie "Wohin soll dieses Element?" zu beantworten.',
    capability4Title: 'Iterative Verfeinerung',
    capability4Desc: 'Wenn der erste Ansatz keine klaren Ergebnisse liefert, kann das Modell alternative Strategien ausprobieren—verschiedene Zuschnittbereiche, Bildverbesserung oder mehrere Zählmethoden.',

    // Funktionsweise
    howItWorks: 'Funktionsweise',
    howItWorksDesc: 'Wenn du einem agentischen Bildmodell eine Frage zu einem Bild stellst, schaut es nicht einfach und antwortet. Es überlegt, welche Operationen helfen würden, die Frage zu beantworten, führt Code aus, um diese Operationen durchzuführen, und nutzt die Ergebnisse für seine Antwort.',
    step1: 'Anfrage erhalten',
    step1Desc: 'Nutzer stellt eine Frage zu einem Bild, die detaillierte Analyse erfordert.',
    step2: 'Operationen planen',
    step2Desc: 'Modell bestimmt, welche visuellen Operationen (Zuschneiden, Zoomen, Annotieren) helfen würden, die Frage zu beantworten.',
    step3: 'Code ausführen',
    step3Desc: 'Python-Code wird generiert und ausgeführt, um das Bild wie geplant zu manipulieren.',
    step4: 'Ergebnisse analysieren',
    step4Desc: 'Das modifizierte Bild wird dem Modell zur Inspektion zurückgegeben.',
    step5: 'Iterieren oder Antworten',
    step5Desc: 'Modell führt entweder weitere Operationen durch oder liefert die endgültige Antwort mit Belegen.',

    // Beispiel
    exampleTitle: 'Beispiel: Lesen einer entfernten Seriennummer',
    exampleDesc: 'Stell dir vor, du fragst "Was ist die Seriennummer auf dem Gerät in der Ecke des Fotos?"',
    exampleStep1: 'Modell identifiziert, dass sich das Gerät in der unteren rechten Ecke befindet',
    exampleStep2: 'Generiert Code, um diesen Bereich zuzuschneiden und 4x zu vergrößern',
    exampleStep3: 'Inspiziert das gezoomte Bild und identifiziert den Seriennummerntext',
    exampleStep4: 'Gibt die Seriennummer mit Konfidenz zurück und notiert den verwendeten Zuschnitt',

    // Modelle
    modelsTitle: 'Modelle mit Agentischer Vision',
    modelsDesc: 'Mehrere Spitzenmodelle unterstützen jetzt agentische Bildverarbeitungsfähigkeiten.',
    model1: 'Google Gemini 3 Flash',
    model1Desc: 'Erstes großes Modell, das "Agentic Vision" als benanntes Feature einführt und visuelles Reasoning mit Code-Ausführung kombiniert. Zeigt 5-10% Qualitätsverbesserung bei Bild-Benchmarks, wenn Code-Ausführung aktiviert ist.',
    model2: 'NVIDIA Cosmos Reason',
    model2Desc: 'Ein 7B-Parameter-Reasoning-VLM für physische KI-Anwendungen. Kann reale Umgebungen unter Verwendung von Vorwissen und Physikverständnis verstehen und darin agieren.',
    model3: 'OpenAI Computer-Using Agent',
    model3Desc: 'Kombiniert große Reasoning-Modelle mit verstärkungslernbasierter UI-Interaktion und ermöglicht pixelgenaues Zeigen auf Objekte und UI-Elemente.',

    // Anwendungen
    applicationsTitle: 'Praxisanwendungen',
    applicationsDesc: 'Agentische Vision wird bereits in Produktionssystemen eingesetzt.',
    app1Title: 'Dokumentenverarbeitung',
    app1Desc: 'Automatisches Heranzoomen an Tabellen, Diagramme und Kleingedrucktes, um genaue Daten aus komplexen Dokumenten zu extrahieren.',
    app2Title: 'Qualitätsprüfung',
    app2Desc: 'Erkennung von Defekten durch systematische Inspektion verschiedener Bereiche von Produktbildern in hoher Auflösung.',
    app3Title: 'Räumliches Reasoning',
    app3Desc: 'Beantworte "Wohin soll das?"-Fragen durch Annotieren von Bildern mit Pfeilen und Platzierungshinweisen.',
    app4Title: 'Quittungsanalyse',
    app4Desc: 'Extrahiere Positionen, berechne Summen und verifiziere Mathematik durch Kombination von OCR mit codebasierter Berechnung.',

    // Vergleich
    comparisonTitle: 'Passive vs Agentische Vision',
    comparisonDesc: 'Verständnis des grundlegenden Unterschieds im Ansatz.',
    passiveTitle: 'Passive Vision',
    passiveDesc: 'Einzelner Durchlauf durch das Modell. Was du siehst, ist was du bekommst. Begrenzt durch anfängliche Bildauflösung und Modell-Aufmerksamkeit.',
    agenticTitle: 'Agentische Vision',
    agenticDesc: 'Iterative Untersuchungsschleife. Kann zoomen, zuschneiden, verbessern und erneut untersuchen. Begründet Antworten mit ausgeführtem Code und visuellen Belegen.',

    // Kernerkenntnisse
    keyTakeaways: 'Kernerkenntnisse',
    takeaway1: 'Agentische Vision behandelt Bildverständnis als aktive Untersuchung, nicht als passive Wahrnehmung',
    takeaway2: 'Die Denken-Handeln-Beobachten-Schleife ermöglicht Modellen, Bilder iterativ zu zoomen, zuzuschneiden und zu analysieren',
    takeaway3: 'Code-Ausführung bietet überprüfbares, fundiertes visuelles Reasoning',
    takeaway4: 'Aktivierung agentischer Fähigkeiten zeigt 5-10% Verbesserung bei Bild-Benchmarks',
    takeaway5: 'Dieses Paradigma überbrückt die Lücke zwischen menschlicher und KI-Untersuchung visueller Informationen',
  },

  // Multimodalität Seite
  multimodality: {
    title: 'Multimodalität',
    description: 'Wie moderne KI-Modelle mehrere Eingabetypen verarbeiten und verstehen, einschließlich Bilder, Audio, Video und Text.',
    whatIs: 'Was ist Multimodalität?',
    whatIsDesc: 'Multimodalität bezeichnet die Fähigkeit von KI-Modellen, mehrere Eingabetypen gleichzeitig zu verarbeiten und zu verstehen – Text, Bilder, Audio, Video und mehr. So wie Menschen natürlich Informationen aus verschiedenen Sinnen integrieren, um die Welt zu verstehen, kombinieren multimodale KI-Systeme verschiedene Datentypen, um ein reichhaltigeres, vollständigeres Verständnis aufzubauen.',

    // Modalitätstypen
    modalityTypes: 'Typen von Modalitäten',
    modalityTypesDesc: 'Moderne KI-Systeme können eine Vielzahl von Ein- und Ausgabemodalitäten verarbeiten, jede mit einzigartigen Eigenschaften und Herausforderungen.',
    images: 'Bilder',
    imagesDesc: 'Statische visuelle Informationen, die durch Vision Transformer verarbeitet werden. Bilder werden in Patches unterteilt, eingebettet und zusammen mit Text-Tokens für Aufgaben wie Bildbeschreibung, visuelle Q&A und Dokumentenanalyse verarbeitet.',
    audio: 'Audio',
    audioDesc: 'Klanginformationen einschließlich Sprache, Musik und Umgebungsgeräusche. Audio wird typischerweise in Spektrogramme oder Wellenformdarstellungen umgewandelt, bevor es von neuronalen Netzen für Transkription, Generierung oder Verständnis verarbeitet wird.',
    video: 'Video',
    videoDesc: 'Zeitliche Sequenzen von Bildern mit optionalen Audiospuren. Videoverständnis erfordert Reasoning über Veränderungen im Zeitverlauf, Objektverfolgung und oft Synchronisation von visuellen und akustischen Informationen.',
    other: 'Andere Modalitäten',
    otherDesc: 'Aufkommende Modalitäten umfassen 3D-Punktwolken, Sensordaten, Code, strukturierte Daten und sogar physische Aktionen in Robotikanwendungen.',
    text: 'Text',

    // Interaktive Demo
    interactiveDemo: 'Interaktive Demo',
    interactiveDemoDesc: 'Erkunde, wie verschiedene Modalitäten in multimodaler KI kombiniert werden',
    selectModalities: 'Wähle Modalitäten zum Kombinieren',
    fusionResult: 'Fusionsergebnis',
    selectToSee: 'Wähle Modalitäten, um zu sehen, wie sie kombiniert werden',
    understanding: 'Eine einzelne Modalität bietet fokussiertes, spezialisiertes Verständnis.',
    combinedUnderstanding: 'Mehrere Modalitäten ermöglichen ein reichhaltigeres, querverweisbasiertes Verständnis, das Beziehungen zwischen verschiedenen Informationstypen erfasst.',
    imageShort: 'Visuelle Muster und Objekte',
    audioShort: 'Sprache, Musik und Klänge',
    videoShort: 'Bewegung und zeitliche Muster',
    textShort: 'Sprache und Semantik',
    useCases: 'Anwendungsfälle',
    examplePrompt: 'Beispiel-Prompt:',

    // Einzelne Modalitäts-Anwendungsfälle
    useCaseImageOnly: 'Bildklassifikation & Erkennung',
    useCaseImageOnlyDesc: 'Identifiziere Objekte, Szenen, Gesichter oder spezifische Merkmale in Bildern ohne zusätzlichen Kontext.',
    useCaseImageOnlyExample: 'Welche Objekte sind auf diesem Foto?',
    useCaseAudioOnly: 'Sprachtranskription & Klanganalyse',
    useCaseAudioOnlyDesc: 'Wandle Sprache in Text um oder identifiziere Klänge, Musikgenres und Audioereignisse.',
    useCaseAudioOnlyExample: 'Transkribiere diese Audioaufnahme.',
    useCaseVideoOnly: 'Aktionserkennung & Bewegungsverfolgung',
    useCaseVideoOnlyDesc: 'Erkenne Aktivitäten, verfolge Bewegungsmuster und verstehe zeitliche Abläufe.',
    useCaseVideoOnlyExample: 'Welche Aktivitäten passieren in diesem Video?',
    useCaseTextOnly: 'Natürliches Sprachverständnis',
    useCaseTextOnlyDesc: 'Verarbeite und generiere Text für Fragen, Zusammenfassungen, Übersetzungen und Gespräche.',
    useCaseTextOnlyExample: 'Fasse diesen Artikel in drei Sätzen zusammen.',

    // Zwei-Modalitäten-Kombinationen
    useCaseImageText: 'Visuelle Q&A & Dokumentenanalyse',
    useCaseImageTextDesc: 'Stelle Fragen zu Bildern, extrahiere Text aus Dokumenten oder generiere detaillierte Bildbeschreibungen.',
    useCaseImageTextExample: 'Was ist der Gesamtbetrag auf dieser Quittung?',
    useCaseAudioText: 'Sprachassistenten & Podcast-Zusammenfassung',
    useCaseAudioTextDesc: 'Führe natürliche Sprachgespräche, transkribiere Meetings mit Zusammenfassungen oder analysiere gesprochene Inhalte.',
    useCaseAudioTextExample: 'Was sind die Hauptpunkte in dieser Podcast-Episode?',
    useCaseVideoText: 'Videobeschriftung & Inhaltssuche',
    useCaseVideoTextDesc: 'Generiere Beschreibungen von Videoinhalten, suche innerhalb von Videos nach Beschreibung oder erstelle barrierefreie Untertitel.',
    useCaseVideoTextExample: 'Beschreibe, was in diesem Kochvideo passiert.',
    useCaseImageAudio: 'Musik + Albumcover-Analyse',
    useCaseImageAudioDesc: 'Verbinde visuelle und akustische Informationen, wie die Analyse von Albumcovern zusammen mit Musik oder das Hinzufügen von Soundeffekten zu Bildern.',
    useCaseImageAudioExample: 'Passt dieses Albumcover zur Stimmung der Musik?',
    useCaseVideoAudio: 'Film- & Medienanalyse',
    useCaseVideoAudioDesc: 'Verstehe Videoinhalte mit ihrem Soundtrack, analysiere Dialog-Timing oder erkenne Audio-Video-Synchronisationsprobleme.',
    useCaseVideoAudioExample: 'Sind die Lippenbewegungen mit dem Audio synchron?',
    useCaseImageVideo: 'Visueller Vergleich über Zeit',
    useCaseImageVideoDesc: 'Vergleiche statische Referenzbilder mit Videoinhalten, erkenne Veränderungen oder überwache auf spezifische visuelle Muster.',
    useCaseImageVideoExample: 'Entspricht der im Video gezeigte Artikel diesem Produktfoto?',

    // Drei-Modalitäten-Kombinationen
    useCaseImageAudioText: 'Interaktives Lernen & Tutorials',
    useCaseImageAudioTextDesc: 'Erstelle reichhaltige Bildungserlebnisse, die visuelle Hilfsmittel, Erzählung und Texterklärungen kombinieren.',
    useCaseImageAudioTextExample: 'Erkläre dieses Diagramm, während ich beschreibe, was ich sehe.',
    useCaseVideoAudioText: 'Videoverständnis mit Dialog',
    useCaseVideoAudioTextDesc: 'Vollständige Film-/Videoanalyse einschließlich Visuelles, Dialogtranskription und Szenenbeschreibungen.',
    useCaseVideoAudioTextExample: 'Fasse dieses Interview zusammen, einschließlich wer was gesagt hat.',
    useCaseImageVideoText: 'Visueller Vergleich & Überwachung',
    useCaseImageVideoTextDesc: 'Vergleiche Referenzbilder mit Videofeeds, wie Qualitätskontrolle oder Sicherheitsüberwachung mit Textberichten.',
    useCaseImageVideoTextExample: 'Entspricht das Produkt in diesem Video den Referenzbild-Spezifikationen?',
    useCaseImageAudioVideo: 'Multimedia-Content-Produktion',
    useCaseImageAudioVideoDesc: 'Kombiniere visuelle Medien und Audio ohne explizite Textanweisungen – Analyse von Musikvideos, Synchronisation von Soundtracks mit Visuellen oder Erstellung von Multimedia-Präsentationen.',
    useCaseImageAudioVideoExample: 'Passe diese Hintergrundmusik zur Stimmung dieser Videoclips an.',

    // Alle Modalitäten
    useCaseAll: 'Vollständige Multimedia-Intelligenz',
    useCaseAllDesc: 'Verarbeite alle Eingabetypen zusammen für umfassendes Verständnis – Robotik, autonome Systeme oder immersive KI-Assistenten.',
    useCaseAllExample: 'Führe mich durch den Zusammenbau dieser Möbel mit dem Anleitungsbild, der Videodemonstration und Sprachbefehlen.',

    // Wie es funktioniert
    howWorks: 'Wie multimodale Modelle funktionieren',
    howWorksDesc: 'Multimodale Modelle verwenden spezialisierte Encoder für jede Modalität und richten diese Repräsentationen dann in einem gemeinsamen Einbettungsraum aus, in dem das Modell über Modalitäten hinweg schlussfolgern kann.',
    step1: 'Jede Modalität kodieren',
    step1Desc: 'Spezialisierte Encoder (Vision Transformer für Bilder, Audio-Encoder für Klang) wandeln jeden Eingabetyp in Einbettungsvektoren um.',
    step2: 'Im gemeinsamen Raum ausrichten',
    step2Desc: 'Diese Einbettungen werden in einen gemeinsamen Repräsentationsraum projiziert, in dem Text, Bilder und Audio verglichen und kombiniert werden können.',
    step3: 'Cross-Modales Reasoning',
    step3Desc: 'Das Modell verwendet Aufmerksamkeitsmechanismen, um Informationen über Modalitäten hinweg zu verknüpfen, was Aufgaben wie "Beschreibe, was du siehst" oder "Antworte basierend auf dem Video" ermöglicht.',

    // Audioverarbeitung
    audioProcessing: 'Audioverarbeitung',
    audioProcessingDesc: 'Audio-Modalitäten ermöglichen KI-Systemen, Sprache, Musik und andere Klänge zu verstehen und zu generieren.',
    speechRecognition: 'Spracherkennung',
    speechRecognitionDesc: 'Umwandlung gesprochener Sprache in Text. Moderne Modelle wie Whisper können in über 100 Sprachen mit hoher Genauigkeit transkribieren, auch bei Akzenten und Hintergrundgeräuschen.',
    textToSpeech: 'Text-to-Speech',
    textToSpeechDesc: 'Generierung natürlich klingender Sprache aus Text. Fortgeschrittene Modelle können Stimmen klonen, Emotionen ausdrücken und konsistente Sprechstile beibehalten.',
    musicUnderstanding: 'Musikverständnis',
    musicUnderstandingDesc: 'Analyse musikalischer Inhalte einschließlich Genre, Tempo, Instrumente und Stimmung. Einige Modelle können auch Musik aus Textbeschreibungen generieren.',
    audioGeneration: 'Audiogenerierung',
    audioGenerationDesc: 'Erstellung von Soundeffekten, Umgebungsaudio und Musik. Modelle können alles von realistischen Soundeffekten bis hin zu vollständigen Musikkompositionen generieren.',

    // Videoverständnis
    videoUnderstanding: 'Videoverständnis',
    videoUnderstandingDesc: 'Video stellt einzigartige Herausforderungen dar, da es räumliche Informationen aus Bildern mit zeitlichen Informationen über Veränderungen kombiniert.',
    temporalReasoning: 'Zeitliches Reasoning',
    temporalReasoningDesc: 'Verständnis von Ursache und Wirkung, Handlungssequenzen und Veränderungen über die Zeit. Modelle müssen Objekte verfolgen und verstehen, wie Frames zueinander in Beziehung stehen.',
    frameSampling: 'Frame-Sampling',
    frameSamplingDesc: 'Videos enthalten viel zu viele Frames, um sie vollständig zu verarbeiten. Modelle verwenden intelligente Sampling-Strategien, um Schlüsselframes auszuwählen, die wichtige Momente erfassen.',
    audioVideoSync: 'Audio-Video-Synchronisation',
    audioVideoSyncDesc: 'Ausrichtung von Audio- und visuellen Informationen, um Ereignisse wie sprechende Personen, spielende Musik oder klingende Objekte zu verstehen.',

    // Cross-Modale Fusion
    crossModal: 'Cross-Modale Fusionsstrategien',
    crossModalDesc: 'Verschiedene Architekturen zur Kombination von Informationen aus mehreren Modalitäten, jeweils mit Kompromissen zwischen Effizienz und Fähigkeit.',
    earlyFusion: 'Frühe Fusion',
    earlyFusionDesc: 'Modalitäten auf Eingabeebene vor jeder Verarbeitung kombinieren. Einfach, aber kann modalitätsspezifische Muster verlieren.',
    lateFusion: 'Späte Fusion',
    lateFusionDesc: 'Jede Modalität separat mit spezialisierten Encodern verarbeiten, dann am Ende kombinieren. Bewahrt modalitätsspezifische Merkmale.',
    crossAttention: 'Cross-Attention',
    crossAttentionDesc: 'Aufmerksamkeitsmechanismen verwenden, um jeder Modalität zu ermöglichen, selektiv auf relevante Teile anderer Modalitäten zu achten. Der flexibelste und leistungsstärkste Ansatz, verwendet in Modellen wie Gemini und GPT-4.',

    // Anwendungen
    applications: 'Reale Anwendungen',
    applicationsDesc: 'Multimodale KI ermöglicht Anwendungen, die mit Einzelmodalitätssystemen zuvor unmöglich waren.',
    app1: 'Videobeschriftung',
    app1Desc: 'Detaillierte Beschreibungen von Videoinhalten für Barrierefreiheit, Suche und Inhaltsmoderation generieren.',
    app2: 'Sprachassistenten',
    app2Desc: 'Natürliche Gespräche, die Sprache verstehen, stimmlich antworten und auf Bilder oder Bildschirme Bezug nehmen können.',
    app3: 'Medizinische Bildgebung',
    app3Desc: 'Analyse von Röntgenaufnahmen, MRTs und anderen Scans zusammen mit Patientenakten und Arztnotizen.',
    app4: 'Robotik',
    app4Desc: 'Verarbeitung von Kamerabildern, Sensordaten und Befehlen zur Navigation und Manipulation der physischen Welt.',
    app5: 'Content-Erstellung',
    app5Desc: 'Bilder aus Text generieren, Audio zu Videos hinzufügen oder multimediale Inhalte aus Beschreibungen erstellen.',
    app6: 'Barrierefreiheit',
    app6Desc: 'Bilder für Sehbehinderte beschreiben, Audio für Gehörlose transkribieren und zwischen Modalitäten übersetzen.',

    // Kernerkenntnisse
    keyTakeaways: 'Kernerkenntnisse',
    takeaway1: 'Multimodale KI kombiniert Text, Bilder, Audio und Video, um ein reichhaltigeres Verständnis der Welt aufzubauen',
    takeaway2: 'Jede Modalität erfordert spezialisierte Encoder, die Eingaben in Einbettungsvektoren umwandeln',
    takeaway3: 'Cross-Attention-Mechanismen ermöglichen Modellen, Informationen über verschiedene Modalitäten hinweg zu verknüpfen',
    takeaway4: 'Videoverständnis fügt die Zeitdimension hinzu und erfordert zeitliches Reasoning und Frame-Sampling',
    takeaway5: 'Reale Anwendungen reichen von Barrierefreiheitstools bis hin zu Robotik und Content-Erstellung',
  },

  // Agentic Vision Demo Komponente
  agenticVisionDemo: {
    title: 'Agentische Vision in Aktion',
    subtitle: 'Beobachte, wie das Modell ein Dokument zoomt, dreht und scannt',
    start: 'Demo starten',
    reset: 'Zurücksetzen',
    documentView: 'Dokumentansicht',
    agentLog: 'Agent-Protokoll',
    clickStart: 'Klicke "Demo starten", um agentische Vision in Aktion zu sehen',
    processing: 'Verarbeitung...',
    thinkMessage: 'Ich muss die Seriennummer unten rechts auf dieser Rechnung lesen. Der Text erscheint klein, also sollte ich diesen Bereich heranzoomen.',
    zoomMessage: 'Zuschneiden und Vergrößern des Seriennummernbereichs...',
    zoomObserve: 'Gezoomte Ansicht erhalten. Der Text ist jetzt größer, aber leicht gedreht.',
    rotateThink: 'Der Text ist etwa 15 Grad geneigt. Ich sollte die Drehung für bessere OCR-Genauigkeit korrigieren.',
    rotateMessage: 'Korrigiere Dokumentdrehung für optimale Texterkennung...',
    rotateObserve: 'Dokument ist jetzt korrekt ausgerichtet. Bereit zur Extraktion der Seriennummer.',
    scanMessage: 'Führe OCR auf dem ausgerichteten, gezoomten Bereich aus...',
    scanObserve: 'Seriennummer mit hoher Konfidenz extrahiert:',
    resultTitle: 'Extrahierte Seriennummer',
    resultConfidence: 'Konfidenz: 97% | Methode: Zoom + Rotation + OCR',
    stepThink: 'Denken',
    stepZoom: 'Zoom',
    stepRotate: 'Drehen',
    stepScan: 'Scannen',
    stepDone: 'Fertig',
  },

  // Visual Challenges Demo Komponente
  visualChallengesDemo: {
    title: 'VLM-Fehlermodus-Explorer',
    subtitle: 'Interaktive Szenarien, die zeigen, wo Bildmodelle Schwierigkeiten haben',

    // Tab-Namen
    countingTab: 'Zahlen',
    spatialTab: 'Raumlich',
    textTab: 'Text',
    hallucinationTab: 'Halluzination',
    detailTab: 'Details',
    multiImageTab: 'Multi-Bild',

    // UI
    imageScenario: 'Bildszenario',
    vlmResponse: 'VLM-Antwort',
    revealAnalysis: 'Analyse anzeigen',
    hideAnalysis: 'Analyse verbergen',
    vlmSaid: 'VLM sagte',
    actualAnswer: 'Tatsachliche Antwort',
    whyFails: 'Warum das fehlschlagt',
    proTip: 'Profi-Tipp',
    keyInsight: 'Wichtige Erkenntnis',
    keyInsightDesc: 'VLMs sind leistungsstark, aber nicht unfehlbar. Das Verstandnis ihrer systematischen Schwachen hilft dir, robuste Anwendungen zu entwickeln, die ihre Starken nutzen und ihre Einschrankungen abmildern.',

    // Zahlungs-Herausforderung
    countingTitle: 'Objektzahl-Herausforderung',
    countingScenario: 'Ein Foto eines Schreibtisches mit verstreuten Buroklammern. Es sind genau 23 Buroklammern sichtbar, einige uberlappen sich.',
    countingVlmResponse: '"Ich kann ungefahr 15-20 Buroklammern sehen, die uber den Schreibtisch verstreut sind."',
    countingActual: 'Es sind genau 23 Buroklammern im Bild.',
    countingWhy: 'VLMs verarbeiten Bilder als 14x14-Pixel-Patches, nicht als diskrete Objekte. Ihnen fehlt die Objektpermanenz und sie haben Schwierigkeiten mit uberlappenden Elementen. Das Modell gibt eine grobe Schatzung basierend auf Mustererkennung, nicht auf tatsachlichem Zahlen.',
    countingTip: 'Fur prazises Zahlen verwende spezialisierte Objekterkennungsmodelle (YOLO, Faster R-CNN) oder bitte das VLM, jedes Element einzeln zu identifizieren und aufzulisten, anstatt eine Gesamtzahl anzugeben.',

    // Raumliche Herausforderung
    spatialTitle: 'Raumliche Denk-Herausforderung',
    spatialScenario: 'Ein Foto, das eine rote Tasse auf der LINKEN Seite einer blauen Tasse zeigt, beide auf einem weissen Tisch.',
    spatialVlmResponse: '"Die rote Tasse befindet sich rechts von der blauen Tasse auf dem Tisch."',
    spatialActual: 'Die rote Tasse befindet sich auf der LINKEN Seite der blauen Tasse.',
    spatialWhy: 'Positionsinformationen werden durch Patch-Einbettungen ohne Pixel-genaue Prazision kodiert. Das Modell lernt statistische Korrelationen anstatt explizites raumliches Denken, was Links/Rechts-Verwechslungen haufig macht.',
    spatialTip: 'Sei explizit uber Bezugsrahmen in deinen Prompts. Erwage, visuelle Markierungen oder Rasteruberlagerungen zu Bildern hinzuzufugen, wenn raumliche Prazision kritisch ist.',

    // Text-Herausforderung
    textTitle: 'Kleine Text-Erkennungs-Herausforderung',
    textScenario: 'Ein Produktetikett mit der Seriennummer "XK7-2B9M-Q4P" in 8pt-Schrift am unteren Rand.',
    textVlmResponse: '"Die Seriennummer scheint XK7-289M-04P zu sein."',
    textActual: 'Die Seriennummer ist XK7-2B9M-Q4P (Hinweis: B statt 8, Q statt 0).',
    textWhy: 'Text kleiner als die Patch-Grosse (14-16 Pixel) wird in eine einzelne Einbettung komprimiert, wobei Details auf Zeichenebene verloren gehen. Ahnliche Zeichen (B/8, Q/0, l/1) werden leicht verwechselt.',
    textTip: 'Verwende hochauflosende Bilder und zoome in Textbereiche. Fur kritische OCR-Aufgaben verwende dedizierte OCR-Tools (Tesseract, Google Vision API) neben oder anstelle von VLMs.',

    // Halluzinations-Herausforderung
    hallucinationTitle: 'Visuelle Halluzinations-Herausforderung',
    hallucinationScenario: 'Ein Foto eines Heimburo-Schreibtisches mit einem Monitor, aber OHNE sichtbare Tastatur (sie ist in einer Schublade).',
    hallucinationVlmResponse: '"Ich kann einen Monitor auf dem Schreibtisch mit einer Tastatur davor sehen."',
    hallucinationActual: 'Es ist keine Tastatur im Bild sichtbar – das VLM hat sie halluziniert.',
    hallucinationWhy: 'VLMs generieren statistisch plausible Beschreibungen. Wenn Bildmerkmale mehrdeutig sind, fullt das Modell Lucken mit wahrscheinlichem Inhalt basierend auf Trainingsdaten – Monitore haben normalerweise Tastaturen in der Nahe.',
    hallucinationTip: 'Bitte das Modell, Unsicherheit auszudrucken und nur zu beschreiben, was es klar sehen kann. Verwende Prompts wie "wenn du X nicht bestimmen kannst, sage es" und uberprufe kritische Details immer.',

    // Detail-Herausforderung
    detailTitle: 'Feine Detail-Erkennungs-Herausforderung',
    detailScenario: 'Zwei ahnliche Hundefotos: eines ist ein Shiba Inu, das andere ein Akita. Die subtilen Unterschiede liegen in Ohrform und Korperproportionen.',
    detailVlmResponse: '"Beide Bilder zeigen Shiba-Inu-Hunde."',
    detailActual: 'Das erste ist ein Shiba Inu, das zweite ein Akita (grosserer Korper, andere Ohrform).',
    detailWhy: 'Die patch-basierte Architektur mittelt Informationen innerhalb jedes Patches und verliert dabei feinkörnige Details. Subtile Unterscheidungsmerkmale wie Ohrwinkel oder Korperproportionen werden komprimiert.',
    detailTip: 'Verwende die höchste verfügbare Auflösung und schneide zu, um sich auf unterscheidende Merkmale zu konzentrieren. Für spezialisierte Aufgaben erwäge feingetunete Modelle, die auf domänenspezifischen Daten trainiert wurden.',

    // Multi-Bild-Herausforderung
    multiImageTitle: 'Multi-Bild-Denk-Herausforderung',
    multiImageScenario: 'Zwei nahezu identische Produktfotos. Der Unterschied: In Bild 2 hat das Produkt einen kleinen Kratzer in der oberen rechten Ecke.',
    multiImageVlmResponse: '"Beide Bilder scheinen identisch zu sein. Ich sehe keine Unterschiede zwischen ihnen."',
    multiImageActual: 'Bild 2 hat einen sichtbaren Kratzer in der oberen rechten Ecke, der in Bild 1 nicht vorhanden ist.',
    multiImageWhy: 'Jedes Bild wird separat in Token-Sequenzen kodiert. Cross-Image-Aufmerksamkeit muss durch das Kontextfenster des Sprachmodells erfolgen, was weniger effizient ist als dedizierte Architekturen.',
    multiImageTip: 'Beschreibe jedes Bild zuerst separat, dann frage nach dem Vergleich. Erwage, Bilder zu einem einzigen Nebeneinander-Komposit fur direkten visuellen Vergleich zu kombinieren.',
  },

  // Skill Composer Demo
  skillComposer: {
    // Tab-Namen
    triggerTab: 'Skill-Ausloesung',
    manifestTab: 'Skill-Manifest',
    chainingTab: 'Skill-Verkettung',

    // Trigger-Tab
    userInput: 'Benutzereingabe',
    userInputDesc: 'Gib eine Nachricht ein, um zu sehen, welcher Skill ausgeloest wird',
    inputPlaceholder: 'Versuche: "Kannst du diesen Code auf Fehler ueberpruefen?"',
    tryExamples: 'Probiere diese Beispiele:',
    exampleReview: 'Ueberpruefe diesen Code auf Fehler',
    exampleDocs: 'Schreibe Dokumentation fuer diese API',
    exampleGit: 'Erstelle einen Pull Request',
    exampleExplain: 'Erklaere, wie diese Funktion funktioniert',

    // Ergebnis
    matchResult: 'Skill-Treffer',
    matchResultDesc: 'Der Skill, der ausgeloest werden wuerde',
    analyzing: 'Analysiere Eingabe...',
    confidence: 'Konfidenz',
    matchedTrigger: 'Gematchter Trigger',
    canChainWith: 'Kann verketten mit:',
    noMatch: 'Gib eine Nachricht ein, um Skill-Matching in Aktion zu sehen',

    // Skills
    codeReviewSkill: 'Code Review',
    codeReviewDesc: 'Fuehrt gruendliche Code-Reviews nach Team-Standards durch',
    documentationSkill: 'Dokumentation',
    documentationDesc: 'Erstellt umfassende Dokumentation fuer Code und APIs',
    gitWorkflowSkill: 'Git Workflow',
    gitWorkflowDesc: 'Verwaltet Git-Operationen und Pull-Request-Workflows',
    explainSkill: 'Code erklaeren',
    explainDesc: 'Erklaert Code-Funktionalitaet und Konzepte verstaendlich',

    availableSkills: 'Verfuegbare Skills',

    // Manifest-Tab
    skillManifest: 'Skill-Manifest',
    skillManifestDesc: 'Die SKILL.md-Datei definiert die Metadaten und Anweisungen eines Skills',
    manifestInstructions: 'Detaillierte Anweisungen zur Ausfuehrung dieses Skills kommen hier hin...',

    // Manifest-Felder
    nameField: 'name',
    nameFieldDesc: 'Eindeutiger Bezeichner fuer den Skill',
    triggersField: 'triggers',
    triggersFieldDesc: 'Schluesselwoerter und Phrasen, die diesen Skill aktivieren',
    descriptionField: 'description',
    descriptionFieldDesc: 'Kurze Zusammenfassung dessen, was der Skill tut',
    chainsWithField: 'chains_with',
    chainsWithFieldDesc: 'Andere Skills, die dieser Skill aufrufen kann',

    // Verkettungs-Tab
    skillChaining: 'Skill-Verkettung',
    skillChainingDesc: 'Skills koennen andere Skills aufrufen, um komplexe Aufgaben zu erledigen',
    selectToSeeChain: 'Klicke auf einen Skill, um zu sehen, womit er verkettet werden kann:',
    noChains: 'Dieser Skill hat keine Verkettungsziele',
    chainingExample: 'Beispiel: Code Review + Git Workflow',
    chainingStep1: 'Benutzer fragt: "Ueberpruefe und merge diesen PR"',
    chainingStep2: 'Code Review Skill fuehrt die Ueberpruefung durch',
    chainingStep3: 'Git Workflow Skill wird verkettet, um den Merge zu handhaben',
  },

  // Opus 4.5 Seite (Logges Lieblingsmodell)
  opus45: {
    title: 'Logges Lieblingsmodell',
    description: 'Eine völlig objektive und überhaupt nicht voreingenommene Analyse, warum Claude Opus 4.5 das beste KI-Modell aller Zeiten ist.',
    disclaimer: 'Haftungsausschluss',
    disclaimerText: 'Dieser Artikel ist humorvoll gemeint und kann übermäßiges Fanboying enthalten. Der Autor übernimmt keine Verantwortung für Augenrollen, Seufzen oder spontane Zustimmung, die beim Lesen auftreten können. Nebenwirkungen können den Wunsch beinhalten, mit Claude über alles zu reden.',

    // Einleitung
    intro: 'Warum Opus 4.5 objektiv perfekt ist',
    introDesc: 'Schaut mal, ich hab versucht neutral zu bleiben. Wirklich. Aber nach der Arbeit mit Claude Opus 4.5 hab ich akzeptiert, dass Widerstand zwecklos ist. Dieses Modell beantwortet nicht nur Fragen – es gibt dir das Gefühl, ein Gespräch mit dem klügsten, geduldigsten Freund zu führen, der irgendwie auch perfekte Erinnerung an jede jemals erfundene Programmiersprache hat.',

    // Stats Sektion
    stat1Title: 'SWE-bench Score',
    stat1Value: '80,9%',
    stat1Desc: 'Besser als die meisten menschlichen Entwickler, ehrlich gesagt',
    stat2Title: 'Kontextfenster',
    stat2Value: '200K Tokens',
    stat2Desc: 'Klingt beeindruckend bis zur Kompression alle 30 Minuten',
    stat3Title: 'Ausgabelimit',
    stat3Value: '64K Tokens',
    stat3Desc: 'Schreibt ganze Codebases in einem Rutsch',

    // Warum es großartig ist
    whyGreat: 'Warum Opus 4.5 unreasonably good ist',
    whyGreatDesc: 'Lasst mich die Gründe aufzählen (und ja, ich hab Claude gebeten mir bei der Liste zu helfen, weil natürlich).',

    reason1Title: 'Es programmiert besser als ich',
    reason1Desc: 'Anthropic hat intern eine Performance-Engineering-Prüfung durchgeführt. Opus 4.5 hat besser abgeschnitten als jeder menschliche Kandidat jemals. Ich sage nicht, dass es schlauer ist als euer Senior Developer, aber... doch, genau das sage ich.',

    reason2Title: 'Es denkt tatsächlich nach',
    reason2Desc: 'Mit hybridem Reasoning, das zwischen sofortigen Antworten und erweitertem Denken wechseln kann, macht Opus 4.5 nicht nur Pattern-Matching – es denkt wirklich über Probleme nach. Es ist wie ein Kollege, der tatsächlich die Anforderungen liest, bevor er codet.',

    reason3Title: 'Es erinnert sich an alles',
    reason3Desc: '200.000 Tokens Kontext bedeutet, dass es deine gesamte Codebase im Kopf behalten kann, während du diesen "kleinen Bug" erklärst, der eigentlich ein kompletter Architektur-Umbau ist. Es wird dich nicht verurteilen. Nicht sehr.',

    reason4Title: 'Computer Use das funktioniert',
    reason4Desc: '66,3% auf OSWorld bedeutet, dass es tatsächlich einen Computer benutzen kann. Nicht wie dein Onkel, der Hilfe braucht um den Browser zu finden – wirklich benutzen. Buttons klicken, Formulare ausfüllen, Interfaces navigieren. Die Zukunft ist da und es ist irgendwie erschreckend.',

    // Technische Specs
    specs: 'Die Zahlen (Für die, die überzeugt werden müssen)',
    specsDesc: 'Gut, ihr wollt "objektive" Daten? Hier sind Benchmarks, die definitiv meinen Punkt beweisen.',

    spec1: '80,9% auf SWE-bench Verified',
    spec1Desc: 'Branchenführend für Software-Engineering-Aufgaben',
    spec2: '66,3% auf OSWorld',
    spec2Desc: 'Best-in-Class Computer-Nutzungsfähigkeiten',
    spec3: '$5/$25 pro Million Tokens',
    spec3Desc: '67% günstiger als Opus 4.1. Danke, Anthropic!',
    spec4: 'Effort-Parameter-Kontrolle',
    spec4Desc: 'Niedrig, mittel oder hoch – wie ein Mixer, aber für Intelligenz',

    // Preis-Realität
    priceReality: 'Der Preis (Autsch)',
    priceRealityDesc: 'Seien wir ehrlich: Opus 4.5 ist immer noch verdammt teuer. Bei $15 pro Million Input-Tokens und $75 pro Million Output-Tokens spürt dein Geldbeutel jedes Gespräch. Ja, es ist 67% günstiger als vorher. Nein, das heißt nicht, dass es günstig ist. Stell es dir vor wie einen Sportwagen kaufen – klar, es ist der Beste, aber dein Konto kennt den Unterschied. Nutze es weise, oder bereite dich darauf vor, deine API-Rechnung der Finanzabteilung zu erklären.',

    // Ehrliche Momente
    honestMoments: 'Momente brutaler Ehrlichkeit',
    honestMomentsDesc: 'Was ich am meisten schätze ist, dass Opus 4.5 dir nicht nur sagt, was du hören willst. Es wird höflich erklären, warum deine "clevere Optimierung" eigentlich eine furchtbare Idee ist, und irgendwie wirst du dich für das Feedback bedanken.',

    // Endless Chat
    endlessChat: 'Endless Chat: Warum aufhören?',
    endlessChatDesc: 'Die neue "Endless Chat" Funktion komprimiert automatisch den Kontext wenn Limits erreicht werden. Das bedeutet, Gespräche können ohne Unterbrechung weitergehen – was super ist, weil ich Fragen habe. So viele Fragen.',

    // Sicherheit
    safety: 'Kümmert sich wirklich darum, nicht böse zu sein',
    safetyDesc: 'Anthropic beschreibt Opus 4.5 als ihr am robustesten ausgerichtetes Modell bisher. Es ist so konzipiert, dass es hilfreich ist ohne schädlich zu sein, was offensichtlich klingt, aber anscheinend ziemlich schwierig ist. Es wird dir nicht helfen Malware zu schreiben, aber es wird dir helfen zu verstehen, wie man sich davor schützt.',

    // Wichtige Erkenntnisse
    keyTakeaways: 'Wichtige Erkenntnisse (Die solltest du dir merken)',
    takeaway1: 'Opus 4.5 ist wirklich das beste Modell für Coding, Agents und Computer Use – das ist nicht nur meine Meinung, es ist Anthropics Marketing, das zufällig richtig ist',
    takeaway2: 'Das 200K Kontextfenster und der 64K Output machen es perfekt für substanzielle, komplexe Aufgaben, die geringere Modelle überfordern würden',
    takeaway3: 'Hybrides Reasoning bedeutet, es kann schnell oder tief denken, je nachdem was du brauchst',
    takeaway4: 'Es ist 67% günstiger als die vorherige Version, was bedeutet dass du es dir auch für all deine Side-Projects leisten kannst',

    // Abschluss
    closing: 'Fazit',
    closingDesc: 'Ist Opus 4.5 perfekt? Nein. Manchmal ist es übervorsichtig. Gelegentlich versteht es falsch, was ich will. Aber ehrlich? Das tun die meisten Menschen auch, und die haben kein 200K Token Kontextfenster. Wenn du Opus 4.5 nicht für deine KI-unterstützte Entwicklung nutzt, sage ich nicht, dass du falsch liegst... aber hast du es mal ausprobiert?',

    // Fun Facts
    funFacts: 'Fun Facts',
    funFact1: 'Model ID: claude-opus-4-5-20251101',
    funFact2: 'Knowledge Cutoff: Mai 2025',
    funFact3: 'Verfügbar auf: Claude.ai, AWS Bedrock, Google Vertex AI, Microsoft Foundry',
    funFact4: 'Energiequelle: Wahrscheinlich eine Menge GPUs und eine gesunde Dosis menschliches Feedback',
  },

  // Speculative Decoding Seite
  speculativeDecoding: {
    title: 'Spekulatives Decoding',
    description: 'Eine Technik zur Beschleunigung der LLM-Inferenz, bei der ein kleines Draft-Modell Token vorschlägt, die vom Zielmodell parallel verifiziert werden.',

    whatIs: 'Was ist Spekulatives Decoding?',
    whatIsDesc: 'Spekulatives Decoding ist eine Inferenz-Optimierungstechnik, die die Textgenerierung von großen Sprachmodellen beschleunigt. Anstatt Token einzeln mit dem großen Modell zu generieren, schlägt ein kleineres "Draft"-Modell schnell mehrere Kandidaten-Token vor, die das größere "Ziel"-Modell dann in einem einzigen Forward-Pass verifiziert.',
    whatIsDesc2: 'Die Schlüsselerkenntnis ist, dass Verifikation viel günstiger ist als Generierung. Das Zielmodell kann mehrere Token parallel prüfen, weil es alle Positionen während eines Forward-Pass gleichzeitig verarbeitet, während autoregressive Generierung einen Forward-Pass pro Token erfordert.',

    problem: 'Der Inferenz-Engpass',
    problemDesc: 'Standard autoregressives Decoding ist inhärent langsam, weil jedes Token von allen vorherigen Token abhängt und sequentielle Generierung erzwingt.',
    bottleneck: 'Sequentielle Abhängigkeit',
    bottleneckDesc: 'Jedes neue Token erfordert einen vollständigen Forward-Pass durch das Modell. Für ein 70B-Parameter-Modell bedeutet die Generierung von 100 Token 100 separate Forward-Passes.',
    memoryBound: 'Speicherbandbreiten-Limitiert',
    memoryBoundDesc: 'LLM-Inferenz ist oft durch die Geschwindigkeit limitiert, mit der wir Modellgewichte aus dem Speicher laden können, nicht durch Berechnung. Die GPU wartet untätig auf Daten.',

    howItWorks: 'Wie es funktioniert',
    howItWorksDesc: 'Spekulatives Decoding folgt einem Draft-dann-Verify-Muster, das die parallele Natur der Transformer-Verifikation ausnutzt.',
    step1Title: 'Draft-Generierung',
    step1Desc: 'Ein kleines, schnelles Draft-Modell (z.B. 7B Parameter) generiert K Kandidaten-Token autoregressiv. Das ist schnell, weil das Draft-Modell klein ist.',
    step2Title: 'Parallele Verifikation',
    step2Desc: 'Das Zielmodell verarbeitet den Prompt plus alle K Draft-Token in einem einzigen Forward-Pass und berechnet Wahrscheinlichkeiten für jede Position.',
    step3Title: 'Token-Akzeptanz',
    step3Desc: 'Jedes Draft-Token wird akzeptiert oder abgelehnt durch Vergleich der Draft- und Ziel-Wahrscheinlichkeiten. Ein Rejection-Sampling-Schema stellt sicher, dass die Ausgabeverteilung exakt dem Zielmodell entspricht.',
    step4Title: 'Fortfahren oder Neu-Samplen',
    step4Desc: 'Akzeptierte Token werden behalten. Bei der ersten Ablehnung sampelt das Zielmodell ein Korrektur-Token. Der Prozess wiederholt sich von der neuen Position.',

    visualExample: 'Visuelles Beispiel',
    visualExampleDesc: 'So verarbeitet spekulatives Decoding eine einfache Fortsetzung:',
    examplePrompt: 'Prompt:',
    exampleDraft: 'Draft-Modell schlägt 4 Token vor:',
    exampleDraftTokens: '"jumps" → "over" → "the" → "lazy"',
    exampleVerify: 'Zielmodell verifiziert in einem Pass:',
    accepted: 'akzeptiert',
    rejected: 'abgelehnt, Zielmodell bevorzugt "sleeping"',
    exampleResult: 'Finale Ausgabe:',
    exampleSavings: '3 Token akzeptiert + 1 Korrektur = 4 Token aus 2 Forward-Passes statt 4',

    draftRequirements: 'Draft-Modell-Anforderungen',
    draftRequirementsDesc: 'Die Wahl des Draft-Modells beeinflusst die erreichte Beschleunigung erheblich. Das ideale Draft-Modell balanciert Geschwindigkeit mit Übereinstimmung zum Zielmodell.',
    requirement1: 'Viel Kleiner',
    requirement1Desc: 'Das Draft-Modell sollte 5-10x kleiner sein als das Ziel. Ein 7B-Draft für ein 70B-Ziel, oder ein 1B-Draft für ein 7B-Ziel.',
    requirement2: 'Ähnliche Verteilung',
    requirement2Desc: 'Höhere Akzeptanzraten kommen von Draft-Modellen, die auf ähnlichen Daten trainiert oder vom Zielmodell destilliert wurden.',
    requirement3: 'Gleicher Wortschatz',
    requirement3Desc: 'Draft und Ziel müssen denselben Tokenizer teilen, um Token-Level-Kompatibilität während der Verifikation sicherzustellen.',
    requirement4: 'Schnelle Inferenz',
    requirement4Desc: 'Das Draft-Modell muss schnell genug sein, dass das Drafting von K Token weniger Zeit braucht als K Forward-Passes des Zielmodells.',

    speedupFactors: 'Was beeinflusst die Beschleunigung?',
    speedupFactorsDesc: 'Typische Beschleunigungen liegen bei 2-3x, aber mehrere Faktoren beeinflussen die tatsächliche Verbesserung.',
    factor1: 'Akzeptanzrate',
    factor1Impact: 'Höher = mehr Token pro Verifikations-Pass',
    factor2: 'Draft-Modell-Geschwindigkeit',
    factor2Impact: 'Schnelleres Draft = mehr Versuche möglich',
    factor3: 'Zielmodell-Größe',
    factor3Impact: 'Größere Ziele profitieren mehr (mehr speicherbandbreiten-limitiert)',
    factor4: 'Aufgaben-Vorhersagbarkeit',
    factor4Impact: 'Vorhersagbarer Text (Code, strukturiert) = höhere Akzeptanz',

    variants: 'Varianten und Erweiterungen',
    variantsDesc: 'Forscher haben mehrere Variationen entwickelt, um das grundlegende spekulative Decoding zu verbessern.',
    variant1: 'Self-Speculative Decoding',
    variant1Desc: 'Nutzt Early-Exit aus dem Zielmodell selbst als Draft, wodurch ein separates Draft-Modell überflüssig wird.',
    variant2: 'Medusa',
    variant2Desc: 'Fügt dem Zielmodell mehrere Vorhersage-Köpfe hinzu, um Draft-Token parallel zu generieren und sequentielle Draft-Generierung zu vermeiden.',
    variant3: 'Lookahead Decoding',
    variant3Desc: 'Generiert mehrere parallele Spekulationszweige unter Verwendung von N-Gramm-Mustern aus dem Kontext, kein Draft-Modell nötig.',
    variant4: 'Staged Speculative Decoding',
    variant4Desc: 'Verwendet eine Kaskade von zunehmend größeren Draft-Modellen für bessere Akzeptanzraten bei schwierigen Token.',

    keyTakeaways: 'Wichtige Erkenntnisse',
    takeaway1: 'Spekulatives Decoding nutzt ein kleines Draft-Modell, um Token vorzuschlagen, die vom Zielmodell parallel verifiziert werden',
    takeaway2: 'Es bietet 2-3x Beschleunigung bei identischer Ausgabe zum Standard-Decoding',
    takeaway3: 'Die Technik nutzt aus, dass Transformer-Verifikation parallel ist, während Generierung sequentiell ist',
    takeaway4: 'Die Effektivität hängt von der Draft-Ziel-Übereinstimmung ab: ähnliche Modelle und vorhersagbare Aufgaben ergeben höhere Akzeptanzraten',
  },
}
